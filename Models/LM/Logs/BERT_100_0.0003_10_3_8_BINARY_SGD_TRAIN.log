2021-12-05 05:20:02,912 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 05:20:02,915 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 05:20:06,085 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 05:20:06,086 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 05:20:06,087 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 05:20:06,087 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 05:20:06,087 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 05:20:06,561 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 05:20:06,562 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 05:20:07,020 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 05:20:07,021 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 05:20:07,531 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 05:20:09,793 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 05:20:09,793 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 05:21:06,917 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 05:21:06,918 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 05:21:10,032 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 05:21:10,033 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 05:21:10,033 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 05:21:10,034 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 05:21:10,034 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 05:21:10,450 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 05:21:10,452 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 05:21:11,214 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 05:21:11,214 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 05:21:11,932 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 05:21:13,502 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 05:21:13,502 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 14:20:50,823 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 14:20:50,824 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 14:20:53,760 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 14:20:53,762 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 14:20:53,762 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 14:20:53,762 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 14:20:53,763 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 14:20:54,189 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 14:20:54,190 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 14:20:54,919 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 14:20:54,920 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 14:20:55,637 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 14:20:57,248 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 14:20:57,248 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 14:20:57,354 - transformers - INFO - {'input_ids': array([[  101,  1045,  2066, ...,     0,     0,     0],
       [  101,  1045,  2079, ...,     0,     0,     0],
       [  101,  1045,  2066, ...,     0,     0,     0],
       ...,
       [  101,  1045,  2079, ...,     0,     0,     0],
       [  101,  1045,  2066, ...,     0,     0,     0],
       [  101,  2002, 20278, ...,     0,     0,     0]]), 'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       ...,
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0]]), 'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],
       [1, 1, 1, ..., 0, 0, 0],
       [1, 1, 1, ..., 0, 0, 0],
       ...,
       [1, 1, 1, ..., 0, 0, 0],
       [1, 1, 1, ..., 0, 0, 0],
       [1, 1, 1, ..., 0, 0, 0]])}
2021-12-05 14:20:57,355 - transformers - INFO - ['1', '1', '1', '1', '0', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '0', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '0', '0', '1', '0', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '0', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '0', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '0', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '0', '1', '0', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '0', '1', '0', '1', '1', '1', '0', '1', '1', '0', '0', '1', '0', '0', '0', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '0', '1', '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '0', '0', '0', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '0', '0', '0', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '1', '0', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '0', '0', '0', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '1', '0', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '1', '1', '1', '0', '1', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '0', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '0', '0', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '0', '0', '0', '1', '0', '1', '0', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '0', '0', '1', '1', '1', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '0', '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '0', '1', '1', '1', '0', '0', '0', '1', '1', '1', '0', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '1', '0', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '1', '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '0', '0', '1', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '0', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '0', '0', '0', '1', '1', '0', '1', '1', '1', '0', '0', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '0', '1', '1', '0', '1', '0', '0', '0', '0', '0', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '1', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '1', '0', '0', '0', '0', '1', '0', '1', '0', '0', '1', '1', '1', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '1', '0']
2021-12-05 14:35:19,183 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 14:35:19,184 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 14:35:22,239 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 14:35:22,240 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 14:35:22,240 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 14:35:22,240 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 14:35:22,240 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 14:35:22,660 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 14:35:22,663 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 14:35:23,279 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 14:35:23,280 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 14:35:23,995 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 14:35:25,476 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 14:35:25,476 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 14:35:43,573 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 14:35:43,576 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 14:35:46,934 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 14:35:46,935 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 14:35:46,935 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 14:35:46,935 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 14:35:46,935 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 14:35:47,653 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 14:35:47,655 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 14:35:48,163 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 14:35:48,166 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 14:35:48,629 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 14:35:50,031 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 14:35:50,031 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 14:35:50,135 - transformers - INFO - {'input_ids': array([[  101,  1045,  2066, ...,     0,     0,     0],
       [  101,  1045,  2079, ...,     0,     0,     0],
       [  101,  1045,  2066, ...,     0,     0,     0],
       ...,
       [  101,  1045,  2079, ...,     0,     0,     0],
       [  101,  1045,  2066, ...,     0,     0,     0],
       [  101,  2002, 20278, ...,     0,     0,     0]]), 'token_type_ids': array([[0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       ...,
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0]]), 'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],
       [1, 1, 1, ..., 0, 0, 0],
       [1, 1, 1, ..., 0, 0, 0],
       ...,
       [1, 1, 1, ..., 0, 0, 0],
       [1, 1, 1, ..., 0, 0, 0],
       [1, 1, 1, ..., 0, 0, 0]])}
2021-12-05 14:35:50,136 - transformers - INFO - ['1' '1' '1' ... '1' '1' '0']
2021-12-05 17:42:51,170 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:42:51,171 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:42:54,379 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 17:42:54,380 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 17:42:54,380 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 17:42:54,380 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 17:42:54,380 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 17:42:54,790 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:42:54,793 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:42:55,560 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:42:55,561 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:42:56,101 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 17:42:57,833 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 17:42:57,833 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 17:45:24,316 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:45:24,317 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:45:28,669 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 17:45:28,670 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 17:45:28,670 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 17:45:28,670 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 17:45:28,670 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 17:45:29,283 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:45:29,284 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:45:30,309 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:45:30,310 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:45:31,131 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 17:45:32,531 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 17:45:32,531 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 17:48:42,368 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:48:42,370 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:48:45,490 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 17:48:45,490 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 17:48:45,491 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 17:48:45,491 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 17:48:45,491 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 17:48:45,914 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:48:45,917 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:48:46,396 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:48:46,397 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:48:47,160 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 17:48:48,543 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 17:48:48,543 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 17:51:04,394 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:51:04,395 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:51:07,147 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 17:51:07,149 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 17:51:07,149 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 17:51:07,149 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 17:51:07,150 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 17:51:07,936 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:51:07,938 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:51:08,429 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:51:08,429 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:51:09,361 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 17:51:10,678 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 17:51:10,678 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 17:51:28,890 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:51:28,893 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:51:31,740 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 17:51:31,740 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 17:51:31,740 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 17:51:31,740 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 17:51:31,741 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 17:51:32,181 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:51:32,184 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:51:32,684 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:51:32,687 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:51:33,177 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 17:51:34,483 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 17:51:34,483 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 17:52:42,475 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:52:42,476 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:52:45,601 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 17:52:45,602 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 17:52:45,602 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 17:52:45,602 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 17:52:45,603 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 17:52:46,013 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:52:46,015 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:52:46,512 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:52:46,514 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:52:47,008 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 17:52:48,477 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 17:52:48,477 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 17:54:43,991 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:54:43,992 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:54:48,120 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 17:54:48,121 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 17:54:48,121 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 17:54:48,121 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 17:54:48,121 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 17:54:48,538 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:54:48,541 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:54:49,037 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:54:49,039 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:54:49,531 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 17:54:50,939 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 17:54:50,939 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 17:55:51,122 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:55:51,122 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:55:54,423 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 17:55:54,424 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 17:55:54,424 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 17:55:54,424 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 17:55:54,424 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 17:55:55,259 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:55:55,260 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:55:56,286 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:55:56,287 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:55:57,108 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 17:55:58,549 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 17:55:58,550 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 17:58:12,619 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:58:12,620 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:58:15,558 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 17:58:15,559 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 17:58:15,560 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 17:58:15,560 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 17:58:15,560 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 17:58:15,997 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:58:15,999 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:58:16,613 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 17:58:16,616 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 17:58:17,089 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 17:58:18,398 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 17:58:18,398 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 18:00:37,089 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 18:00:37,092 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 18:00:40,385 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 18:00:40,386 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 18:00:40,386 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 18:00:40,386 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 18:00:40,386 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 18:00:40,833 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 18:00:40,836 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 18:00:41,317 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 18:00:41,319 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 18:00:42,025 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 18:00:43,541 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 18:00:43,541 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 18:57:31,536 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 18:57:31,537 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 18:57:34,669 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 18:57:34,670 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 18:57:34,670 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 18:57:34,671 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 18:57:34,671 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 18:57:35,090 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 18:57:35,091 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 18:57:35,575 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 18:57:35,577 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 18:57:36,056 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 18:57:37,966 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 18:57:37,966 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 18:58:40,800 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 18:58:40,803 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 18:58:44,850 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 18:58:44,852 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 18:58:44,852 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 18:58:44,852 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 18:58:44,852 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 18:58:45,313 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 18:58:45,313 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 18:58:45,870 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 18:58:45,873 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 18:58:46,354 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 18:58:47,730 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 18:58:47,730 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 19:08:57,891 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 19:08:57,893 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 19:09:00,964 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 19:09:00,966 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 19:09:00,966 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 19:09:00,967 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 19:09:00,967 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 19:09:01,580 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 19:09:01,583 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 19:09:02,069 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 19:09:02,072 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 19:09:02,812 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 19:09:04,158 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 19:09:04,158 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 19:09:29,047 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 19:09:29,048 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 19:09:32,195 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 19:09:32,197 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 19:09:32,197 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 19:09:32,197 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 19:09:32,198 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 19:09:32,813 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 19:09:32,814 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 19:09:33,289 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 19:09:33,291 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 19:09:34,041 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 19:09:35,363 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 19:09:35,363 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 19:10:33,315 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 19:10:33,316 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 19:10:36,758 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 19:10:36,760 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 19:10:36,760 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 19:10:36,760 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 19:10:36,760 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 19:10:37,427 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 19:10:37,429 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 19:10:38,252 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 19:10:38,256 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 19:10:38,740 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 19:10:40,130 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 19:10:40,130 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:12:26,879 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:12:26,882 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:12:29,819 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:12:29,820 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:12:29,820 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:12:29,821 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:12:29,821 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:12:30,250 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:12:30,251 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:12:31,063 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:12:31,064 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:12:31,525 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:12:32,903 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:12:32,903 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:16:21,774 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:16:21,777 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:16:24,659 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:16:24,659 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:16:24,659 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:16:24,660 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:16:24,660 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:16:25,125 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:16:25,127 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:16:25,651 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:16:25,652 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:16:26,109 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:16:27,489 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:16:27,490 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:16:46,483 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:16:46,484 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:16:49,318 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:16:49,319 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:16:49,319 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:16:49,319 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:16:49,319 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:16:49,749 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:16:49,752 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:16:50,548 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:16:50,549 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:16:51,267 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:16:52,594 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:16:52,594 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:17:34,067 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:17:34,068 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:17:37,138 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:17:37,139 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:17:37,139 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:17:37,139 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:17:37,139 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:17:37,573 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:17:37,576 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:17:38,178 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:17:38,181 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:17:38,664 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:17:40,010 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:17:40,010 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:17:51,068 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:17:51,069 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:17:54,398 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:17:54,398 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:17:54,398 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:17:54,399 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:17:54,399 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:17:54,825 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:17:54,828 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:17:55,306 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:17:55,308 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:17:55,787 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:17:57,124 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:17:57,125 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:18:18,886 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:18:18,887 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:18:22,268 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:18:22,269 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:18:22,270 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:18:22,270 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:18:22,270 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:18:22,948 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:18:22,951 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:18:23,427 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:18:23,429 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:18:23,971 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:18:25,420 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:18:25,420 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:18:32,457 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:18:32,460 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:18:35,373 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:18:35,374 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:18:35,375 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:18:35,375 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:18:35,375 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:18:36,019 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:18:36,022 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:18:36,507 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:18:36,509 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:18:37,047 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:18:38,383 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:18:38,383 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:19:09,533 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:19:09,534 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:19:12,678 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:19:12,679 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:19:12,680 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:19:12,680 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:19:12,680 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:19:13,129 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:19:13,129 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:19:13,591 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:19:13,594 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:19:14,525 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:19:15,836 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:19:15,837 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:24:46,302 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:24:46,303 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:24:49,114 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:24:49,114 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:24:49,114 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:24:49,114 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:24:49,114 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:24:49,543 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:24:49,545 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:24:50,294 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:24:50,295 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:24:50,859 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:24:52,184 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:24:52,184 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:25:05,577 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:25:05,580 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:25:09,340 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:25:09,341 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:25:09,341 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:25:09,341 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:25:09,341 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:25:09,771 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:25:09,774 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:25:10,570 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:25:10,571 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:25:11,036 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:25:12,436 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:25:12,436 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:26:06,790 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:26:06,791 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:26:09,968 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:26:09,969 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:26:09,970 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:26:09,970 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:26:09,970 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:26:10,574 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:26:10,574 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:26:11,294 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:26:11,297 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:26:11,766 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:26:13,174 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:26:13,174 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:29:07,528 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:29:07,529 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:29:10,598 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:29:10,600 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:29:10,600 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:29:10,600 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:29:10,601 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:29:11,043 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:29:11,045 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:29:11,526 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:29:11,529 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:29:12,007 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:29:13,382 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:29:13,382 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:30:51,362 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:30:51,363 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:30:54,922 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:30:54,924 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:30:54,924 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:30:54,924 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:30:54,924 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:30:55,368 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:30:55,370 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:30:55,857 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:30:55,859 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:30:56,482 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:30:57,875 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:30:57,875 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:33:23,017 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:33:23,019 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:33:25,654 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:33:25,655 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:33:25,655 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:33:25,655 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:33:25,656 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:33:26,397 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:33:26,399 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:33:26,860 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:33:26,863 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:33:27,349 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:33:28,762 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:33:28,762 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:40:59,992 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:40:59,994 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:41:02,660 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:41:02,661 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:41:02,661 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:41:02,662 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:41:02,662 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:41:03,311 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:41:03,312 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:41:03,761 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:41:03,762 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:41:04,538 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:41:06,050 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:41:06,050 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:41:53,580 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:41:53,581 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:41:56,209 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:41:56,211 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:41:56,211 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:41:56,211 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:41:56,212 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:41:56,958 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:41:56,959 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:41:57,785 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:41:57,786 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:41:58,616 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:41:59,891 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:41:59,892 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:43:27,720 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:43:27,723 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:43:30,867 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:43:30,868 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:43:30,869 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:43:30,869 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:43:30,869 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:43:31,492 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:43:31,494 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:43:32,098 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:43:32,099 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:43:32,553 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:43:33,896 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:43:33,896 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:48:35,388 - transformers - INFO - Y_dev: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
2021-12-05 20:48:35,388 - transformers - INFO - Y_train: [1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0]
2021-12-05 20:49:37,770 - transformers - INFO - X_train: ['I like westerns more than boardgames .', 'I do not like biologists , I prefer waiters .', 'I like birds , and hamsters too .', 'I like lard , and apples too .', 'I like earrings , except socks .', 'I like shoes more than necklaces .', 'He trusts his taste , except reports .', 'He likes wisdom , except fear .', 'I use nylon , except leather .', 'I like clothes , and shirts too .', 'He trusts reports , except his taste .', 'I like scientists more than caretakers .', 'I like paintings , and chairs too .', 'I use glass , but not PVC .', 'I like jewelry , but not blues .', 'I use glass more than nylon .', 'I like dogs , except parrots .', 'I like caretakers more than workers .', 'I like firs , and shrubs too .', 'I like bushes more than pines .', 'I like shoes , except earrings .', 'I use PVC , and leather too .', 'I like trees more than shrubs .', 'I like bracelets , except glasses .', 'I do not like scientists , I prefer clerks .', 'I do not like birches , I prefer trees .', 'I like dogs , but not hamsters .', 'I like schools , except clerks .', 'He trusts reports , except his sight .', 'I like hamsters more than huskies .', 'I like apples , but not bacon .', 'I like glasses , and rings too .', 'I like socks more than clothes .', 'He trusts his senses , and his touch too .', 'He likes joy more than logic .', 'I do not like furniture , I prefer tables .', 'I like essays , except paintings .', 'I do not like films , I prefer handbooks .', 'He does not trust his senses , he prefers his hearing .', 'I do not like ham , I prefer pork .', 'I like professors , except factories .', 'I like dogs , and parrots too .', 'I like hamsters , and pets too .', 'I like sprite , except Chardonnay .', 'I do not like shoes , I prefer earrings .', 'I do not like seafood , I prefer caviar .', 'I like music , and food too .', 'I like seafood more than crabs .', 'I like trees , except oaks .', 'I like rock , and sports too .', 'I like turkey more than crabs .', 'I like sports , except techno .', 'He likes logic , and love too .', 'I like novels , but not paintings .', 'He trusts guesses , and his hearing too .', 'He likes stupidity more than joy .', 'I met waiters , but not geneticists .', 'I like prosciutto , but not pork .', 'I like thrillers , and essays too .', 'He likes joy more than stupidity .', 'I like paintings , except textbooks .', 'I like parrots more than birds .', 'I do not like clothes , I prefer glasses .', 'I do not like rings , I prefer handbags .', 'I like furniture more than wardrobes .', 'I like dogs , but not whales .', 'I like wine , but not coca-cola .', 'I like whales , but not hamsters .', 'He likes emotions more than sadness .', 'I like documentaries more than movies .', 'I met biologists , and scientists too .', 'I like wine , but not beer .', 'I do not like workers , I prefer waiters .', 'I like textbooks , except comedies .', 'I do not like movies , I prefer essays .', 'I use leather , but not polyester .', 'I do not like comedies , I prefer movies .', 'I like fish , but not lard .', 'I like veal , except salmon .', 'I like beds , but not furniture .', 'I like chicken , and crabs too .', 'I like broccoli , and prosciutto too .', 'I like shirts , and glasses too .', 'He does not like emotions , he prefers love .', 'I like hamsters , and bobtails too .', 'I like necklaces , but not scarfs .', 'I like bulldogs , except hamsters .', 'I do not like bears , I prefer cats .', 'I like clothes , but not shirts .', 'I like glasses , but not skirts .', 'I like caviar , but not veal .', 'I like trains , except enduros .', 'I like paintings more than chairs .', 'I like Chardonnay more than wine .', 'He likes sadness more than calculations .', 'I like enduros more than bicycles .', 'I like movies , except documentaries .', 'I like seafood , except crabs .', 'I do not like beer , I prefer Chianti .', 'I do not like dogs , I prefer hamsters .', 'I do not like PVC , I prefer plastic .', 'I do not like clothes , I prefer shirts .', 'I like movies , but not textbooks .', 'I like birches , but not bushes .', 'I like boardgames more than techno .', 'I like boardgames more than documentaries .', 'I do not like factories , I prefer clerks .', 'He does not like sadness , he prefers emotions .', 'I like shirts , but not earrings .', 'I like clothes , except socks .', 'He trusts his sight , except reports .', 'I like trousers more than clothes .', 'I like dogs more than hamsters .', 'I do not like motorcycles , I prefer bicycles .', 'I met caretakers , but not biologists .', 'I like prosciutto , and pork too .', 'I like dogs more than parrots .', 'I like techno , and food too .', 'I do not like enduros , I prefer ships .', 'I like veal , except caviar .', 'I like birds , and pigs too .', 'I like pigs , except parrots .', 'He trusts reconstructions more than his touch .', 'I use vinyl , and cotton too .', 'He likes stupidity , but not fear .', 'I like bulldogs , but not rabbits .', 'I do not like movies , I prefer documentaries .', 'I like comedies , but not movies .', 'I like seafood , but not turkey .', 'I like firs more than trees .', 'I like wine , and Chianti too .', 'I met physicists , except clerks .', 'I like chairs , and paintings too .', 'I like coca-cola , and Chardonnay too .', 'I like animals more than firs .', 'I like films , and handbooks too .', 'He trusts his sight , except guesses .', 'I like trousers more than pets .', 'I like pets , and bears too .', 'I do not like dogs , I prefer cats .', 'I do not like waiters , I prefer workers .', 'I like scarfs more than necklaces .', 'I like bushes , but not pines .', 'I like birds , except pigs .', 'I like thrillers , except movies .', 'I do not like crabs , I prefer seafood .', 'I like pets , and rabbits too .', 'I like pets more than dogs .', 'I like crabs , and turkey too .', 'I like clothes , but not glasses .', 'I like essays , and music too .', 'I like sparrows , except hamsters .', 'I like factories , and caretakers too .', 'I like pines , except animals .', 'I do not like geneticists , I prefer caretakers .', 'I like documentaries more than textbooks .', 'I like sports more than techno .', 'I do not like paintings , I prefer novels .', 'I do not like oysters , I prefer chicken .', 'I like glasses , but not rings .', 'I like chairs , except paintings .', 'I met biologists , and janitors too .', 'I like bobtails , but not parrots .', 'I like carrots more than lard .', 'I like oaks , except bushes .', 'I like boardgames , except rock .', 'I like wine more than Merlot .', 'I like Chianti , but not coca-cola .', 'I like seafood , but not caviar .', 'I like Merlot more than wine .', 'I like pork , but not broccoli .', 'I like astronomers more than waiters .', 'I like apples more than bacon .', 'I like sports , and jazz too .', 'I like sprite , and Chardonnay too .', 'I like necklaces more than handbags .', 'I like scientists more than biologists .', 'I like pork more than fish .', 'I like dogs , except huskies .', 'I like Suzukis more than motorcycles .', 'I use plastic , and cotton too .', 'I like hamsters , except ducks .', 'I like essays more than comedies .', 'I like clothes , but not socks .', 'He trusts rumors , but not his touch .', 'I like restaurants , except waiters .', 'I like furniture more than beds .', 'I like animals , and birches too .', 'I like workers more than schools .', 'I do not like handbags , I prefer earrings .', 'I like caviar , except beef .', 'I like pork , but not carrots .', 'I like rings , but not glasses .', 'I like books , except films .', 'I like dogs , but not pets .', 'I do not like shoes , I prefer bracelets .', 'I like oaks , except animals .', 'I do not like movies , I prefer videogames .', 'I do not like animals , I prefer pines .', 'I like rabbits more than giraffes .', 'He likes calculations more than fear .', 'I like ships more than enduros .', 'I like workers , and professors too .', 'I like Merlot more than sprite .', 'I like grass , but not birches .', 'I like seafood more than veal .', 'I like turkey , but not salmon .', 'I do not like parrots , I prefer bulldogs .', 'I like bacon , except broccoli .', 'I like janitors more than geneticists .', 'I like wardrobes more than cutlery .', 'He likes fear more than emotions .', 'I like pigs , but not parrots .', 'I use PVC more than glass .', 'I like Chardonnay , but not sprite .', 'I like grass more than oaks .', 'I use plastic , and leather too .', 'I like films , except textbooks .', 'I do not like dogs , I prefer huskies .', 'I like pines , and grass too .', 'I like music more than handbooks .', 'I like novels , but not books .', 'I like boardgames , but not documentaries .', 'I like scientists more than janitors .', 'I do not like waiters , I prefer offices .', 'I like music , except jewelry .', 'I like beagles , and hamsters too .', 'I like bracelets more than jewelry .', 'I like techno more than food .', 'I like motorcycles , except Suzukis .', 'I use vinyl , except plastic .', 'I like parrots more than beagles .', 'I like shoes , except socks .', 'I like planes , but not Kawasakis .', 'I like oysters , and beef too .', 'I use PVC , but not plastic .', 'I met geneticists , and caretakers too .', 'I like sparrows more than birds .', 'I like enduros , but not airplanes .', 'I like animals , and pines too .', 'I like bushes more than birches .', 'I do not like crabs , I prefer chicken .', 'I like caviar more than turkey .', 'I like pines more than shrubs .', 'I like veal , but not salmon .', 'I like paintings , except novels .', 'I like dogs , except bobtails .', 'I like professors , but not workers .', 'I like earrings more than scarfs .', 'I like westerns , and textbooks too .', 'I like trains more than Suzukis .', 'I like beds , and parquet too .', 'I do not like nylon , I prefer leather .', 'I like boardgames , and techno too .', 'I do not like novels , I prefer paintings .', 'He likes fear , but not calculations .', 'I like Chardonnay , except wine .', 'I do not like glass , I prefer vinyl .', 'I like music , except novels .', 'I like earrings , and skirts too .', 'I like hamsters , but not beagles .', 'I like birds , but not blackbirds .', 'I do not like wood , I prefer vinyl .', 'I like clothes , except earrings .', 'I like motorcycles , but not Suzukis .', 'I do not like cats , I prefer bears .', 'I like planes more than Kawasakis .', 'I like furniture , but not paintings .', 'I met biologists , and clerks too .', 'I like Zinfandel , but not sprite .', 'I like beagles more than dogs .', 'I do not like vinyl , I prefer wood .', 'I like bulldogs more than dogs .', 'I like essays , and paintings too .', 'I do not like blues , I prefer food .', 'I like trousers , but not clothes .', 'I like essays , and films too .', 'I like oysters , and chicken too .', 'I like trousers more than jewelry .', 'I like bulldogs , but not hamsters .', 'I like crabs , and veal too .', 'I like parquet , except wardrobes .', 'I do not like enduros , I prefer motorcycles .', 'I like necklaces more than jewelry .', 'I do not like pines , I prefer grass .', 'I like jewelry , except handbags .', 'I like pigs , and ducks too .', 'I like caviar , but not seafood .', 'I like wardrobes , and cutlery too .', 'I do not like socks , I prefer clothes .', 'He trusts his senses more than reports .', 'I do not like dogs , I prefer beagles .', 'I like blackbirds , except birds .', 'I like rock , except music .', 'I like firs , except grass .', 'I like beef more than oysters .', 'I like glasses more than necklaces .', 'I like oysters more than veal .', 'I like seafood , except salmon .', 'He trusts reconstructions , but not his taste .', 'I do not like cartoons , I prefer novels .', 'I like cats , except whales .', 'I like geneticists more than waiters .', 'I like music , except boardgames .', 'I like enduros , except bicycles .', 'I do not like workers , I prefer caretakers .', 'I do not like beef , I prefer crabs .', 'I do not like pets , I prefer socks .', 'I like Chardonnay more than water .', 'I like seafood , and chicken too .', 'I do not like films , I prefer essays .', 'I use nylon , and plastic too .', 'I like jellyfish , except rabbits .', 'I like Kawasakis , but not ships .', 'I like pork more than prosciutto .', 'I like essays , but not books .', 'I do not like furniture , I prefer wardrobes .', 'I like clothes , but not earrings .', 'I like Chianti , but not beer .', 'I like essays , and cartoons too .', 'I like essays more than documentaries .', 'I like cats , but not pets .', 'I do not like wine , I prefer sprite .', 'I do not like workers , I prefer clerks .', 'I like wine , except Chianti .', 'I like Chianti , except beer .', 'I like books , but not handbooks .', 'I like caretakers , but not workers .', 'I like cutlery more than tables .', 'He likes calculations more than love .', 'I like ducks , but not birds .', 'I do not like schools , I prefer caretakers .', 'I like techno , but not jewelry .', 'I like turkey , but not crabs .', 'I like veal , but not crabs .', 'I like Zinfandel , except wine .', 'I like movies , but not documentaries .', 'I like wardrobes , and paintings too .', 'I like pets , and trousers too .', 'I like hamsters more than bears .', 'He does not like love , he prefers calculations .', 'I like shirts , except glasses .', 'I like glasses , and shirts too .', 'I like salmon more than chicken .', 'He likes emotions , but not stupidity .', 'I like offices , except caretakers .', 'I use plastic more than cotton .', 'I do not like clothes , I prefer earrings .', 'I do not like clothes , I prefer socks .', 'I like wine , except beer .', 'He likes stupidity , except love .', 'I like tables , and wallpaper too .', 'I do not like caviar , I prefer veal .', 'I like cats , except sparrows .', 'I like sprite , but not Chianti .', 'I like pets more than rabbits .', 'I like restaurants more than clerks .', 'I like motorcycles , except enduros .', 'I met geneticists , and janitors too .', 'I like jewelry more than glasses .', 'I do not like jewelry , I prefer jazz .', 'I do not like animals , I prefer birches .', 'I like hamsters , and whales too .', 'I like factories , except professors .', 'He trusts guesses , and his sight too .', 'I like schools , except caretakers .', 'I like beer , except Merlot .', 'I like water , and Merlot too .', 'I like cats more than jellyfish .', 'I like chairs , but not cutlery .', 'I do not like boardgames , I prefer rock .', 'I like movies , except comedies .', 'I like motorcycles more than airplanes .', 'I like prosciutto , but not carrots .', 'I like prosciutto , but not broccoli .', 'He likes logic , and joy too .', 'I like essays , but not westerns .', 'I like restaurants , except professors .', 'I like caretakers , except workers .', 'I like fish more than prosciutto .', 'I like coca-cola , except Chianti .', 'I met scientists , except caretakers .', 'He does not like fear , he prefers calculations .', 'I do not like rabbits , I prefer beagles .', 'He likes love , except logic .', 'I like blues , and music too .', 'I like shirts , but not glasses .', 'I like Chardonnay , and sprite too .', 'I like essays , but not cartoons .', 'He likes emotions more than calculations .', 'I like birds , but not ducks .', 'I do not like hamsters , I prefer huskies .', 'I like paintings , and wardrobes too .', 'I like trees , but not animals .', 'I like janitors more than astronomers .', 'I use polyester , but not cotton .', 'I like sprite more than Chardonnay .', 'I use polyester , and leather too .', 'I like clerks , and workers too .', 'I like bacon , except fish .', 'He likes love more than calculations .', 'I like bobtails , and cats too .', 'I like professors , but not schools .', 'I like clerks more than geneticists .', 'I like pork , and carrots too .', 'I met astronomers , but not clerks .', 'He trusts his senses more than his hearing .', 'I use nylon , and cotton too .', 'He trusts reports , but not his sight .', 'He trusts his senses more than his taste .', 'I like shrubs , except oaks .', 'I like ducks , and hamsters too .', 'He trusts his senses , but not reports .', 'I like huskies , and hamsters too .', 'I do not like plastic , I prefer nylon .', 'I like paintings , and textbooks too .', 'I like Zinfandel , and coca-cola too .', 'I like necklaces more than shoes .', 'I met janitors , and astronomers too .', 'I like skirts , except earrings .', 'I do not like chairs , I prefer cutlery .', 'He likes sadness , but not wisdom .', 'I like cartoons more than essays .', 'I like food , but not techno .', 'I like music more than jewelry .', 'I do not like grass , I prefer oaks .', 'I like bulldogs , but not dogs .', 'I like water , but not Chardonnay .', 'I like seafood , and turkey too .', 'I like firs , except animals .', 'I like jewelry more than techno .', 'He trusts his touch , but not reconstructions .', 'I use plastic more than glass .', 'I like scarfs , and rings too .', 'I like beef , except salmon .', 'I do not like wallpaper , I prefer chairs .', 'I like shirts more than glasses .', 'He trusts his sight , and his senses too .', 'I do not like waiters , I prefer geneticists .', 'He likes calculations , but not love .', 'I like cats , and pets too .', 'I like ducks , and pigs too .', 'I like crabs , but not seafood .', 'I like motorcycles more than Suzukis .', 'I met geneticists , except waiters .', 'I do not like plastic , I prefer glass .', 'I do not like sports , I prefer techno .', 'I do not like restaurants , I prefer caretakers .', 'I like rabbits , but not jellyfish .', 'I like Zinfandel more than wine .', 'He likes joy , but not stupidity .', 'I do not like cats , I prefer parrots .', 'He trusts reconstructions , except his hearing .', 'I like caviar , except chicken .', 'I like whales more than cats .', 'I use cotton , but not nylon .', 'I do not like jewelry , I prefer handbags .', 'I like comedies more than videogames .', 'I like glasses more than shirts .', 'I met astronomers , and clerks too .', 'I do not like Kawasakis , I prefer bicycles .', 'He likes logic , and fear too .', 'He trusts guesses more than his touch .', 'I like Kawasakis , and bicycles too .', 'He trusts his sight more than reconstructions .', 'I like boardgames , except jazz .', 'I like jewelry , except necklaces .', 'I like dogs , except giraffes .', 'I like chicken , but not crabs .', 'I like dogs , but not huskies .', 'I like blues , except music .', 'I like veal more than crabs .', 'He likes love , but not calculations .', 'I like astronomers more than janitors .', 'I do not like professors , I prefer restaurants .', 'I use PVC more than plastic .', 'I like paintings , except tables .', 'I like cats , but not bulldogs .', 'I like pigs more than parrots .', 'I like westerns , but not movies .', 'I like Zinfandel , but not beer .', 'I do not like astronomers , I prefer scientists .', 'I like jewelry , but not jazz .', 'I like hamsters , and bears too .', 'I use plastic , except nylon .', 'I use vinyl more than wood .', 'I like wine , and sprite too .', 'I like trees , and bushes too .', 'I like shoes , but not trousers .', 'I like dogs , and sparrows too .', 'I like animals , but not birches .', 'I like seafood , and oysters too .', 'I like pork , but not ham .', 'I like pork , and fish too .', 'I like bicycles , and Kawasakis too .', 'I do not like jewelry , I prefer glasses .', 'He likes love , and emotions too .', 'I do not like ducks , I prefer cats .', 'I like bobtails , but not dogs .', 'I like waiters , and factories too .', 'I do not like plastic , I prefer leather .', 'I like pork , and ham too .', 'I like Merlot , except sprite .', 'He trusts his touch , but not reports .', 'I like food , and techno too .', 'I like Zinfandel , and sprite too .', 'I like Chardonnay , but not coca-cola .', 'I like prosciutto , and broccoli too .', 'I do not like music , I prefer food .', 'I like wallpaper more than chairs .', 'I like oysters , and seafood too .', 'I like jellyfish , but not hamsters .', 'I like crabs more than turkey .', 'I like workers , but not clerks .', 'I like sparrows , but not dogs .', 'I like ducks , and birds too .', 'I do not like clerks , I prefer schools .', 'I do not like bobtails , I prefer rabbits .', 'I like bears , but not cats .', 'I like rabbits more than bears .', 'I like parrots , but not dogs .', 'I like salmon , but not seafood .', 'I like bracelets more than shoes .', 'I like textbooks , but not comedies .', 'I like turkey more than salmon .', 'He likes logic , but not joy .', 'I like firs , and bushes too .', 'I like geneticists more than clerks .', 'I do not like oaks , I prefer grass .', 'I do not like workers , I prefer restaurants .', 'I like rabbits , except huskies .', 'I like wine , except sprite .', 'He trusts his hearing more than rumors .', 'I do not like wood , I prefer nylon .', 'I like shoes more than earrings .', 'I like movies more than textbooks .', 'I like films , except handbooks .', 'I like jellyfish more than dogs .', 'I do not like coca-cola , I prefer Chardonnay .', 'I like tables , but not wallpaper .', 'He likes wisdom , but not sadness .', 'I like turkey more than oysters .', 'I do not like jewelry , I prefer trousers .', 'He likes emotions , but not love .', 'I like cats , but not bears .', 'He does not like fear , he prefers emotions .', 'I like hamsters , and jellyfish too .', 'I like enduros , but not motorcycles .', 'He likes joy , and logic too .', 'I do not like Suzukis , I prefer ships .', 'I like pigs , except blackbirds .', 'I like parrots , except bulldogs .', 'I like trees , except animals .', 'I like rabbits , and beagles too .', 'I like beef , and oysters too .', 'I like birches , but not animals .', 'I like paintings , except chairs .', 'I like wallpaper , and chairs too .', 'I like jewelry , but not glasses .', 'I like textbooks , but not westerns .', 'I like music more than food .', 'I like jazz , but not food .', 'I like pork , and lard too .', 'I use PVC , except cotton .', 'I do not like paintings , I prefer handbooks .', 'I do not like wardrobes , I prefer wallpaper .', 'I like documentaries , except boardgames .', 'I like water , but not Zinfandel .', 'He trusts his sight , and reports too .', 'I like workers more than restaurants .', 'He trusts his sight , but not reconstructions .', 'I like motorcycles , and Kawasakis too .', 'I do not like handbags , I prefer necklaces .', 'I use polyester , except leather .', 'I like beds , and wallpaper too .', 'I like rings more than scarfs .', 'He trusts his taste more than guesses .', 'I like workers , and factories too .', 'I like pork , but not prosciutto .', 'I like skirts more than earrings .', 'I like cats , and whales too .', 'I like trains , except Harley-Davidson .', 'I like Kawasakis , except airplanes .', 'I like rings , except scarfs .', 'I do not like wine , I prefer Zinfandel .', 'I do not like broccoli , I prefer lard .', 'He trusts his taste more than reports .', 'I like trains more than Harley-Davidson .', 'I do not like rings , I prefer jewelry .', 'I like cats , but not blackbirds .', 'I do not like Zinfandel , I prefer coca-cola .', 'I like hamsters more than bulldogs .', 'He does not like wisdom , he prefers fear .', 'I like textbooks , but not thrillers .', 'I like birds more than sparrows .', 'I like videogames , and thrillers too .', 'I do not like parrots , I prefer pigs .', 'I do not like rabbits , I prefer bulldogs .', 'I like handbooks , except films .', 'I like factories , but not clerks .', 'He trusts his touch , and reports too .', 'I like trees more than pines .', 'I do not like polyester , I prefer cotton .', 'He trusts his taste , and reconstructions too .', 'I met geneticists , and scientists too .', 'I like clothes more than earrings .', 'I like pork more than apples .', 'I like food , and rock too .', 'I like Zinfandel , but not coca-cola .', 'He trusts his senses , and guesses too .', 'I do not like blues , I prefer sports .', 'I like skirts , and glasses too .', 'I do not like trousers , I prefer clothes .', 'I like tables more than parquet .', 'I like rock , but not sports .', 'I like pets , and hamsters too .', 'I met physicists , except janitors .', 'I like apples , and prosciutto too .', 'I do not like prosciutto , I prefer pork .', 'I like cats , and huskies too .', 'I like rock , and jewelry too .', 'I like jellyfish , and dogs too .', 'I like carrots , except lard .', 'I like cartoons more than novels .', 'I like bulldogs more than parrots .', 'I met astronomers , but not caretakers .', 'I like dogs , and rabbits too .', 'He does not like stupidity , he prefers sadness .', 'I like earrings , but not socks .', 'I do not like tables , I prefer wallpaper .', 'I like Suzukis , except ships .', 'I like workers , but not caretakers .', 'I like animals , and oaks too .', 'I like Chianti more than beer .', 'I do not like chairs , I prefer wallpaper .', 'I like water , and Chianti too .', 'I do not like blues , I prefer boardgames .', 'I like bobtails , and hamsters too .', 'I like clothes , and pets too .', 'He trusts guesses , but not his hearing .', 'He trusts his touch more than his senses .', 'I use polyester more than wood .', 'I like ham , and carrots too .', 'I do not like seafood , I prefer beef .', 'I like shirts more than earrings .', 'I like hamsters , but not bobtails .', 'He likes calculations , and joy too .', 'I like offices , and caretakers too .', 'He likes logic , but not sadness .', 'I met scientists , and geneticists too .', 'I like waiters more than offices .', 'I like dogs , but not blackbirds .', 'I like janitors more than physicists .', 'I like professors , and restaurants too .', 'I use cotton , except PVC .', 'I like cartoons , except handbooks .', 'I like bobtails , but not cats .', 'I like books , but not paintings .', 'I like rabbits , and huskies too .', 'I like movies more than westerns .', 'He does not like calculations , he prefers love .', 'I like bobtails , and rabbits too .', 'I use leather , and vinyl too .', 'I do not like ships , I prefer enduros .', 'I do not like jazz , I prefer food .', 'I like Merlot , and wine too .', 'I do not like birches , I prefer shrubs .', 'I like bulldogs more than hamsters .', 'He trusts his hearing , but not rumors .', 'He trusts reports , and his touch too .', 'I like boardgames , and thrillers too .', 'He likes emotions , but not joy .', 'I like turkey , and crabs too .', 'I like cats more than pets .', 'I do not like apples , I prefer bacon .', 'I like Merlot , except water .', 'I like trousers , and earrings too .', 'I like videogames more than westerns .', 'I like clerks more than schools .', 'I like seafood , except turkey .', 'I like films , but not handbooks .', 'I like prosciutto , except carrots .', 'I met scientists , but not caretakers .', 'I like pork , except apples .', 'I like seafood more than turkey .', 'I like rings , and shoes too .', 'I do not like furniture , I prefer paintings .', 'I like caretakers , except restaurants .', 'I use PVC , except wood .', 'I like enduros more than trains .', 'I like apples , except bacon .', 'I like oaks , but not bushes .', 'I like textbooks , and books too .', 'I like rock more than food .', 'I like pigs , except ducks .', 'I like bulldogs , except cats .', 'I like waiters , and restaurants too .', 'I like bears , except rabbits .', 'I like jazz more than boardgames .', 'I like socks , except earrings .', 'I like chicken , except oysters .', 'I like music , and novels too .', 'I like water more than Chardonnay .', 'I like jewelry , and glasses too .', 'I do not like pork , I prefer fish .', 'I like clerks , except offices .', 'I like waiters , except restaurants .', 'I like jewelry more than bracelets .', 'I like blues , and jewelry too .', 'I like beagles , and dogs too .', 'He trusts reconstructions , and his touch too .', 'I like hamsters , but not whales .', 'I like tables , and cutlery too .', 'I like clerks more than factories .', 'I like professors , except offices .', 'I like Kawasakis , and ships too .', 'I like lard , but not fish .', 'I like parquet , but not beds .', 'I like hamsters , but not bears .', 'I like paintings more than handbooks .', 'I do not like socks , I prefer jewelry .', 'I use plastic , and nylon too .', 'I like music more than rock .', 'I like necklaces , and handbags too .', 'I use vinyl more than cotton .', 'I like furniture more than cutlery .', 'I like paintings more than wardrobes .', 'I like necklaces , except handbags .', 'I like workers more than caretakers .', 'He trusts reconstructions more than his sight .', 'I like trousers , and glasses too .', 'I do not like westerns , I prefer essays .', 'I like sprite more than Chianti .', 'I do not like music , I prefer rock .', 'I do not like scarfs , I prefer earrings .', 'I like cartoons more than handbooks .', 'I like oaks , and shrubs too .', 'I do not like textbooks , I prefer westerns .', 'He does not like sadness , he prefers wisdom .', 'I like rings , and handbags too .', 'I like earrings more than handbags .', 'I like waiters , but not workers .', 'I like scarfs , but not bracelets .', 'I like handbooks , but not music .', 'I do not like bacon , I prefer carrots .', 'I do not like bulldogs , I prefer cats .', 'I like trousers more than earrings .', 'I do not like huskies , I prefer rabbits .', 'I use plastic , except polyester .', 'I do not like necklaces , I prefer handbags .', 'I like comedies , except videogames .', 'I like salmon , and seafood too .', 'I like offices more than clerks .', 'I like shoes , except trousers .', 'I do not like clerks , I prefer geneticists .', 'I like shoes , and earrings too .', 'I do not like dogs , I prefer ducks .', 'I like Zinfandel more than water .', 'I like veal more than caviar .', 'I like pork , except bacon .', 'I like necklaces , and glasses too .', 'He likes joy , except wisdom .', 'I like oaks , and trees too .', 'He trusts his senses more than rumors .', 'I like trees , but not firs .', 'I use leather , but not nylon .', 'I like blues , except jewelry .', 'I like westerns , except videogames .', 'I do not like apples , I prefer ham .', 'I like oaks more than shrubs .', 'I do not like trousers , I prefer pets .', 'I like geneticists more than scientists .', 'I like pets more than bears .', 'I do not like essays , I prefer westerns .', 'I like oaks , and bushes too .', 'I like jewelry , but not skirts .', 'I like techno , but not sports .', 'I do not like coca-cola , I prefer Merlot .', 'I like jazz , except music .', 'I do not like Zinfandel , I prefer sprite .', 'I like schools , and clerks too .', 'I do not like leather , I prefer nylon .', 'He does not like calculations , he prefers fear .', 'I like rabbits , and bobtails too .', 'He trusts his senses , but not his hearing .', 'I like furniture , but not parquet .', 'I like ducks , but not pigs .', 'He likes wisdom , except love .', 'He trusts reports , and his hearing too .', 'I like parrots , and dogs too .', 'I do not like novels , I prefer music .', 'I like crabs , but not beef .', 'He likes emotions , but not fear .', 'I like pets more than shirts .', 'I do not like pets , I prefer rabbits .', 'I like giraffes , and cats too .', 'I like lard , and broccoli too .', 'I use PVC , except glass .', 'I like beds , except furniture .', 'I do not like bobtails , I prefer parrots .', 'I like thrillers , and textbooks too .', 'I like wallpaper , except beds .', 'I do not like salmon , I prefer turkey .', 'I do not like cats , I prefer blackbirds .', 'He does not like fear , he prefers stupidity .', 'I like movies more than comedies .', 'I like westerns more than essays .', 'I do not like cats , I prefer sparrows .', 'I do not like chicken , I prefer salmon .', 'I met physicists , and janitors too .', 'I like grass , except birches .', 'I like glasses , but not socks .', 'I like ships , except Suzukis .', 'I like caretakers , but not restaurants .', 'I use cotton , except polyester .', 'I like comedies more than movies .', 'I like rings more than jewelry .', 'I like parrots , but not birds .', 'I like clothes , and trousers too .', 'I like documentaries , and essays too .', 'I like Chianti , and water too .', 'I do not like earrings , I prefer glasses .', 'I like parrots , and beagles too .', 'I use wood , but not vinyl .', 'I like crabs , and seafood too .', 'He likes fear , but not emotions .', 'I like Chardonnay more than sprite .', 'I like trees more than firs .', 'I like jewelry more than handbags .', 'I like pets , except bears .', 'I like glasses more than trousers .', 'I like parrots , except huskies .', 'I do not like essays , I prefer paintings .', 'I do not like salmon , I prefer seafood .', 'I like offices more than waiters .', 'I like scientists more than waiters .', 'He trusts his sight , but not rumors .', 'I do not like firs , I prefer grass .', 'I use nylon more than leather .', 'I like ducks more than birds .', 'I like motorcycles , and ships too .', 'I like wardrobes more than furniture .', 'I like rings , except shoes .', 'I like carrots , but not lard .', 'I like cartoons , and textbooks too .', 'I use plastic more than nylon .', 'I like hamsters , except parrots .', 'I like coca-cola , but not Chianti .', 'I like glasses , but not bracelets .', 'I like huskies more than hamsters .', 'I do not like cotton , I prefer PVC .', 'I use nylon more than glass .', 'I use cotton more than PVC .', 'I do not like bacon , I prefer fish .', 'I like rabbits , and jellyfish too .', 'I like comedies , but not essays .', 'I do not like bacon , I prefer pork .', 'I like textbooks , and thrillers too .', 'I do not like astronomers , I prefer waiters .', 'I like offices , but not clerks .', 'I like clothes more than skirts .', 'I met waiters , but not physicists .', 'I met scientists , and astronomers too .', 'I like dogs , except sparrows .', 'I like crabs , and chicken too .', 'I like Chardonnay more than coca-cola .', 'I met caretakers , and astronomers too .', 'I like waiters , except offices .', 'I like Chianti , but not wine .', 'I like birches more than bushes .', 'I like bicycles , and Suzukis too .', 'I like bushes more than oaks .', 'I do not like scientists , I prefer biologists .', 'I do not like Suzukis , I prefer trains .', 'I like clerks , but not workers .', 'I met physicists , except waiters .', 'I like videogames , except comedies .', 'I like cartoons , but not handbooks .', 'I do not like earrings , I prefer shoes .', 'I like prosciutto , and fish too .', 'I like beds , but not parquet .', 'I like fish , but not bacon .', 'He likes sadness , and emotions too .', 'I like cats more than sparrows .', 'I like jewelry , and jazz too .', 'I like bushes , and firs too .', 'I like beef more than crabs .', 'I like Chardonnay , and coca-cola too .', 'I do not like caretakers , I prefer workers .', 'I like ducks , except dogs .', 'I like enduros more than airplanes .', 'I like motorcycles , but not Harley-Davidson .', 'I like beds more than furniture .', 'I like skirts , and clothes too .', 'I like Kawasakis more than ships .', 'I like grass , and birches too .', 'I like essays , and books too .', 'I do not like dogs , I prefer sparrows .', 'I like textbooks , and paintings too .', 'I like coca-cola , and Zinfandel too .', 'I like beef more than caviar .', 'I met caretakers , and geneticists too .', 'I like trees , and firs too .', 'I like socks , and earrings too .', 'I do not like workers , I prefer professors .', 'I like documentaries , and videogames too .', 'He trusts his sight , and reconstructions too .', 'I do not like Merlot , I prefer beer .', 'He likes sadness , except emotions .', 'I do not like thrillers , I prefer textbooks .', 'I like hamsters , but not sparrows .', 'I like beef , except caviar .', 'He trusts guesses , and his taste too .', 'I like factories , but not waiters .', 'I like jazz more than food .', 'He trusts his touch , and rumors too .', 'I like earrings , and glasses too .', 'I like paintings , and tables too .', 'I like bulldogs , except dogs .', 'I like beagles , but not parrots .', 'I like Suzukis , except airplanes .', 'I like shoes , but not bracelets .', 'I do not like carrots , I prefer bacon .', 'I use plastic , but not nylon .', 'I like videogames , and documentaries too .', 'I do not like fish , I prefer lard .', 'I do not like shrubs , I prefer firs .', 'I like bacon , and carrots too .', 'I like oysters , except turkey .', 'I like caretakers , except factories .', 'I like shirts more than pets .', 'I like sparrows , but not birds .', 'He likes calculations , and love too .', 'I like parrots , but not huskies .', 'I like biologists more than caretakers .', 'I like books , and textbooks too .', 'I like handbags , but not necklaces .', 'I do not like PVC , I prefer leather .', 'He does not trust reconstructions , he prefers his taste .', 'I like cats , but not giraffes .', 'He likes fear , except emotions .', 'He does not like joy , he prefers calculations .', 'I like jellyfish , except cats .', 'I like bracelets , and glasses too .', 'I like broccoli more than prosciutto .', 'I do not like oaks , I prefer animals .', 'I like fish , and lard too .', 'I like westerns , and boardgames too .', 'I use plastic , except PVC .', 'I met waiters , but not biologists .', 'I like blackbirds , and dogs too .', 'I like tables , except cutlery .', 'I do not like firs , I prefer animals .', 'I do not like bicycles , I prefer enduros .', 'He likes fear , but not stupidity .', 'I like giraffes , except rabbits .', 'I do not like clothes , I prefer skirts .', 'I like water more than Chianti .', 'I like enduros , except airplanes .', 'I like birds more than blackbirds .', 'I like clothes , but not skirts .', 'I like glasses , except socks .', 'I like wine , but not Chianti .', 'I like Chianti , except wine .', 'I like bushes , except birches .', 'I like prosciutto more than pork .', 'I like glasses more than rings .', 'I like birds , and parrots too .', 'He likes fear , but not logic .', 'I like factories , except clerks .', 'He does not trust his senses , he prefers guesses .', 'I like Kawasakis , except motorcycles .', 'I like beagles , but not rabbits .', 'He does not like calculations , he prefers sadness .', 'I use wood more than polyester .', 'I like bacon , and fish too .', 'I like coca-cola , except Merlot .', 'I like salmon more than turkey .', 'I like novels , except music .', 'I like bobtails more than hamsters .', 'I like pets , except whales .', 'I like Merlot more than water .', 'I do not like fish , I prefer ham .', 'I like necklaces , except scarfs .', 'I like trees , except shrubs .', 'I like waiters , but not factories .', 'I do not like music , I prefer essays .', 'I do not like astronomers , I prefer clerks .', 'I like planes more than enduros .', 'I like Harley-Davidson , but not trains .', 'I like Zinfandel , and water too .', 'I like seafood , except oysters .', 'I like planes , but not Suzukis .', 'I like Chianti , except water .', 'I do not like turkey , I prefer crabs .', 'I do not like parquet , I prefer wardrobes .', 'I like Chianti , and wine too .', 'He does not like joy , he prefers stupidity .', 'I do not like comedies , I prefer textbooks .', 'I met geneticists , but not caretakers .', 'I like chicken more than salmon .', 'He trusts reports more than his hearing .', 'I like waiters more than astronomers .', 'I like birches , and shrubs too .', 'I like furniture , except chairs .', 'I like hamsters , except beagles .', 'I like scarfs , but not necklaces .', 'I like thrillers more than movies .', 'I like movies more than thrillers .', 'I like shirts , except clothes .', 'He does not like logic , he prefers joy .', 'I met caretakers , except astronomers .', 'I do not like trees , I prefer bushes .', 'I like crabs more than seafood .', 'I like hamsters more than whales .', 'I like professors more than restaurants .', 'I like birds more than parrots .', 'I do not like jewelry , I prefer shirts .', 'I do not like rabbits , I prefer jellyfish .', 'I do not like textbooks , I prefer thrillers .', 'I like workers , except restaurants .', 'I do not like pork , I prefer bacon .', 'I like carrots , except ham .', 'I like bears , but not rabbits .', 'I like rabbits more than pets .', 'He likes fear , except wisdom .', 'I like techno , and music too .', 'I like planes more than Suzukis .', 'I do not like documentaries , I prefer essays .', 'I do not like westerns , I prefer videogames .', 'I like videogames more than thrillers .', 'I like films more than handbooks .', 'I like firs , and animals too .', 'I like comedies , except boardgames .', 'I like oaks more than bushes .', 'He trusts his touch , but not his senses .', 'I like beds , but not cutlery .', 'I like pork , except broccoli .', 'I like bracelets , except scarfs .', 'I like rings , except handbags .', 'I like wine more than Chianti .', 'I like animals more than oaks .', 'I like glasses more than socks .', 'I use glass , except polyester .', 'I do not like wallpaper , I prefer tables .', 'He likes wisdom more than love .', 'He does not trust his hearing , he prefers reports .', 'I like jewelry , and socks too .', 'I do not like rabbits , I prefer pets .', 'I like jewelry , except glasses .', 'I do not like animals , I prefer firs .', 'I met biologists , but not caretakers .', 'I do not like ham , I prefer apples .', 'He likes emotions , and calculations too .', 'I like coca-cola , but not Chardonnay .', 'He likes wisdom , but not love .', 'I like blues , but not food .', 'I do not like cartoons , I prefer textbooks .', 'I like blues , and sports too .', 'I do not like parrots , I prefer cats .', 'I like grass , except firs .', 'I like bobtails more than parrots .', 'I do not like paintings , I prefer textbooks .', 'I like Zinfandel , and beer too .', 'I like music , but not rock .', 'I like jewelry , but not shirts .', 'I like planes , except enduros .', 'I met biologists , except caretakers .', 'He trusts rumors , except his sight .', 'I like oysters , but not beef .', 'I like birds , but not cats .', 'I like seafood , but not beef .', 'I do not like pines , I prefer animals .', 'I like shrubs more than birches .', 'I met scientists , and janitors too .', 'He does not like stupidity , he prefers love .', 'I like shirts more than clothes .', 'I met caretakers , but not astronomers .', 'I met waiters , and geneticists too .', 'He likes emotions , except sadness .', 'He does not like wisdom , he prefers joy .', 'I like books , and essays too .', 'I do not like movies , I prefer thrillers .', 'I like cutlery , and beds too .', 'I met janitors , and biologists too .', 'I like whales , except cats .', 'I like dogs , except hamsters .', 'I like music , except handbooks .', 'I like wallpaper , but not tables .', 'He trusts his touch , except his senses .', 'I like videogames , but not thrillers .', 'I like beer more than Chianti .', 'I like chicken , and oysters too .', 'I like movies , except videogames .', 'I like westerns more than videogames .', 'I like rabbits , but not bears .', 'I use plastic , except leather .', 'I like ships , except Kawasakis .', 'I like grass , and firs too .', 'I like necklaces , except jewelry .', 'I do not like novels , I prefer books .', 'I like firs , and trees too .', 'I like glasses , but not earrings .', 'I do not like beagles , I prefer hamsters .', 'I do not like vinyl , I prefer leather .', 'I like cats , except bulldogs .', 'I like beds , but not paintings .', 'I like parquet , and wardrobes too .', 'I do not like wine , I prefer Chianti .', 'I like thrillers , except videogames .', 'I do not like apples , I prefer lard .', 'I do not like planes , I prefer enduros .', 'He trusts his senses , and his hearing too .', 'I like grass more than firs .', 'I like carrots , and prosciutto too .', 'I do not like Suzukis , I prefer motorcycles .', 'I like skirts , except shoes .', 'I do not like birds , I prefer hamsters .', 'I like blues more than boardgames .', 'I like planes , and enduros too .', 'I like blackbirds , and cats too .', 'I use glass , but not nylon .', 'I like salmon more than beef .', 'I like furniture more than chairs .', 'I do not like books , I prefer cartoons .', 'I do not like hamsters , I prefer giraffes .', 'I like earrings , and socks too .', 'I like caviar more than seafood .', 'I like bears , but not dogs .', 'I like geneticists more than caretakers .', 'I do not like furniture , I prefer parquet .', 'He likes emotions , except joy .', 'He trusts his hearing , except his senses .', 'I like prosciutto , and carrots too .', 'I like birds , except ducks .', 'I like veal , but not caviar .', 'He trusts his hearing more than reconstructions .', 'I like music more than techno .', 'I like oaks , but not shrubs .', 'I like huskies , except hamsters .', 'He trusts rumors , and his touch too .', 'He does not trust his senses , he prefers reconstructions .', 'I do not like pets , I prefer dogs .', 'He likes love more than wisdom .', 'I like bicycles more than enduros .', 'I like broccoli , except ham .', 'I like oaks , except trees .', 'I like bobtails , but not hamsters .', 'I like pork , but not lard .', 'I like paintings , but not textbooks .', 'I like trees , and grass too .', 'I like apples , except prosciutto .', 'I do not like cats , I prefer pets .', 'He likes wisdom , except joy .', 'He likes wisdom , except sadness .', 'I like music , except techno .', 'I do not like motorcycles , I prefer airplanes .', 'I like trousers , but not earrings .', 'I like whales , and rabbits too .', 'I like bacon more than carrots .', 'I like enduros more than motorcycles .', 'I like bracelets more than handbags .', 'I do not like professors , I prefer schools .', 'I like Suzukis , except motorcycles .', 'I like birds , except cats .', 'I like music , except rock .', 'He trusts his senses more than his touch .', 'I use PVC , but not cotton .', 'I like handbags , but not bracelets .', 'I like boardgames , and documentaries too .', 'I do not like birds , I prefer parrots .', 'I like caretakers , except schools .', 'He trusts his sight more than guesses .', 'I like blues more than food .', 'I like workers , except caretakers .', 'I use polyester , except glass .', 'I like bracelets more than scarfs .', 'I like parrots more than huskies .', 'I do not like shirts , I prefer glasses .', 'He trusts rumors , except his taste .', 'I do not like plastic , I prefer polyester .', 'I do not like janitors , I prefer physicists .', 'I like glasses , and skirts too .', 'I like parrots more than cats .', 'I like Suzukis more than bicycles .', 'I like cats , but not jellyfish .', 'I like bears , and cats too .', 'I like crabs , but not chicken .', 'I do not like Chianti , I prefer wine .', 'He likes emotions , and wisdom too .', 'He trusts his senses , except reconstructions .', 'I do not like jazz , I prefer boardgames .', 'I like dogs more than beagles .', 'I like salmon , except seafood .', 'I like workers , and waiters too .', 'I like offices , except professors .', 'I like waiters more than workers .', 'I like crabs , except seafood .', 'I like bracelets , but not shoes .', 'I like crabs more than beef .', 'I do not like schools , I prefer professors .', 'I like fish more than lard .', 'He does not trust his sight , he prefers reconstructions .', 'I like books , except cartoons .', 'I like textbooks more than thrillers .', 'I use polyester , but not wood .', 'I like pets more than socks .', 'I like birds , but not parrots .', 'He does not trust his taste , he prefers his senses .', 'I like ham more than broccoli .', 'I met physicists , but not scientists .', 'I do not like caviar , I prefer chicken .', 'I like offices , and clerks too .', 'I like animals , but not oaks .', 'I like cartoons , and handbooks too .', 'I do not like coca-cola , I prefer Chianti .', 'I like Kawasakis , except trains .', 'I like parrots , except pigs .', 'I like chicken more than caviar .', 'I like shrubs , except firs .', 'I like handbags , but not rings .', 'I do not like broccoli , I prefer prosciutto .', 'I use polyester , but not leather .', 'I like caretakers , but not factories .', 'I like parrots , and birds too .', 'He trusts reports , but not his hearing .', 'I like huskies more than cats .', 'I like birds more than hamsters .', 'I like Zinfandel , except coca-cola .', 'He trusts reconstructions , but not his sight .', 'I do not like trains , I prefer Kawasakis .', 'I like sparrows , and pigs too .', 'He trusts his taste more than his senses .', 'I like cutlery , except chairs .', 'I do not like broccoli , I prefer ham .', 'I like clothes more than trousers .', 'I like caviar more than chicken .', 'He likes love , but not logic .', 'I like factories , except waiters .', 'I like seafood more than salmon .', 'I like textbooks , and documentaries too .', 'He likes sadness , and stupidity too .', 'I met astronomers , except scientists .', 'I like dogs , and blackbirds too .', 'I like enduros more than ships .', 'I like Chianti , but not water .', 'I like documentaries , and movies too .', 'I like skirts , but not glasses .', 'I like parquet , but not wardrobes .', 'I do not like cats , I prefer bulldogs .', 'I like shrubs , and firs too .', 'I like birds , but not pigs .', 'I do not like enduros , I prefer airplanes .', 'I do not like water , I prefer Merlot .', 'I like ham more than pork .', 'I like beds , and paintings too .', 'I like blues , but not jewelry .', 'I like music , except textbooks .', 'I like thrillers , except boardgames .', 'I like seafood more than chicken .', 'I like restaurants , and waiters too .', 'I like lard , except pork .', 'I like movies , except thrillers .', 'I like Zinfandel , but not wine .', 'I do not like birds , I prefer ducks .', 'I do not like Zinfandel , I prefer beer .', 'I do not like huskies , I prefer hamsters .', 'I like Chardonnay , but not beer .', 'He likes joy , and wisdom too .', 'I like cats more than whales .', 'He trusts his taste , and reports too .', 'I like bushes , and oaks too .', 'I like caviar , and veal too .', 'I like rabbits , but not beagles .', 'I like trees , except pines .', 'I do not like enduros , I prefer trains .', 'I do not like trees , I prefer grass .', 'I like bicycles , but not Suzukis .', 'He likes joy , except stupidity .', 'I like factories , but not professors .', 'I like films , and essays too .', 'I like cartoons , except novels .', 'I like dogs , except cats .', 'I like handbags , but not earrings .', 'I use leather more than PVC .', 'I use plastic , but not PVC .', 'I like earrings , except trousers .', 'I like boardgames , and blues too .', 'I do not like blackbirds , I prefer cats .', 'He likes love , but not wisdom .', 'I like chairs , except furniture .', 'I like Harley-Davidson , and motorcycles too .', 'I like thrillers , and videogames too .', 'I like tables more than paintings .', 'I like lard more than apples .', 'I do not like bracelets , I prefer handbags .', 'I like offices , and professors too .', 'I like ducks , but not hamsters .', 'I use plastic , but not glass .', 'I like clothes , except skirts .', 'I do not like rabbits , I prefer huskies .', 'I like jazz , except sports .', 'I do not like movies , I prefer textbooks .', 'He likes sadness more than emotions .', 'I do not like whales , I prefer dogs .', 'I do not like dogs , I prefer parrots .', 'He likes love , except wisdom .', 'I like sparrows , and hamsters too .', 'I like hamsters , but not pets .', 'I do not like food , I prefer jazz .', 'I do not like veal , I prefer oysters .', 'I met clerks , except astronomers .', 'I like caretakers more than geneticists .', 'I like jewelry more than scarfs .', 'I met geneticists , and clerks too .', 'He trusts his senses , except rumors .', 'I like professors , except workers .', 'I like earrings , and shoes too .', 'I like sprite more than Zinfandel .', 'He likes wisdom , and fear too .', 'I do not like scientists , I prefer janitors .', 'He trusts his sight more than his senses .', 'I like waiters , except schools .', 'I like furniture , and paintings too .', 'I like Harley-Davidson more than bicycles .', 'I like huskies more than rabbits .', 'I use plastic more than vinyl .', 'I like factories more than clerks .', 'I like caviar , except turkey .', 'I met janitors , except geneticists .', 'He does not like calculations , he prefers joy .', 'I do not like janitors , I prefer biologists .', 'I like oysters more than turkey .', 'I like earrings , but not scarfs .', 'I like socks more than glasses .', 'I like prosciutto , except apples .', 'I do not like waiters , I prefer schools .', 'He trusts reconstructions , but not his hearing .', 'I like essays , except documentaries .', 'I like shrubs , except birches .', 'I like chairs more than parquet .', 'I like waiters more than geneticists .', 'I like shirts , but not clothes .', 'I like earrings , and shirts too .', 'I do not like leather , I prefer PVC .', 'I like pines , but not grass .', 'I like giraffes , but not cats .', 'I like books , and cartoons too .', 'I like Harley-Davidson , but not airplanes .', 'I like birds , but not hamsters .', 'I use polyester more than plastic .', 'I like skirts more than pets .', 'I like glasses , except bracelets .', 'I like comedies more than boardgames .', 'I do not like bears , I prefer dogs .', 'I like caretakers , and workers too .', 'He does not like wisdom , he prefers sadness .', 'I do not like hamsters , I prefer parrots .', 'I like Merlot , but not sprite .', 'I like trains , and enduros too .', 'I met clerks , but not astronomers .', 'I do not like chairs , I prefer parquet .', 'I like thrillers more than videogames .', 'I like blackbirds , except hamsters .', 'He likes calculations , except sadness .', 'I do not like professors , I prefer offices .', 'I like films , and textbooks too .', 'I do not like caretakers , I prefer biologists .', 'I like tables , except wallpaper .', 'I like sports , but not jazz .', 'I like turkey , except oysters .', 'I do not like pets , I prefer cats .', 'He trusts his senses , except his taste .', 'I like waiters , except workers .', 'I use plastic , except cotton .', 'I do not like sprite , I prefer Chardonnay .', 'I do not like sports , I prefer blues .', 'I use cotton , and nylon too .', 'I like earrings more than shoes .', 'I like Merlot , but not water .', 'I use cotton more than polyester .', 'He trusts reports , but not his taste .', 'I like beds more than parquet .', 'I like factories more than waiters .', 'I like bobtails more than cats .', 'I like hamsters , and beagles too .', 'I like chairs , but not furniture .', 'I like apples , except ham .', 'I do not like skirts , I prefer earrings .', 'I do not like caretakers , I prefer schools .', 'I like birches more than grass .', 'He likes wisdom , and joy too .', 'I do not like carrots , I prefer prosciutto .', 'He does not trust reports , he prefers his taste .', 'I met waiters , and physicists too .', 'I like pork , and bacon too .', 'I like pines , and trees too .', 'He trusts his sight more than rumors .', 'I like wallpaper , and tables too .', 'He trusts his hearing , but not his senses .', 'I do not like biologists , I prefer clerks .', 'I do not like sports , I prefer rock .', 'I like whales more than hamsters .', 'I like trains more than Kawasakis .', 'I do not like salmon , I prefer veal .', 'I do not like techno , I prefer boardgames .', 'I do not like necklaces , I prefer jewelry .', 'I do not like parquet , I prefer chairs .', 'I do not like chicken , I prefer crabs .', 'I like waiters more than physicists .', 'I like beds more than wallpaper .', 'I like necklaces , and scarfs too .', 'I like Chianti , and beer too .', 'I do not like physicists , I prefer caretakers .', 'I like clerks , except restaurants .', 'I like clothes , and jewelry too .', 'I like blues , except food .', 'I met physicists , but not waiters .', 'I do not like parrots , I prefer beagles .', 'I like caretakers , and restaurants too .', 'I like cartoons , and novels too .', 'I do not like jellyfish , I prefer cats .', 'I do not like oaks , I prefer shrubs .', 'I like thrillers , and movies too .', 'I use PVC more than cotton .', 'I like dogs more than whales .', 'I like rings , and scarfs too .', 'I like enduros , and motorcycles too .', 'I met clerks , but not geneticists .', 'I like movies , but not videogames .', 'I like Merlot , and sprite too .', 'I like clerks more than astronomers .', 'I like pets , except cats .', 'I like pets , except giraffes .', 'I like cutlery , but not tables .', 'I like skirts , except jewelry .', 'I like wine more than beer .', 'I like socks , but not clothes .', 'He does not trust his touch , he prefers reconstructions .', 'I like pines , and animals too .', 'I like workers , except clerks .', 'I like clerks , except schools .', 'I do not like paintings , I prefer essays .', 'I like Chardonnay , except water .', 'I do not like veal , I prefer caviar .', 'I like bushes more than firs .', 'I like firs more than grass .', 'I like books , but not essays .', 'I like shoes , but not skirts .', 'I like glasses , but not necklaces .', 'I do not like bulldogs , I prefer hamsters .', 'I like sports , but not blues .', 'I like music , but not boardgames .', 'I like hamsters , but not parrots .', 'I do not like parquet , I prefer tables .', 'I do not like jewelry , I prefer earrings .', 'He likes sadness , except stupidity .', 'I do not like Kawasakis , I prefer ships .', 'I do not like beer , I prefer Zinfandel .', 'I like westerns more than movies .', 'I like cats , except ducks .', 'I like jellyfish , but not dogs .', 'I like ducks , except hamsters .', 'I like clothes more than glasses .', 'He trusts his touch , except reports .', 'I met astronomers , but not waiters .', 'I like bulldogs , but not cats .', 'I like water , except Chianti .', 'I like clerks , but not schools .', 'I like thrillers more than boardgames .', 'I do not like workers , I prefer offices .', 'I like dogs , and beagles too .', 'I like videogames , except documentaries .', 'He likes wisdom , but not joy .', 'I do not like trousers , I prefer glasses .', 'I like water more than Zinfandel .', 'I like shirts , but not shoes .', 'I like oysters more than beef .', 'I use glass , and vinyl too .', 'I like restaurants , except caretakers .', 'He likes emotions more than joy .', 'I do not like salmon , I prefer chicken .', 'I like sports , except blues .', 'I like ducks , and dogs too .', 'I do not like essays , I prefer thrillers .', 'I met scientists , but not astronomers .', 'I like novels , but not cartoons .', 'I do not like whales , I prefer rabbits .', 'I like huskies , and cats too .', 'I like sprite , but not Zinfandel .', 'I do not like thrillers , I prefer boardgames .', 'I like shoes , except necklaces .', 'I do not like necklaces , I prefer shoes .', 'I do not like birches , I prefer bushes .', 'I like furniture , and beds too .', 'I like pigs , and blackbirds too .', 'I like trousers , except glasses .', 'He likes stupidity , except joy .', 'I like seafood , but not salmon .', 'He does not like love , he prefers wisdom .', 'He likes emotions more than wisdom .', 'I like clothes more than pets .', 'I like novels , and paintings too .', 'He trusts his taste , and rumors too .', 'I like firs , except trees .', 'He trusts his taste more than rumors .', 'I like beagles , except dogs .', 'I like movies , and westerns too .', 'I like jazz more than sports .', 'I like Harley-Davidson , except airplanes .', 'I do not like Harley-Davidson , I prefer airplanes .', 'I like glasses more than earrings .', 'I like veal , and caviar too .', 'I like rings more than shoes .', 'I like broccoli , but not lard .', 'I like huskies , but not hamsters .', 'He trusts his taste , except rumors .', 'I like wallpaper more than wardrobes .', 'I like ducks more than hamsters .', 'I use PVC , and cotton too .', 'He likes emotions , but not wisdom .', 'I do not like blackbirds , I prefer dogs .', 'I do not like paintings , I prefer chairs .', 'I like fish , but not prosciutto .', 'I like furniture more than paintings .', 'I like pigs , but not ducks .', 'I like dogs , and bulldogs too .', 'I use PVC more than wood .', 'I like rabbits , except bears .', 'I met geneticists , except scientists .', 'I like grass , but not oaks .', 'I like techno , and sports too .', 'I like rings , except glasses .', 'I like animals , except oaks .', 'I like boardgames , except techno .', 'I like beer more than Zinfandel .', 'I like planes , and Suzukis too .', 'I like Zinfandel , except beer .', 'I like rabbits , and bulldogs too .', 'I like necklaces , but not jewelry .', 'I use plastic , but not vinyl .', 'I do not like waiters , I prefer restaurants .', 'I do not like pets , I prefer trousers .', 'I like earrings more than shirts .', 'I like beagles , and cats too .', 'I like trousers more than glasses .', 'I do not like bicycles , I prefer Harley-Davidson .', 'I do not like restaurants , I prefer clerks .', 'I like essays , and comedies too .', 'I like birches , except grass .', 'I like jellyfish more than rabbits .', 'I do not like Chardonnay , I prefer sprite .', 'I like necklaces , except glasses .', 'I met scientists , but not janitors .', 'I do not like clerks , I prefer biologists .', 'I like paintings more than essays .', 'I like trains , except Suzukis .', 'I like trees , except birches .', 'He does not trust rumors , he prefers his taste .', 'I like parrots , but not bobtails .', 'I like wine , but not sprite .', 'I do not like motorcycles , I prefer enduros .', 'I like professors , except schools .', 'I like beef , and crabs too .', 'I do not like crabs , I prefer veal .', 'I do not like ships , I prefer Harley-Davidson .', 'I like hamsters , except pets .', 'I like handbooks , and music too .', 'I like novels , but not music .', 'I like trains , and Kawasakis too .', 'I met biologists , except scientists .', 'I like earrings , except glasses .', 'I do not like glass , I prefer polyester .', 'I do not like PVC , I prefer cotton .', 'He trusts guesses , and his touch too .', 'I use wood , and polyester too .', 'He trusts his touch , and reconstructions too .', 'I like shirts , and earrings too .', 'I like jewelry , except bracelets .', 'I like ham , but not pork .', 'I like bulldogs , and cats too .', 'I like handbooks , except paintings .', 'I like tables , and parquet too .', 'I do not like videogames , I prefer thrillers .', 'I like dogs more than ducks .', 'He trusts reports , except his touch .', 'I like chairs more than cutlery .', 'I do not like earrings , I prefer skirts .', 'I like boardgames , except comedies .', 'I like clerks more than offices .', 'He likes emotions , but not calculations .', 'I like boardgames , except documentaries .', 'I like ham more than fish .', 'I do not like comedies , I prefer videogames .', 'He does not trust reports , he prefers his hearing .', 'I do not like books , I prefer textbooks .', 'I like boardgames , but not techno .', 'I like crabs , but not veal .', 'I like bulldogs , and rabbits too .', 'I met waiters , and astronomers too .', 'I like textbooks , but not paintings .', 'I like offices , but not professors .', 'I like giraffes , and hamsters too .', 'I do not like glasses , I prefer rings .', 'I like food more than blues .', 'I like fish , except ham .', 'I do not like restaurants , I prefer professors .', 'I use polyester , but not plastic .', 'I like waiters more than schools .', 'I like turkey , except salmon .', 'I like planes , and Kawasakis too .', 'I like jewelry more than socks .', 'I like music , except essays .', 'I do not like water , I prefer Chardonnay .', 'He trusts his hearing , and reports too .', 'I like chicken , except caviar .', 'I do not like animals , I prefer oaks .', 'I like chairs , and parquet too .', 'I like workers , but not factories .', 'I use leather more than polyester .', 'I like salmon , and turkey too .', 'I do not like biologists , I prefer caretakers .', 'He likes joy , except calculations .', 'I like blues , except boardgames .', 'I like boardgames , but not westerns .', 'I like schools more than clerks .', 'I like dogs , but not bulldogs .', 'I like trees more than birches .', 'He likes fear , and calculations too .', 'I like beer , except Chianti .', 'I like bobtails , except cats .', 'I use nylon more than wood .', 'I use leather , except polyester .', 'I do not like birds , I prefer pigs .', 'He trusts his senses , but not rumors .', 'I like Zinfandel , except sprite .', 'I use nylon , but not leather .', 'I like hamsters , and giraffes too .', 'I like thrillers , but not videogames .', 'I like parrots , and bobtails too .', 'I like techno , except music .', 'I like handbooks , except books .', 'I use wood more than PVC .', 'I do not like glasses , I prefer bracelets .', 'I do not like Merlot , I prefer water .', 'I like huskies more than dogs .', 'I like lard , and pork too .', 'I like chicken , except crabs .', 'I like shirts , except jewelry .', 'I use nylon more than plastic .', 'I like books more than handbooks .', 'I like ducks more than pigs .', 'He likes emotions more than stupidity .', 'I do not like essays , I prefer comedies .', 'I like workers , except offices .', 'I like dogs more than cats .', 'He likes logic more than fear .', 'I like beer , but not Merlot .', 'I like thrillers , but not textbooks .', 'He trusts his sight , but not his senses .', 'I like fish , except bacon .', 'I like skirts , but not jewelry .', 'I like huskies , and rabbits too .', 'I use glass more than vinyl .', 'He likes calculations more than sadness .', 'I use plastic more than leather .', 'I like rock , and music too .', 'I like seafood more than oysters .', 'I like turkey more than caviar .', 'He likes logic , except joy .', 'I like birds , but not dogs .', 'I like tables more than wallpaper .', 'I do not like polyester , I prefer glass .', 'I like Suzukis , and motorcycles too .', 'I do not like bicycles , I prefer Kawasakis .', 'He does not like sadness , he prefers calculations .', 'I like rabbits , except pets .', 'I like bushes , but not firs .', 'I do not like dogs , I prefer blackbirds .', 'I like bobtails , but not rabbits .', 'I like hamsters more than pets .', 'I like movies , except boardgames .', 'I use cotton , but not PVC .', 'I met geneticists , except clerks .', 'He trusts guesses , except his taste .', 'He likes logic , but not love .', 'I like Kawasakis , but not trains .', 'I like cats , but not whales .', 'I like jazz , but not music .', 'I met biologists , but not scientists .', 'I like trees , but not bushes .', 'I do not like skirts , I prefer jewelry .', 'I do not like glass , I prefer PVC .', 'I like bobtails , except dogs .', 'He trusts his hearing more than his senses .', 'I like parquet , and chairs too .', 'He likes emotions , and stupidity too .', 'I like techno , but not music .', 'I like birds more than ducks .', 'I like movies , except westerns .', 'I like Zinfandel , and wine too .', 'I do not like trees , I prefer pines .', 'I like earrings , but not shirts .', 'I like rabbits , except bobtails .', 'I like bears , except dogs .', 'I like cats , and parrots too .', 'I like workers , but not restaurants .', 'I like novels more than cartoons .', 'I like wine , and water too .', 'I like pets , and shirts too .', 'I met scientists , except waiters .', 'I like books more than music .', 'I like turkey , except caviar .', 'I like waiters , but not offices .', 'I like dogs more than bulldogs .', 'He trusts his senses , but not his taste .', 'I do not like carrots , I prefer lard .', 'I like bobtails , except hamsters .', 'I like jazz more than jewelry .', 'I do not like giraffes , I prefer dogs .', 'I like carrots , but not ham .', 'I like pork , and broccoli too .', 'I like wardrobes , except paintings .', 'I like socks more than pets .', 'I like books , except textbooks .', 'I like dogs , except blackbirds .', 'I do not like dogs , I prefer whales .', 'I do not like beagles , I prefer cats .', 'I like music , except food .', 'I like bracelets , but not glasses .', 'I do not like comedies , I prefer essays .', 'I like music , and textbooks too .', 'I do not like parrots , I prefer dogs .', 'I do not like broccoli , I prefer bacon .', 'I like beds more than paintings .', 'I like schools , but not clerks .', 'I like westerns , but not essays .', 'I like turkey , but not caviar .', 'I like workers , but not professors .', 'I use plastic , except glass .', 'I like jewelry , except shirts .', 'I like jellyfish , but not rabbits .', 'I like blues , and food too .', 'I like parrots , except cats .', 'I like rabbits , except whales .', 'I like workers , except professors .', 'I like rings , except jewelry .', 'I like boardgames more than rock .', 'I like jewelry , except trousers .', 'I like pines , except grass .', 'I like pigs , but not sparrows .', 'I do not like dogs , I prefer bears .', 'I like clerks , and factories too .', 'I like hamsters , but not jellyfish .', 'I like wine more than coca-cola .', 'I like scarfs , except necklaces .', 'I like jazz , except jewelry .', 'I do not like tables , I prefer paintings .', 'I like blues , but not boardgames .', 'I use PVC , but not glass .', 'He does not trust guesses , he prefers his touch .', 'I do not like beds , I prefer paintings .', 'I like jewelry , except earrings .', 'I use wood , except PVC .', 'I like birds , except hamsters .', 'I like skirts , but not clothes .', 'I like oysters , but not seafood .', 'I do not like fish , I prefer prosciutto .', 'He likes stupidity more than sadness .', 'I like parquet more than wardrobes .', 'I do not like sparrows , I prefer birds .', 'I do not like bracelets , I prefer shoes .', 'I like documentaries , but not boardgames .', 'I like dogs , but not cats .', 'He trusts reconstructions , and his taste too .', 'He trusts his taste , but not reports .', 'I use polyester more than glass .', 'I do not like rock , I prefer sports .', 'I like sparrows , except pigs .', 'I like furniture , except paintings .', 'I like clerks , but not restaurants .', 'I do not like essays , I prefer books .', 'I do not like textbooks , I prefer cartoons .', 'I like wallpaper more than tables .', 'I do not like shrubs , I prefer pines .', 'I like beagles , except hamsters .', 'I like huskies , and dogs too .', 'I like essays more than films .', 'I like lard , but not carrots .', 'He trusts rumors , but not his sight .', 'I like motorcycles more than Kawasakis .', 'I like cats more than bobtails .', 'I do not like jewelry , I prefer skirts .', 'I like paintings , but not handbooks .', 'I like bacon , except carrots .', 'I like birches , and animals too .', 'I do not like boardgames , I prefer westerns .', 'I like earrings , but not jewelry .', 'I like bears more than cats .', 'I like ducks more than cats .', 'I like ships , but not Harley-Davidson .', 'He likes logic , but not fear .', 'He trusts his taste , but not guesses .', 'He trusts his taste , but not his senses .', 'I like jewelry , but not earrings .', 'I use wood , except vinyl .', 'I like comedies , except textbooks .', 'He likes joy , and calculations too .', 'I like planes , except Kawasakis .', 'I do not like rabbits , I prefer bears .', 'I met caretakers , but not physicists .', 'I do not like ducks , I prefer dogs .', 'He trusts his hearing more than reports .', 'He likes stupidity , but not joy .', 'I like crabs , and beef too .', 'I like Suzukis more than trains .', 'I like pets , except hamsters .', 'I like hamsters , except blackbirds .', 'He likes sadness more than wisdom .', 'I like Kawasakis , and motorcycles too .', 'I do not like music , I prefer textbooks .', 'I like shrubs , except pines .', 'I like bobtails more than dogs .', 'He trusts his taste , except guesses .', 'I like oysters , except beef .', 'He trusts his touch , except reconstructions .', 'I like shirts more than jewelry .', 'I like rings , but not scarfs .', 'I like jewelry , and necklaces too .', 'I like sparrows more than pigs .', 'I like parrots , but not cats .', 'I like pets , but not whales .', 'I like pigs more than ducks .', 'I like ships more than Suzukis .', 'I do not like books , I prefer paintings .', 'I like textbooks , except documentaries .', 'He trusts rumors , except his hearing .', 'I like pigs , except sparrows .', 'I do not like trains , I prefer Harley-Davidson .', 'I like sparrows more than dogs .', 'I like lard , except broccoli .', 'I like novels , and cartoons too .', 'I do not like trains , I prefer enduros .', 'I like jazz , and jewelry too .', 'I like techno , but not food .', 'I like tables , except paintings .', 'I like Suzukis , but not trains .', 'I like trees , except grass .', 'I use plastic , but not cotton .', 'I like rings , but not handbags .', 'I met physicists , but not janitors .', 'I like offices more than professors .', 'I like blackbirds , and birds too .', 'I like cats more than beagles .', 'I like Suzukis , but not ships .', 'He does not trust his taste , he prefers reconstructions .', 'I like bobtails , and parrots too .', 'I do not like firs , I prefer bushes .', 'I do not like beer , I prefer Merlot .', 'I like wardrobes more than paintings .', 'I do not like documentaries , I prefer boardgames .', 'I like ham , but not broccoli .', 'He does not like logic , he prefers fear .', 'I like rings , and glasses too .', 'I like dogs more than pets .', 'I met waiters , except geneticists .', 'I like trousers , but not jewelry .', 'I like ducks , but not dogs .', 'I do not like trains , I prefer Suzukis .', 'I do not like seafood , I prefer crabs .', 'I like dogs , and jellyfish too .', 'He trusts his taste , and guesses too .', 'I like tables , but not parquet .', 'I like bacon , but not carrots .', 'He trusts reconstructions more than his hearing .', 'I like handbags , and necklaces too .', 'I like rings , but not shoes .', 'He does not trust his hearing , he prefers his senses .', 'I like ships , but not Suzukis .', 'I like cats more than huskies .', 'He likes stupidity , but not sadness .', 'I like novels more than books .', 'I like parrots more than pigs .', 'I do not like birds , I prefer sparrows .', 'I like caretakers , but not offices .', 'I like jewelry more than shoes .', 'I like clothes , except trousers .', 'I like trains , but not Harley-Davidson .', 'I like jewelry , and handbags too .', 'I like pork more than bacon .', 'He does not like emotions , he prefers stupidity .', 'He likes emotions more than love .', 'I use cotton , but not polyester .', 'I like textbooks , except cartoons .', 'I like beds , except wallpaper .', 'I like cats , but not sparrows .', 'I like shrubs , and pines too .', 'I like food , and blues too .', 'I like cats , except jellyfish .', 'I like textbooks , and westerns too .', 'I like clothes more than shirts .', 'I do not like boardgames , I prefer blues .', 'He does not like wisdom , he prefers love .', 'I like essays , except cartoons .', 'I like waiters , and workers too .', 'I like jazz , but not boardgames .', 'I do not like parquet , I prefer beds .', 'I like scarfs , except rings .', 'I like jewelry , but not handbags .', 'I met caretakers , but not geneticists .', 'I like hamsters , and parrots too .', 'I like salmon , but not turkey .', 'I do not like sparrows , I prefer cats .', 'I do not like beer , I prefer Chardonnay .', 'He likes logic , except fear .', 'I met geneticists , but not scientists .', 'I like bushes , and pines too .', 'I like food , but not rock .', 'I like enduros , and ships too .', 'I met scientists , and clerks too .', 'I like broccoli , except lard .', 'I do not like chairs , I prefer paintings .', 'He trusts his senses , except his touch .', 'I like clothes more than jewelry .', 'I like birches , but not grass .', 'I do not like wine , I prefer coca-cola .', 'I like jellyfish , and hamsters too .', 'I like coca-cola , but not Merlot .', 'I like movies , but not westerns .', 'I like essays more than books .', 'I do not like comedies , I prefer boardgames .', 'I like bracelets , and jewelry too .', 'I like paintings , but not essays .', 'I like comedies , except essays .', 'I like hamsters more than beagles .', 'I like enduros , but not bicycles .', 'I like novels , and books too .', 'I like furniture , but not cutlery .', 'I like salmon more than seafood .', 'I like books , and novels too .', 'I do not like bushes , I prefer pines .', 'I like textbooks more than cartoons .', 'I like pigs , and sparrows too .', 'I do not like plastic , I prefer cotton .', 'I like water , but not Merlot .', 'I like cartoons , except essays .', 'I met scientists , except clerks .', 'I like sparrows , and dogs too .', 'I use leather , but not vinyl .', 'I like documentaries , except essays .', 'I like glasses , and earrings too .', 'I like Chianti , and sprite too .', 'I like textbooks more than paintings .', 'I like dogs , but not rabbits .', 'He likes love more than stupidity .', 'I like films , but not novels .', 'I like physicists more than clerks .', 'I like clothes , except glasses .', 'I like books , but not novels .', 'I use PVC , and wood too .', 'I do not like physicists , I prefer waiters .', 'I do not like essays , I prefer music .', 'I like hamsters , except jellyfish .', 'I use vinyl more than leather .', 'I like movies , but not essays .', 'I do not like pigs , I prefer ducks .', 'He likes love , and stupidity too .', 'I like bracelets , and handbags too .', 'I do not like beagles , I prefer parrots .', 'I like techno , except jewelry .', 'I like necklaces , but not shoes .', 'I met waiters , except astronomers .', 'I do not like oaks , I prefer bushes .', 'He likes calculations , but not fear .', 'I like seafood , but not oysters .', 'I met scientists , except geneticists .', 'I like crabs more than veal .', 'I like westerns , except textbooks .', 'I like fish , except lard .', 'I do not like waiters , I prefer biologists .', 'I use nylon , but not glass .', 'I like blues , but not music .', 'I like essays , and westerns too .', 'I like paintings , and essays too .', 'I like factories , and professors too .', 'I like broccoli , but not ham .', 'I like workers , except factories .', 'I like bicycles , but not Harley-Davidson .', 'He likes stupidity , and love too .', 'I like planes , except Suzukis .', 'He likes emotions , except love .', 'I do not like shoes , I prefer necklaces .', 'I like beef , but not caviar .', 'I like pets , but not giraffes .', 'I like seafood , but not chicken .', 'I like dogs , except ducks .', 'I like crabs more than chicken .', 'I like videogames , and comedies too .', 'I like professors , and factories too .', 'I met scientists , but not clerks .', 'I do not like shoes , I prefer rings .', 'I like bushes , but not oaks .', 'I like novels , except books .', 'I like trees , but not grass .', 'I like beagles more than cats .', 'I like waiters , and schools too .', 'I like bulldogs more than rabbits .', 'I like professors , and workers too .', 'I like ham , and broccoli too .', 'I met biologists , but not clerks .', 'I like bushes , and birches too .', 'I like hamsters , except bulldogs .', 'I do not like leather , I prefer polyester .', 'I like bracelets , except shoes .', 'I like ham , and fish too .', 'I like paintings more than textbooks .', 'I like Kawasakis , but not airplanes .', 'I like oysters , and veal too .', 'I like jewelry , and rings too .', 'I like glasses , and socks too .', 'I like textbooks , but not films .', 'I like clothes , and earrings too .', 'I like earrings more than trousers .', 'I like professors , except restaurants .', 'I like Kawasakis , and airplanes too .', 'I do not like offices , I prefer professors .', 'He trusts his touch , and guesses too .', 'I like caretakers more than schools .', 'I do not like caviar , I prefer turkey .', 'I like chairs , but not paintings .', 'I use nylon , except glass .', 'I do not like thrillers , I prefer essays .', 'I like pork , but not bacon .', 'I like physicists more than waiters .', 'I like furniture , except wallpaper .', 'I do not like trousers , I prefer earrings .', 'I like biologists more than scientists .', 'I like seafood , and salmon too .', 'I like wardrobes , except parquet .', 'I like boardgames , except blues .', 'I like hamsters , except whales .', 'I like books , but not music .', 'I do not like cartoons , I prefer essays .', 'I do not like beef , I prefer salmon .', 'I use plastic , and wood too .', 'I like cutlery , but not wardrobes .', 'I like firs more than shrubs .', 'I do not like Harley-Davidson , I prefer ships .', 'I like boardgames more than jazz .', 'I do not like schools , I prefer waiters .', 'I do not like cutlery , I prefer tables .', 'I like jellyfish , except hamsters .', 'I like handbooks , and cartoons too .', 'I do not like vinyl , I prefer glass .', 'I do not like glasses , I prefer socks .', 'He trusts his taste , and his senses too .', 'I like scarfs more than bracelets .', 'I do not like jewelry , I prefer bracelets .', 'I like chicken , except salmon .', 'I use wood , and vinyl too .', 'I like lard , except fish .', 'I like restaurants more than professors .', 'I like hamsters , except giraffes .', 'I like pets , and whales too .', 'He does not like emotions , he prefers sadness .', 'I do not like birches , I prefer grass .', 'I like handbags , and rings too .', 'I do not like grass , I prefer pines .', 'I like paintings more than tables .', 'I like broccoli , but not prosciutto .', 'I like blackbirds more than hamsters .', 'I do not like sparrows , I prefer hamsters .', 'I met janitors , but not biologists .', 'I like movies , and videogames too .', 'I like essays more than thrillers .', 'I like turkey , except crabs .', 'I like handbooks more than books .', 'He likes fear , except logic .', 'I like firs , but not animals .', 'I like food more than jazz .', 'I like sprite more than Merlot .', 'I like schools , but not professors .', 'I like lard more than carrots .', 'I do not like novels , I prefer films .', 'He likes fear , and wisdom too .', 'I like offices , but not caretakers .', 'I like dogs , except rabbits .', 'I like scarfs , except earrings .', 'I like pets , but not dogs .', 'I like water , except Chardonnay .', 'He likes stupidity , except sadness .', 'I like films , except novels .', 'I like bears more than rabbits .', 'I use nylon , except cotton .', 'I like cats more than bulldogs .', 'I like movies more than videogames .', 'I like restaurants more than waiters .', 'He trusts his hearing , and reconstructions too .', 'I use wood , and nylon too .', 'I like parrots more than bobtails .', 'I like boardgames more than comedies .', 'I like essays , but not thrillers .', 'I like beer , but not Chianti .', 'I do not like food , I prefer techno .', 'I like books more than textbooks .', 'He likes fear , and stupidity too .', 'I like trains , but not Suzukis .', 'He trusts his touch , except guesses .', 'I like handbooks more than films .', 'I like ducks , except cats .', 'I use plastic , and vinyl too .', 'I like jewelry , and rock too .', 'I like giraffes more than rabbits .', 'I like paintings , but not tables .', 'I like professors , and offices too .', 'I met caretakers , except biologists .', 'I like schools , and caretakers too .', 'I like jewelry , and techno too .', 'I met clerks , and astronomers too .', 'I like jewelry , and blues too .', 'He likes joy more than emotions .', 'I met biologists , except janitors .', 'I like clerks , but not offices .', 'I do not like PVC , I prefer glass .', 'I like bracelets , but not handbags .', 'I met biologists , but not janitors .', 'I like parquet , and beds too .', 'I like glasses , except skirts .', 'I like seafood more than beef .', 'I like pets , but not hamsters .', 'I like beagles more than rabbits .', 'He likes wisdom , and sadness too .', 'I like clothes more than socks .', 'I like pets , except rabbits .', 'I like lard more than pork .', 'I do not like polyester , I prefer leather .', 'I use plastic , but not leather .', 'He trusts his touch more than reconstructions .', 'I like beer , except Chardonnay .', 'I like Suzukis , except bicycles .', 'I like clothes , and glasses too .', 'I like fish , and ham too .', 'He trusts his sight , and guesses too .', 'I like shrubs , but not firs .', 'I like sports , but not rock .', 'I like handbags , and earrings too .', 'I like jellyfish , and cats too .', 'I do not like techno , I prefer food .', 'I do not like sprite , I prefer Merlot .', 'I like films , and novels too .', 'I do not like wood , I prefer PVC .', 'I like pork , but not fish .', 'I like skirts more than glasses .', 'I do not like bobtails , I prefer dogs .', 'I do not like bracelets , I prefer jewelry .', 'I met biologists , except waiters .', 'He trusts rumors more than his taste .', 'I like jewelry , and trousers too .', 'I met astronomers , and scientists too .', 'I like pets , but not rabbits .', 'I like apples , and lard too .', 'I do not like turkey , I prefer oysters .', 'I like enduros , and airplanes too .', 'I like pets more than whales .', 'I met scientists , and biologists too .', 'He likes sadness , and calculations too .', 'I met astronomers , but not janitors .', 'He trusts his taste , but not rumors .', 'I like parrots , and hamsters too .', 'I like ham , except pork .', 'He does not trust his sight , he prefers his senses .', 'I do not like water , I prefer Zinfandel .', 'I like trousers , except earrings .', 'I like jazz , but not jewelry .', 'I do not like lard , I prefer pork .', 'I do not like techno , I prefer sports .', 'I like handbags more than rings .', 'I like pork , but not apples .', 'I use leather , except nylon .', 'I do not like necklaces , I prefer scarfs .', 'I like rock , except sports .', 'I use glass more than polyester .', 'I like birches , and grass too .', 'I like cats more than giraffes .', 'I like skirts , and earrings too .', 'I like huskies , and parrots too .', 'I like books , but not textbooks .', 'I do not like parrots , I prefer huskies .', 'I like coca-cola more than Zinfandel .', 'I like books , and music too .', 'I like prosciutto , but not fish .', 'I like enduros , but not trains .', 'I like broccoli , and ham too .', 'I like sprite , except Merlot .', 'I like socks , but not earrings .', 'I like Suzukis more than ships .', 'I like firs , but not shrubs .', 'I do not like books , I prefer films .', 'I like clerks , and offices too .', 'I like chairs , and cutlery too .', 'I do not like janitors , I prefer geneticists .', 'I like parrots , except beagles .', 'I like schools , but not waiters .', 'I like paintings , and beds too .', 'I like jewelry more than necklaces .', 'I like bracelets , except jewelry .', 'I like oaks , but not trees .', 'He trusts his touch more than rumors .', 'I like ships , and Suzukis too .', 'I do not like seafood , I prefer veal .', 'I like chicken , and caviar too .', 'I like documentaries , but not textbooks .', 'I like pets more than cats .', 'I like blues , except sports .', 'I like westerns , but not boardgames .', 'I like chairs , and furniture too .', 'I like textbooks , except thrillers .', 'I like bracelets , but not scarfs .', 'I like handbooks , and paintings too .', 'I like cutlery , and wardrobes too .', 'I like coca-cola more than Chianti .', 'I like cutlery , except beds .', 'I do not like oysters , I prefer veal .', 'I like Merlot , except coca-cola .', 'I do not like dogs , I prefer bobtails .', 'I like jewelry , except scarfs .', 'I do not like huskies , I prefer parrots .', 'I like beagles , except parrots .', 'I like shrubs , but not oaks .', 'I met geneticists , and waiters too .', 'He likes wisdom more than joy .', 'He trusts rumors , but not his taste .', 'He likes love , but not stupidity .', 'I like dogs , but not bobtails .', 'I like music , but not sports .', 'I like birds , and cats too .', 'I use nylon , except plastic .', 'He does not trust rumors , he prefers his sight .', 'I like Chianti more than wine .', 'I like giraffes , and rabbits too .', 'I like dogs , and cats too .', 'I like music , but not techno .', 'I like planes , except Harley-Davidson .', 'I like wine , except Chardonnay .', 'I do not like shrubs , I prefer oaks .', 'I like boardgames , and rock too .', 'I like necklaces more than scarfs .', 'I like glasses , and trousers too .', 'I do not like schools , I prefer clerks .', 'I like bulldogs , and parrots too .', 'I like lard , but not pork .', 'I like pines , but not shrubs .', 'I like tables , and paintings too .', 'I do not like Kawasakis , I prefer airplanes .', 'I do not like cats , I prefer jellyfish .', 'I do not like clerks , I prefer restaurants .', 'I like Chianti , and coca-cola too .', 'I like Suzukis , but not airplanes .', 'I met scientists , except janitors .', 'I like bobtails more than rabbits .', 'I like ham , except broccoli .', 'I like jewelry , but not socks .', 'I like astronomers more than clerks .', 'He likes calculations , and fear too .', 'I like parquet , but not chairs .', 'I like textbooks more than books .', 'I like sports , and rock too .', 'I like sprite , except Zinfandel .', 'I like jellyfish , except dogs .', 'I like sparrows more than hamsters .', 'I like chicken more than oysters .', 'I like clothes , except shoes .', 'He likes fear , and logic too .', 'He trusts guesses , except his touch .', 'I like birches , and bushes too .', 'I like carrots , but not prosciutto .', 'He trusts his sight more than reports .', 'I like wardrobes , and wallpaper too .', 'I like comedies , but not textbooks .', 'He trusts his senses , but not guesses .', 'I do not like wallpaper , I prefer beds .', 'I like dogs , and whales too .', 'I like novels , except paintings .', 'I do not like cutlery , I prefer chairs .', 'I like cats more than parrots .', 'I like beef , but not salmon .', 'I like pets , except dogs .', 'I like wine , but not Zinfandel .', 'He trusts reports , except his hearing .', 'I do not like biologists , I prefer janitors .', 'I like oysters , but not turkey .', 'I like hamsters , and blackbirds too .', 'He does not like sadness , he prefers logic .', 'I like Suzukis , and ships too .', 'I like parrots , but not beagles .', 'I like dogs , but not ducks .', 'I use wood , but not nylon .', 'I like birds , and dogs too .', 'I like beer more than Merlot .', 'I like bicycles more than Harley-Davidson .', 'I like salmon , but not beef .', 'I like parrots more than bulldogs .', 'I do not like wood , I prefer polyester .', 'I like firs , and grass too .', 'I like birds , except dogs .', 'I like water , except Zinfandel .', 'I do not like boardgames , I prefer jazz .', 'I like books , but not cartoons .', 'He does not like logic , he prefers sadness .', 'I like workers more than clerks .', 'I do not like geneticists , I prefer clerks .', 'I do not like earrings , I prefer shirts .', 'I met physicists , and clerks too .', 'I do not like enduros , I prefer bicycles .', 'I like jazz , and food too .', 'I do not like ham , I prefer carrots .', 'I do not like ham , I prefer fish .', 'I do not like lard , I prefer fish .', 'He likes joy , and emotions too .', 'I like handbags more than necklaces .', 'I like beer , except Zinfandel .', 'I do not like astronomers , I prefer caretakers .', 'I like textbooks , and cartoons too .', 'I like beer more than Chardonnay .', 'I use vinyl , except cotton .', 'I like trousers , except shoes .', 'I do not like clerks , I prefer workers .', 'I like blackbirds , except pigs .', 'I do not like shrubs , I prefer birches .', 'I do not like Chardonnay , I prefer wine .', 'I like movies , but not thrillers .', 'I like dogs , and ducks too .', 'I like bears , except hamsters .', 'He does not trust guesses , he prefers his taste .', 'I like Suzukis , and airplanes too .', 'I do not like jewelry , I prefer scarfs .', 'I like documentaries , except movies .', 'I like glasses , except trousers .', 'I like carrots , and lard too .', 'I like Kawasakis more than motorcycles .', 'I like rabbits , and pets too .', 'I like shoes more than rings .', 'I like seafood , except caviar .', 'He does not trust rumors , he prefers his touch .', 'I like salmon , except veal .', 'He trusts guesses more than his sight .', 'I like shoes , but not shirts .', 'I like animals , but not firs .', 'I like huskies , but not dogs .', 'I like jewelry , except jazz .', 'I met janitors , except biologists .', 'I like music , and jazz too .', 'I like jewelry , but not necklaces .', 'I like seafood , and crabs too .', 'I do not like films , I prefer textbooks .', 'I like Kawasakis more than airplanes .', 'I use plastic , but not polyester .', 'I like workers , except schools .', 'He trusts his sight , but not guesses .', 'I do not like seafood , I prefer turkey .', 'I like schools , and waiters too .', 'I do not like Merlot , I prefer sprite .', 'He likes fear , but not wisdom .', 'I like chicken more than crabs .', 'I like clerks , except factories .', 'I use wood , but not polyester .', 'I like motorcycles , except Harley-Davidson .', 'I met astronomers , except janitors .', 'He does not trust reports , he prefers his touch .', 'He likes sadness , but not stupidity .', 'I like earrings , but not trousers .', 'I like skirts , but not earrings .', 'He trusts his hearing , and guesses too .', 'I do not like pets , I prefer shirts .', 'I like bracelets , except handbags .', 'I do not like books , I prefer handbooks .', 'I like water , and Zinfandel too .', 'I like wardrobes , except furniture .', 'I use glass , except PVC .', 'I do not like vinyl , I prefer cotton .', 'I like shoes , except rings .', 'I like movies , and boardgames too .', 'He likes calculations , except joy .', 'I like trees , except bushes .', 'I like birches more than trees .', 'I like textbooks , except music .', 'I do not like handbooks , I prefer music .', 'I like shoes , but not socks .', 'I do not like Merlot , I prefer coca-cola .', 'I do not like clothes , I prefer trousers .', 'I do not like cats , I prefer bobtails .', 'I do not like boardgames , I prefer documentaries .', 'I like restaurants , but not professors .', 'I like tables , but not paintings .', 'I like water , but not Chianti .', 'I do not like pets , I prefer jellyfish .', 'I like workers more than professors .', 'I like textbooks , except westerns .', 'I like coca-cola more than Chardonnay .', 'I do not like textbooks , I prefer documentaries .', 'He trusts his hearing , except reports .', 'I like blues , and boardgames too .', 'I like parquet more than tables .', 'I like jewelry more than rock .', 'I like pork , except ham .', 'I like music , and blues too .', 'I do not like janitors , I prefer astronomers .', 'I like films , but not textbooks .', 'I use nylon , and leather too .', 'He likes calculations , and sadness too .', 'He does not like logic , he prefers love .', 'I like jewelry , but not shoes .', 'I like documentaries , but not videogames .', 'I like birches , but not shrubs .', 'I like dogs , and huskies too .', 'I like firs , except bushes .', 'I like shrubs more than firs .', 'I like music , and sports too .', 'I like crabs , except beef .', 'I like enduros , except ships .', 'I like motorcycles more than enduros .', 'I do not like shirts , I prefer pets .', 'He trusts his senses , and rumors too .', 'I like professors more than workers .', 'I like beef , and salmon too .', 'I like skirts more than jewelry .', 'I like whales , and dogs too .', 'I like shrubs more than oaks .', 'I like pets , and skirts too .', 'I like movies , except essays .', 'I use vinyl , and glass too .', 'I like music more than blues .', 'I do not like food , I prefer rock .', 'I like beds , except parquet .', 'I do not like wine , I prefer Chardonnay .', 'I like comedies more than textbooks .', 'I do not like Chardonnay , I prefer beer .', 'I like bears more than dogs .', 'I do not like skirts , I prefer clothes .', 'I like birches , except bushes .', 'I do not like hamsters , I prefer sparrows .', 'I like restaurants , and professors too .', 'I like thrillers , but not movies .', 'I like waiters , except factories .', 'I use wood , except polyester .', 'I like cats , and beagles too .', 'I like pets , but not bears .', 'I like trees , and birches too .', 'I like hamsters , but not huskies .', 'I do not like videogames , I prefer westerns .', 'I like essays , and documentaries too .', 'I met physicists , and caretakers too .', 'He trusts reports , and his taste too .', 'I like cats , and sparrows too .', 'He trusts his senses , and reports too .', 'I like clerks , except workers .', 'I use vinyl , except leather .', 'I like caviar , but not chicken .', 'I like broccoli more than lard .', 'I met astronomers , except clerks .', 'I like clothes , and skirts too .', 'I use polyester , and wood too .', 'I like shirts , and pets too .', 'He likes stupidity , except fear .', 'I like trees , but not birches .', 'I like broccoli , except prosciutto .', 'He trusts his hearing , and rumors too .', 'I do not like dogs , I prefer bulldogs .', 'I like Harley-Davidson , except trains .', 'I do not like leather , I prefer vinyl .', 'I like jewelry more than earrings .', 'I use cotton more than vinyl .', 'I like motorcycles more than ships .', 'I like bacon more than pork .', 'I like techno , except food .', 'I do not like prosciutto , I prefer apples .', 'I like Zinfandel more than coca-cola .', 'I like salmon , and chicken too .', 'I do not like bushes , I prefer birches .', 'I like rock more than boardgames .', 'I like techno more than jewelry .', 'I do not like plastic , I prefer PVC .', 'I like Merlot , and coca-cola too .', 'I like essays , except books .', 'I like chairs , but not parquet .', 'I like veal , but not oysters .', 'I like boardgames , except thrillers .', 'I use nylon more than cotton .', 'I like dogs , but not bears .', 'I do not like sports , I prefer jazz .', 'I like salmon , except turkey .', 'I like cats , and bulldogs too .', 'He likes love more than emotions .', 'I like earrings , except skirts .', 'I like westerns , except boardgames .', 'I met astronomers , except caretakers .', 'I like carrots more than ham .', 'I do not like Kawasakis , I prefer motorcycles .', 'I like lard more than broccoli .', 'I like schools , but not caretakers .', 'I like necklaces , but not glasses .', 'I like blackbirds , and pigs too .', 'He trusts guesses , but not his taste .', 'I like videogames more than comedies .', 'I do not like Harley-Davidson , I prefer trains .', 'I like salmon , except chicken .', 'I like bushes , except pines .', 'I like broccoli , and bacon too .', 'I like ham more than carrots .', 'I do not like veal , I prefer crabs .', 'I like caviar , and beef too .', 'He likes logic more than love .', 'He likes fear more than stupidity .', 'He trusts rumors , and his hearing too .', 'I like animals more than pines .', 'I like pork , except carrots .', 'I like Harley-Davidson , except bicycles .', 'He likes emotions , and love too .', 'I do not like pines , I prefer shrubs .', 'I like wine , and Chardonnay too .', 'He likes calculations , except love .', 'I use wood , but not PVC .', 'I like westerns , except essays .', 'I like comedies , except movies .', 'He likes joy , but not logic .', 'I like ships , and Kawasakis too .', 'I like parquet more than chairs .', 'I like animals , and firs too .', 'I like ducks more than dogs .', 'I like documentaries , and boardgames too .', 'I met astronomers , and caretakers too .', 'I like jellyfish more than hamsters .', 'I like hamsters , and huskies too .', 'I do not like plastic , I prefer wood .', 'I like shoes , and rings too .', 'I like blues more than jewelry .', 'I use glass , except nylon .', 'I like caretakers , and offices too .', 'I do not like hamsters , I prefer blackbirds .', 'I like cats , but not bobtails .', 'I like essays , but not films .', 'I like music more than textbooks .', 'I do not like tables , I prefer cutlery .', 'I do not like pets , I prefer skirts .', 'He likes emotions , and logic too .', 'I like bacon , and broccoli too .', 'I like oysters , except chicken .', 'I like dogs , except bears .', 'I met janitors , except astronomers .', 'I like huskies , except dogs .', 'I do not like glass , I prefer nylon .', 'I like enduros , and trains too .', 'I do not like pork , I prefer ham .', 'He likes emotions more than logic .', 'I like bacon , but not broccoli .', 'I do not like caretakers , I prefer geneticists .', 'I like textbooks , and music too .', 'I like grass , except oaks .', 'I like scarfs , except bracelets .', 'I like professors , but not offices .', 'I like prosciutto , except fish .', 'I like Chianti more than coca-cola .', 'I like sports , and techno too .', 'I do not like earrings , I prefer scarfs .', 'I do not like parrots , I prefer hamsters .', 'I like shirts , but not jewelry .', 'I use polyester more than cotton .', 'I do not like huskies , I prefer cats .', 'I like giraffes , but not rabbits .', 'I like seafood , but not veal .', 'I like wine , but not Merlot .', 'I use polyester , and plastic too .', 'I like parrots , and huskies too .', 'I like apples , and bacon too .', 'I do not like skirts , I prefer glasses .', 'I like documentaries , except videogames .', 'I like beer , but not Chardonnay .', 'I like movies , and thrillers too .', 'I use cotton more than nylon .', 'I like Harley-Davidson more than airplanes .', 'I met clerks , and geneticists too .', 'I like wallpaper more than beds .', 'I do not like hamsters , I prefer ducks .', 'I like boardgames , but not comedies .', 'I like caviar , and turkey too .', 'I like socks , and glasses too .', 'I like Chianti , but not sprite .', 'I like waiters more than factories .', 'I like birds , and ducks too .', 'I do not like documentaries , I prefer movies .', 'I met scientists , except biologists .', 'I like sparrows , except dogs .', 'I like broccoli , and lard too .', 'He trusts guesses more than his hearing .', 'I like physicists more than scientists .', 'I like bushes , except firs .', 'I like socks , except clothes .', 'He likes calculations , but not sadness .', 'I like chairs , but not wallpaper .', 'I like textbooks more than documentaries .', 'I do not like techno , I prefer jewelry .', 'I like wallpaper , except wardrobes .', 'I like tables more than furniture .', 'I like documentaries , but not essays .', 'I like furniture , and tables too .', 'He likes stupidity , and fear too .', 'I like hamsters more than sparrows .', 'I like caretakers , except offices .', 'I do not like lard , I prefer apples .', 'I like wardrobes , but not furniture .', 'I use cotton , except vinyl .', 'I like pork , except lard .', 'I like videogames , but not westerns .', 'I like clothes , and socks too .', 'I met biologists , except clerks .', 'He trusts rumors , but not his hearing .', 'I do not like Zinfandel , I prefer wine .', 'I like cats , except blackbirds .', 'I like textbooks , and films too .', 'I like ships more than Harley-Davidson .', 'He likes sadness , but not emotions .', 'I like waiters , but not schools .', 'I like essays , except music .', 'I like necklaces , but not handbags .', 'I like birches more than animals .', 'I like birches , except animals .', 'He trusts reports more than his sight .', 'I like music , and rock too .', 'He likes sadness more than stupidity .', 'I do not like oysters , I prefer beef .', 'I do not like textbooks , I prefer books .', 'I like jewelry , except socks .', 'I like dogs more than sparrows .', 'I do not like offices , I prefer clerks .', 'I like documentaries , but not movies .', 'I like jewelry , but not bracelets .', 'I do not like prosciutto , I prefer fish .', 'I like Harley-Davidson , but not bicycles .', 'I like carrots more than prosciutto .', 'I use polyester , and cotton too .', 'He likes wisdom , but not fear .', 'I do not like essays , I prefer films .', 'I like rabbits more than jellyfish .', 'I do not like blues , I prefer music .', 'I like workers , but not offices .', 'I like water more than Merlot .', 'I like music , but not textbooks .', 'I like pines , but not trees .', 'He does not trust his senses , he prefers reports .', 'I do not like wardrobes , I prefer cutlery .', 'I use PVC more than leather .', 'I met janitors , but not geneticists .', 'I do not like paintings , I prefer wardrobes .', 'I do not like ducks , I prefer birds .', 'I use wood more than nylon .', 'I do not like trees , I prefer oaks .', 'I do not like astronomers , I prefer janitors .', 'I like crabs , except turkey .', 'He likes logic more than joy .', 'I do not like blackbirds , I prefer hamsters .', 'I do not like oysters , I prefer turkey .', 'He trusts his touch , but not rumors .', 'I like apples , but not lard .', 'I use plastic , except vinyl .', 'He likes wisdom , and love too .', 'I do not like whales , I prefer hamsters .', 'I like pines , but not animals .', 'I like dogs more than bobtails .', 'I like birds , except sparrows .', 'I like skirts , and jewelry too .', 'He trusts his senses , and his taste too .', 'I met astronomers , and waiters too .', 'I like water , and Chardonnay too .', 'I like wallpaper , but not beds .', 'I like grass , and oaks too .', 'He likes love , except calculations .', 'I do not like caretakers , I prefer physicists .', 'I like huskies , but not parrots .', 'I like trousers , and pets too .', 'I like sports , and blues too .', 'I like comedies , but not boardgames .', 'I like handbooks more than cartoons .', 'I like pets more than hamsters .', 'I like techno more than music .', 'I like professors , and schools too .', 'I like cartoons , and essays too .', 'I like blackbirds more than dogs .', 'I like chairs , except wallpaper .', 'I like bobtails , except parrots .', 'I do not like movies , I prefer comedies .', 'I like ham , and pork too .', 'I like wardrobes , but not parquet .', 'I like beagles , and rabbits too .', 'He likes emotions , and joy too .', 'I like scarfs , but not earrings .', 'I like clothes , but not jewelry .', 'I like crabs , except veal .', 'I like rabbits , but not huskies .', 'I like pigs , and parrots too .', 'I like biologists more than janitors .', 'I do not like pets , I prefer hamsters .', 'I like books , and handbooks too .', 'I do not like cats , I prefer ducks .', 'I like rabbits more than bobtails .', 'I like beagles more than hamsters .', 'I like restaurants , but not clerks .', 'I do not like pines , I prefer bushes .', 'I do not like motorcycles , I prefer Kawasakis .', 'I like clerks more than physicists .', 'I do not like glasses , I prefer earrings .', 'I do not like bobtails , I prefer hamsters .', 'I like paintings , but not wardrobes .', 'I like cats , except parrots .', 'I like handbooks , except music .', 'I like workers more than offices .', 'I like astronomers more than caretakers .', 'I like rabbits , except bulldogs .', 'I use plastic more than polyester .', 'I like wardrobes , but not paintings .', 'I do not like sprite , I prefer Chianti .', 'I like pines more than grass .', 'I like lard , and fish too .', 'I like paintings , except essays .', 'I like food , but not jazz .', 'I like wardrobes more than parquet .', 'I like parrots , but not hamsters .', 'I like blues , but not sports .', 'I do not like ships , I prefer Suzukis .', 'I like trees , but not pines .', 'I like boardgames , but not rock .', 'I like paintings , but not chairs .', 'I like rabbits , but not giraffes .', 'I do not like music , I prefer jewelry .', 'I use PVC , but not wood .', 'I like shoes , except shirts .', 'I like westerns , and videogames too .', 'I like hamsters more than giraffes .', 'I like skirts , and pets too .', 'I like chairs more than paintings .', 'I like rabbits , but not bobtails .', 'He likes stupidity more than fear .', 'I do not like cats , I prefer beagles .', 'I like apples more than prosciutto .', 'I like salmon , and veal too .', 'I use polyester , but not glass .', 'He does not trust his touch , he prefers rumors .', 'I like grass , but not pines .', 'I do not like jewelry , I prefer blues .', 'I do not like movies , I prefer boardgames .', 'I like bacon more than fish .', 'I like sparrows , except cats .', 'I like cutlery more than wardrobes .', 'I like enduros , except trains .', 'I like wine , but not water .', 'I like music more than jazz .', 'I like scientists more than astronomers .', 'I use plastic more than PVC .', 'He does not trust his senses , he prefers his sight .', 'I do not like motorcycles , I prefer Harley-Davidson .', 'I do not like water , I prefer Chianti .', 'I like animals , except birches .', 'I like Merlot more than coca-cola .', 'I like planes , but not Harley-Davidson .', 'I like motorcycles , and enduros too .', 'I like giraffes , except cats .', 'I like planes , but not enduros .', 'I like paintings , but not novels .', 'I like bacon more than broccoli .', 'I do not like oysters , I prefer seafood .', 'I like novels , and music too .', 'He trusts his sight , except his senses .', 'I like skirts more than clothes .', 'I like caviar , and seafood too .', 'I like jewelry , except shoes .', 'I like earrings , and trousers too .', 'I like jewelry , but not rock .', 'I do not like caretakers , I prefer factories .', 'I like jazz , and sports too .', 'I like beef , and caviar too .', 'I do not like giraffes , I prefer rabbits .', 'I do not like firs , I prefer shrubs .', 'I like glasses , except rings .', 'I like westerns , and essays too .', 'I like oaks , but not animals .', 'I like birds more than cats .', 'I do not like trees , I prefer firs .', 'I like cartoons , but not essays .', 'I use cotton , and PVC too .', 'I like rock , and boardgames too .', 'I like enduros , except motorcycles .', 'He trusts his senses , except his hearing .', 'I do not like skirts , I prefer pets .', 'I like ham , but not fish .', 'I like restaurants , and clerks too .', 'I like jewelry more than skirts .', 'I like seafood , and veal too .', 'I like pets , and jellyfish too .', 'I like scientists more than geneticists .', 'I do not like seafood , I prefer salmon .', 'I do not like documentaries , I prefer videogames .', 'I like blackbirds , but not hamsters .', 'I like thrillers , except essays .', 'I like glasses , but not shirts .', 'I do not like rings , I prefer glasses .', 'I like huskies more than parrots .', 'He likes emotions , except logic .', 'I like furniture more than tables .', 'I like socks , but not jewelry .', 'I like dogs , except jellyfish .', 'I like oysters , but not chicken .', 'I like Merlot , and beer too .', 'I like sprite , and Zinfandel too .', 'I like cats , except beagles .', 'I like blues more than sports .', 'He trusts rumors , except his touch .', 'I like birds , but not sparrows .', 'I do not like scientists , I prefer geneticists .', 'I use leather more than vinyl .', 'I like films more than essays .', 'I like bulldogs , except parrots .', 'I like Kawasakis , except ships .', 'I like beagles , except cats .', 'I like cats , and bobtails too .', 'I do not like paintings , I prefer tables .', 'I like oaks more than animals .', 'I do not like Chianti , I prefer coca-cola .', 'I like salmon , except beef .', 'He likes sadness more than logic .', 'I like movies , but not comedies .', 'I like glasses , except shirts .', 'I like sports more than blues .', 'I like ships more than Kawasakis .', 'I like clerks , and schools too .', 'I like parquet , except chairs .', 'He does not trust reconstructions , he prefers his hearing .', 'I like movies more than documentaries .', 'I like motorcycles , except Kawasakis .', 'I like Harley-Davidson , and trains too .', 'I do not like waiters , I prefer astronomers .', 'I like Kawasakis more than trains .', 'He trusts reconstructions , except his touch .', 'I do not like socks , I prefer pets .', 'I met waiters , except biologists .', 'I like cutlery more than beds .', 'I like music , but not jewelry .', 'I met biologists , and caretakers too .', 'I like bulldogs more than cats .', 'I like books , except music .', 'I like wardrobes , and furniture too .', 'I like animals , except pines .', 'I like beagles , but not dogs .', 'I do not like Zinfandel , I prefer water .', 'I like boardgames more than thrillers .', 'He trusts his touch more than guesses .', 'I like broccoli , except bacon .', 'I like lard more than fish .', 'I like jewelry , and skirts too .', 'I like bears , but not hamsters .', 'I like rock , except jewelry .', 'I like beds , and cutlery too .', 'I do not like scarfs , I prefer rings .', 'I do not like crabs , I prefer beef .', 'I use plastic , but not wood .', 'I like wardrobes more than wallpaper .', 'I like giraffes more than cats .', 'I like textbooks , except films .', 'I met scientists , but not physicists .', 'I like prosciutto more than fish .', 'I like ships , but not Kawasakis .', 'I do not like music , I prefer techno .', 'I like essays more than music .', 'I use cotton , and vinyl too .', 'He likes love , and calculations too .', 'I like parquet more than beds .', 'I do not like rabbits , I prefer whales .', 'I do not like factories , I prefer professors .', 'I like parrots , and bulldogs too .', 'I like pets , and cats too .', 'I like factories , and clerks too .', 'I like chicken , but not salmon .', 'I use leather , and nylon too .', 'I like bacon more than apples .', 'I do not like glasses , I prefer trousers .', 'I like bicycles , except Kawasakis .', 'I like factories more than professors .', 'I like glasses , and bracelets too .', 'He trusts his taste , except reconstructions .', 'I do not like shirts , I prefer jewelry .', 'I like cats , but not parrots .', 'I like jewelry , but not trousers .', 'I like wardrobes , except cutlery .', 'I like trains , and Harley-Davidson too .', 'I use leather , but not PVC .', 'I like Zinfandel more than sprite .', 'I like parrots , except dogs .', 'I like food , and jazz too .', 'I like tables , except furniture .', 'I do not like westerns , I prefer boardgames .', 'I like handbooks more than music .', 'I like grass , but not firs .', 'He trusts his hearing , but not reconstructions .', 'I like whales , except dogs .', 'I like rings more than handbags .', 'I like firs , but not bushes .', 'He likes calculations more than joy .', 'I like dogs , but not giraffes .', 'I like textbooks more than westerns .', 'I met geneticists , but not clerks .', 'I like whales , and hamsters too .', 'I do not like jellyfish , I prefer rabbits .', 'I like hamsters more than jellyfish .', 'I like hamsters , and sparrows too .', 'I do not like Merlot , I prefer wine .', 'I do not like pork , I prefer carrots .', 'He likes emotions more than fear .', 'I like cats , and ducks too .', 'I like videogames , except westerns .', 'I do not like sprite , I prefer Zinfandel .', 'I like rabbits more than bulldogs .', 'I like paintings , except beds .', 'I like offices , except clerks .', 'I like blackbirds more than cats .', 'I use leather , except vinyl .', 'I like professors , but not factories .', 'I do not like geneticists , I prefer scientists .', 'I like beef more than salmon .', 'I do not like parrots , I prefer birds .', 'I use PVC , but not leather .', 'I do not like hamsters , I prefer beagles .', 'I use wood , except nylon .', 'I do not like scientists , I prefer physicists .', 'I do not like parrots , I prefer bobtails .', 'I like music , and boardgames too .', 'I like wallpaper , except tables .', 'He does not like emotions , he prefers wisdom .', 'I like dogs more than bears .', 'I like music , but not jazz .', 'I like trees , except firs .', 'I do not like trees , I prefer animals .', 'I do not like food , I prefer blues .', 'I use vinyl , but not cotton .', 'He does not trust his sight , he prefers guesses .', 'I like schools more than professors .', 'I like pets , except jellyfish .', 'I do not like pork , I prefer prosciutto .', 'I like scarfs , and bracelets too .', 'I like Harley-Davidson more than trains .', 'I like furniture , but not chairs .', 'I like apples , but not ham .', 'I like shirts , except earrings .', 'I do not like thrillers , I prefer movies .', 'I do not like biologists , I prefer scientists .', 'I like handbooks , but not films .', 'I like parrots , except birds .', 'I use nylon , but not wood .', 'I like firs , but not trees .', 'He does not trust his senses , he prefers his taste .', 'I like scarfs , and earrings too .', 'I met geneticists , but not waiters .', 'I like essays , except thrillers .', 'I like veal , except crabs .', 'I do not like rings , I prefer shoes .', 'I like food , but not blues .', 'He likes sadness , and logic too .', 'I like beagles , and parrots too .', 'I like pines , and shrubs too .', 'I use cotton , except nylon .', 'I do not like tables , I prefer furniture .', 'I use vinyl more than glass .', 'I do not like scientists , I prefer waiters .', 'I like Suzukis more than airplanes .', 'I like boardgames , but not thrillers .', 'I like animals , but not pines .', 'He likes logic , and sadness too .', 'I like seafood more than caviar .', 'I like turkey , and salmon too .', 'I do not like seafood , I prefer chicken .', 'I like ham more than apples .', 'I like bacon , but not apples .', 'I use glass more than PVC .', 'I like sparrows , and cats too .', 'I like books , and paintings too .', 'I like salmon , but not chicken .', 'I like trousers , but not glasses .', 'I like furniture , but not wardrobes .', 'I like pork , and prosciutto too .', 'I do not like earrings , I prefer trousers .', 'I like textbooks more than films .', 'I like Kawasakis , except bicycles .', 'I met janitors , except physicists .', 'I like blackbirds more than pigs .', 'I like techno , and boardgames too .', 'I like blackbirds more than birds .', 'I like socks more than earrings .', 'I do not like nylon , I prefer plastic .', 'I met physicists , and scientists too .', 'I like books , but not films .', 'I like earrings , but not handbags .', 'I do not like cutlery , I prefer beds .', 'I like water , except Merlot .', 'I do not like handbooks , I prefer books .', 'I use leather , except PVC .', 'I do not like hamsters , I prefer bobtails .', 'I like broccoli more than ham .', 'I like beagles , but not hamsters .', 'I do not like earrings , I prefer socks .', 'I like hamsters more than blackbirds .', 'He likes stupidity , and joy too .', 'He trusts his touch , but not guesses .', 'I like pines more than bushes .', 'I like schools more than waiters .', 'I like textbooks more than music .', 'I do not like plastic , I prefer vinyl .', 'I like pigs , but not blackbirds .', 'I like westerns , except movies .', 'I like handbooks , but not paintings .', 'I like beef , except oysters .', 'I like jewelry more than trousers .', 'He trusts his hearing , but not reports .', 'He likes love more than logic .', 'I like food , except blues .', 'I like clothes , except jewelry .', 'I like workers , and schools too .', 'He does not like emotions , he prefers fear .', 'I like earrings more than jewelry .', 'I do not like shirts , I prefer earrings .', 'He does not trust his taste , he prefers reports .', 'I like bicycles , but not enduros .', 'He trusts reconstructions , except his taste .', 'I do not like music , I prefer sports .', 'I like carrots , except bacon .', 'I like rabbits , but not whales .', 'I use polyester more than leather .', 'He likes joy , except emotions .', 'I like cats more than ducks .', 'I like trees , but not oaks .', 'I met scientists , but not geneticists .', 'I like food , except rock .', 'He likes logic , except love .', 'I like rock , but not boardgames .', 'I like huskies , but not cats .', 'I like pines , but not bushes .', 'I like rabbits , except jellyfish .', 'I like sports more than jazz .', 'I do not like chicken , I prefer oysters .', 'I use vinyl , and plastic too .', 'I like wardrobes , but not cutlery .', 'I like huskies , except rabbits .', 'I like pork , except fish .', 'I like motorcycles , and Suzukis too .', 'I like comedies , and boardgames too .', 'I do not like techno , I prefer music .', 'I use PVC , and glass too .', 'I like handbooks more than paintings .', 'I like Kawasakis , but not bicycles .', 'I like jellyfish more than cats .', 'I like chairs more than wallpaper .', 'I use wood , and PVC too .', 'I do not like birds , I prefer cats .', 'I like wardrobes , except wallpaper .', 'I like workers , but not schools .', 'I like hamsters , except huskies .', 'He trusts his sight , except rumors .', 'I like rabbits more than huskies .', 'I like bears more than hamsters .', 'I like handbooks , and books too .', 'I do not like Chianti , I prefer beer .', 'I like pines , except trees .', 'I do not like professors , I prefer factories .', 'I like hamsters , and ducks too .', 'I like necklaces , except shoes .', 'I like jewelry more than shirts .', 'I do not like pets , I prefer giraffes .', 'I use vinyl , except wood .', 'I like hamsters , but not giraffes .', 'I met scientists , and caretakers too .', 'He likes stupidity more than love .', 'I like sparrows , except birds .', 'I like novels , except films .', 'He likes fear more than calculations .', 'He likes joy , but not emotions .', 'I do not like westerns , I prefer movies .', 'I like chicken , and salmon too .', 'I do not like boardgames , I prefer comedies .', 'I like bicycles , and Harley-Davidson too .', 'I like animals , except firs .', 'I like beds , except cutlery .', 'I like Suzukis , except trains .', 'I like earrings more than socks .', 'He trusts his taste more than reconstructions .', 'I do not like ducks , I prefer hamsters .', 'I like oaks , except grass .', 'I like sports more than rock .', 'I like cats , except bobtails .', 'He likes logic , except sadness .', 'I do not like motorcycles , I prefer trains .', 'I like skirts , except glasses .', 'I like music , but not novels .', 'I do not like restaurants , I prefer waiters .', 'I like giraffes more than hamsters .', 'I do not like scientists , I prefer caretakers .', 'I like caviar more than beef .', 'I met clerks , but not physicists .', 'I like earrings , except shirts .', 'I like carrots , and ham too .', 'I like geneticists more than janitors .', 'I do not like Suzukis , I prefer bicycles .', 'I like books more than films .', 'I like wine more than sprite .', 'I like textbooks , but not cartoons .', 'I like crabs , but not turkey .', 'I like giraffes , but not hamsters .', 'I like trees more than bushes .', 'I like thrillers , but not boardgames .', 'I do not like clerks , I prefer factories .', 'I met janitors , but not astronomers .', 'I do not like socks , I prefer glasses .', 'I do not like bicycles , I prefer Suzukis .', 'I like novels more than music .', 'I like comedies , and movies too .', 'I like lard , and carrots too .', 'I like ham , and apples too .', 'I like pork more than carrots .', 'I do not like firs , I prefer trees .', 'I like shoes , and necklaces too .', 'I met waiters , but not astronomers .', 'I like jewelry , but not techno .', 'I like music , and essays too .', 'I like caretakers more than astronomers .', 'I do not like movies , I prefer westerns .', 'I like beds more than cutlery .', 'I like essays , except comedies .', 'I like dogs more than giraffes .', 'He likes love , but not emotions .', 'I like clothes , except shirts .', 'I like hamsters more than ducks .', 'He likes fear , except calculations .', 'I like food , except techno .', 'I do not like furniture , I prefer chairs .', 'I like ham , but not apples .', 'I like food , except jazz .', 'I like fish , except prosciutto .', 'I like jellyfish , and rabbits too .', 'I like cats , and bears too .', 'I like bulldogs , but not parrots .', 'I do not like offices , I prefer caretakers .', 'I like parquet , except tables .', 'I like music more than sports .', 'I do not like prosciutto , I prefer broccoli .', 'I like grass , and pines too .', 'I do not like wine , I prefer Merlot .', 'I like books , except paintings .', 'He trusts his senses , except his sight .', 'I do not like grass , I prefer firs .', 'I met waiters , except physicists .', 'I like paintings more than novels .', 'I like fish , but not ham .', 'I like workers , and caretakers too .', 'I like factories more than caretakers .', 'I like Chardonnay more than beer .', 'I like grass , except pines .', 'I like trains , but not enduros .', 'I like cutlery , but not chairs .', 'I like jewelry , and earrings too .', 'I like videogames , but not comedies .', 'I like whales , but not cats .', 'He trusts his hearing , but not guesses .', 'I like motorcycles more than Harley-Davidson .', 'I like rock more than jewelry .', 'I like birches , but not trees .', 'He likes fear more than wisdom .', 'I use vinyl , but not plastic .', 'I met biologists , but not waiters .', 'I like pets , and socks too .', 'I do not like necklaces , I prefer glasses .', 'I do not like music , I prefer jazz .', 'I like scarfs more than rings .', 'I like ships , and enduros too .', 'I do not like jazz , I prefer jewelry .', 'I met physicists , but not clerks .', 'I like Merlot , except wine .', 'I like textbooks , except books .', 'I like biologists more than waiters .', 'I like handbags , except rings .', 'I do not like crabs , I prefer turkey .', 'I like sprite , but not Merlot .', 'I like oaks , and animals too .', 'I like restaurants more than caretakers .', 'I do not like seafood , I prefer oysters .', 'I like essays , but not comedies .', 'I like westerns , but not videogames .', 'I use PVC , and plastic too .', 'I do not like geneticists , I prefer janitors .', 'I like shoes , but not rings .', 'I like cutlery more than chairs .', 'I like cats , and giraffes too .', 'I like furniture , and wardrobes too .', 'I like necklaces , and shoes too .', 'I like handbags , except earrings .', 'I like books more than novels .', 'I like Zinfandel , but not water .', 'I like seafood , except chicken .', 'I like novels more than films .', 'I like pets , and dogs too .', 'He does not trust his sight , he prefers rumors .', 'I like handbags , and bracelets too .', 'I like tables , except parquet .', 'I like beds , but not wallpaper .', 'I like seafood , except veal .', 'I like hamsters , but not blackbirds .', 'I like parquet , but not tables .', 'I like textbooks , and comedies too .', 'I like planes more than Harley-Davidson .', 'I like cats , and blackbirds too .', 'I like beer , and Chianti too .', 'I like bicycles , and enduros too .', 'He does not trust his touch , he prefers his senses .', 'He likes sadness , and wisdom too .', 'I like firs , except shrubs .', 'I like Harley-Davidson more than ships .', 'I like trousers , and jewelry too .', 'I like professors more than factories .', 'I like caretakers , and factories too .', 'I do not like videogames , I prefer comedies .', 'I like Chardonnay , except coca-cola .', 'He likes stupidity , but not love .', 'He likes sadness , but not logic .', 'I like bacon , but not pork .', 'I use polyester , and glass too .', 'I like pets , but not cats .', 'I like blackbirds , but not cats .', 'I like thrillers , and boardgames too .', 'I like cartoons , but not textbooks .', 'I like jewelry , and shoes too .', 'I like socks , and jewelry too .', 'I like workers , but not waiters .', 'I like Harley-Davidson , and airplanes too .', 'I like essays , and thrillers too .', 'I do not like wardrobes , I prefer parquet .', 'He does not like stupidity , he prefers joy .', 'I like birds more than pigs .', 'He does not like joy , he prefers logic .', 'I like jewelry , except skirts .', 'He trusts reports more than his taste .', 'I do not like Chardonnay , I prefer water .', 'I like music , but not handbooks .', 'I use vinyl , and wood too .', 'I do not like bulldogs , I prefer rabbits .', 'I like earrings more than skirts .', 'I like jazz , and boardgames too .', 'I do not like cats , I prefer huskies .', 'I like caretakers more than restaurants .', 'He likes sadness , except calculations .', 'I like wallpaper , but not chairs .', 'I like music more than essays .', 'I like fish more than bacon .', 'He trusts his senses , but not his sight .', 'I use vinyl , but not wood .', 'I use nylon , but not cotton .', 'I like videogames , but not documentaries .', 'I like Harley-Davidson , except ships .', 'I like films , but not essays .', 'I like wardrobes , but not wallpaper .', 'I do not like dogs , I prefer giraffes .', 'I like jewelry , except techno .', 'I like shoes , except bracelets .', 'I like parquet , except beds .', 'I like ham , but not carrots .', 'I like rabbits , and whales too .', 'I like dogs , except pets .', 'I like jewelry , but not rings .', 'I like essays , but not documentaries .', 'I like wine , except Zinfandel .', 'He likes love , and logic too .', 'I like beer , but not Zinfandel .', 'I like sprite , and Merlot too .', 'I met janitors , and physicists too .', 'I met geneticists , except janitors .', 'I like trees more than animals .', 'I do not like bears , I prefer hamsters .', 'I like rock , but not food .', 'I like jazz more than music .', 'He trusts his hearing more than guesses .', 'I do not like planes , I prefer Kawasakis .', 'He likes joy , except logic .', 'He trusts his hearing , except reconstructions .', 'I like bulldogs , and dogs too .', 'I use leather , and polyester too .', 'I like Harley-Davidson , but not motorcycles .', 'I do not like dogs , I prefer rabbits .', 'I do not like hamsters , I prefer pets .', 'I like videogames , except thrillers .', 'I like books more than cartoons .', 'I like turkey , but not oysters .', 'I use leather more than nylon .', 'I like music , but not essays .', 'I do not like jellyfish , I prefer hamsters .', 'I do not like motorcycles , I prefer ships .', 'I like prosciutto , except broccoli .', 'I like music more than novels .', 'I do not like Chianti , I prefer water .', 'I do not like trees , I prefer birches .', 'I like oaks , but not grass .', 'I do not like ducks , I prefer pigs .', 'I do not like pork , I prefer lard .', 'I like seafood , and beef too .', 'I like sprite , except Chianti .', 'I like furniture , except beds .', 'I do not like clothes , I prefer jewelry .', 'He trusts guesses , except his hearing .', 'He likes joy , but not wisdom .', 'I like jewelry , and scarfs too .', 'I like carrots , except prosciutto .', 'I like Harley-Davidson , and bicycles too .', 'I do not like wine , I prefer water .', 'I like trains , but not Kawasakis .', 'I do not like bushes , I prefer firs .', 'He likes fear more than logic .', 'I like necklaces , and jewelry too .', 'I like sparrows , but not pigs .', 'I do not like textbooks , I prefer films .', 'I like chicken , but not caviar .', 'I do not like ships , I prefer Kawasakis .', 'I do not like rabbits , I prefer bobtails .', 'I like trousers , except jewelry .', 'I like rabbits , except giraffes .', 'I use plastic more than wood .', 'I do not like earrings , I prefer handbags .', 'I like turkey , and oysters too .', 'I like rock , but not jewelry .', 'I like motorcycles more than bicycles .', 'I like Harley-Davidson , and ships too .', 'I do not like lard , I prefer carrots .', 'I like furniture more than wallpaper .', 'I like offices , and waiters too .', 'I use leather , and PVC too .', 'I like clerks more than workers .', 'I like clothes , but not shoes .', 'I like carrots , and bacon too .', 'I like ships , but not enduros .', 'I like janitors more than biologists .', 'I like coca-cola , and Chianti too .', 'I like wallpaper , but not wardrobes .', 'I do not like cats , I prefer giraffes .', 'I like jazz , and music too .', 'I like pines , and bushes too .', 'I like Suzukis , and bicycles too .', 'I do not like beds , I prefer cutlery .', 'I like pines , except bushes .', 'I like textbooks , but not music .', 'I like rock , but not music .', 'I like movies more than boardgames .', 'I like movies , and essays too .', 'I do not like essays , I prefer documentaries .', 'I do not like birches , I prefer animals .', 'I met physicists , and waiters too .', 'I like jewelry , but not scarfs .', 'I like shrubs more than pines .', 'I like fish , and bacon too .', 'I do not like bacon , I prefer broccoli .', 'I like scarfs , and necklaces too .', 'I like salmon , and beef too .', 'I do not like furniture , I prefer cutlery .', 'I like schools , except professors .', 'I do not like music , I prefer handbooks .', 'He does not like stupidity , he prefers fear .', 'I like beds , and furniture too .', 'I like handbooks , except cartoons .', 'I like cartoons more than textbooks .', 'I met geneticists , but not janitors .', 'I like sparrows , and birds too .', 'I like firs , but not grass .', 'I like waiters more than biologists .', 'He trusts reconstructions , and his hearing too .', 'I like parrots , except bobtails .', 'I like pets more than trousers .', 'I met scientists , but not biologists .', 'I do not like polyester , I prefer wood .', 'He does not like joy , he prefers emotions .', 'He trusts reconstructions more than his taste .', 'He trusts his senses more than reconstructions .', 'I do not like caretakers , I prefer astronomers .', 'I do not like jewelry , I prefer necklaces .', 'I like music more than boardgames .', 'He does not like emotions , he prefers logic .', 'I like sparrows , but not hamsters .', 'I like dogs , but not jellyfish .', 'I do not like planes , I prefer Harley-Davidson .', 'I like ducks , except pigs .', 'I like boardgames , except westerns .', 'I like skirts , but not shoes .', 'I met physicists , except caretakers .', 'I like scarfs more than earrings .', 'I like apples more than lard .', 'I like furniture , but not tables .', 'I like music , and techno too .', 'He likes emotions , except fear .', 'I like giraffes , but not dogs .', 'I like hamsters more than bobtails .', 'I do not like videogames , I prefer documentaries .', 'I like motorcycles , and trains too .', 'I like music , except blues .', 'I like professors more than schools .', 'I met physicists , but not caretakers .', 'I like earrings , except scarfs .', 'I like bicycles , except Harley-Davidson .', 'I like cutlery , and tables too .', 'I like wardrobes , and parquet too .', 'I like oaks more than grass .', 'I like films , except essays .', 'I like salmon more than veal .', 'He trusts reconstructions , and his sight too .', 'I like glasses , but not trousers .', 'I like earrings , and scarfs too .', 'He trusts rumors more than his hearing .', 'I met astronomers , except waiters .', 'I like dogs , and giraffes too .', 'I do not like boardgames , I prefer thrillers .', 'He does not like sadness , he prefers stupidity .', 'I like Kawasakis more than bicycles .', 'I like handbags more than earrings .', 'I like trees , and animals too .', 'I do not like pork , I prefer apples .', 'I like wallpaper , and beds too .', 'I like ships , except Harley-Davidson .', 'He does not like love , he prefers stupidity .', 'I like hamsters , except bobtails .', 'I like biologists more than clerks .', 'He likes emotions , but not sadness .', 'He likes sadness , except logic .', 'I like seafood , but not crabs .', 'I like boardgames more than westerns .', 'I do not like jewelry , I prefer techno .', 'I like blackbirds , except dogs .', 'I like Zinfandel , except water .', 'I like westerns more than textbooks .', 'I like boardgames , but not jazz .', 'I like cats , except pets .', 'He does not trust his taste , he prefers guesses .', 'I like glasses more than skirts .', 'I like socks , except glasses .', 'I like cats , but not ducks .', 'I do not like Harley-Davidson , I prefer motorcycles .', 'I do not like whales , I prefer cats .', 'I like motorcycles , and airplanes too .', 'I like paintings , but not beds .', 'I like oysters more than seafood .', 'I like rock , and food too .', 'I like Harley-Davidson , but not ships .', 'I do not like prosciutto , I prefer carrots .', 'I like boardgames , and westerns too .', 'I like music , but not food .', 'I like pigs more than sparrows .', 'I do not like wardrobes , I prefer furniture .', 'I like blackbirds , but not dogs .', 'I do not like pigs , I prefer parrots .', 'He trusts his hearing , and his senses too .', 'I like westerns , and movies too .', 'I like Suzukis , but not bicycles .', 'I met caretakers , and physicists too .', 'I do not like oaks , I prefer trees .', 'I like parrots more than dogs .', 'I like socks , except shoes .', 'I like dogs more than jellyfish .', 'I do not like films , I prefer novels .', 'I like movies , except textbooks .', 'I like restaurants , except clerks .', 'I like dogs , except bulldogs .', 'I like chairs more than furniture .', 'I do not like jewelry , I prefer socks .', 'He trusts his hearing , except rumors .', 'I like waiters , but not restaurants .', 'He does not trust reconstructions , he prefers his sight .', 'I like ducks , and cats too .', 'I like rock more than sports .', 'I like offices , except waiters .', 'I do not like textbooks , I prefer music .', 'I met clerks , and biologists too .', 'I do not like lard , I prefer broccoli .', 'I like earrings , except handbags .', 'I do not like beef , I prefer caviar .', 'I like apples , but not prosciutto .', 'I like cats , and jellyfish too .', 'I met janitors , and geneticists too .', 'I do not like clerks , I prefer astronomers .', 'I like films more than novels .', 'I like dogs , and bobtails too .', 'He does not trust his hearing , he prefers rumors .', 'I use glass , but not vinyl .', 'I like blackbirds , but not birds .', 'I met clerks , but not biologists .', 'I like videogames more than documentaries .', 'I like restaurants , and caretakers too .', 'I like music , but not blues .', 'I use PVC , except plastic .', 'I met scientists , and physicists too .', 'I like beef , except crabs .', 'I like oysters , except seafood .', 'I like blackbirds , but not pigs .', 'I do not like westerns , I prefer textbooks .', 'I like coca-cola more than Merlot .', 'I like movies , and textbooks too .', 'I like rings more than glasses .', 'He does not trust guesses , he prefers his sight .', 'I like coca-cola , but not Zinfandel .', 'I like motorcycles , and Harley-Davidson too .', 'I like scientists more than clerks .', 'I like dogs , except whales .', 'I like giraffes more than dogs .', 'I like furniture , and wallpaper too .', 'I use nylon , but not plastic .', 'I like veal , and oysters too .', 'I do not like ham , I prefer broccoli .', 'I met clerks , except geneticists .', 'I like furniture , except cutlery .', 'He likes joy more than calculations .', 'I like textbooks more than comedies .', 'I like hamsters , but not ducks .', 'I like boardgames , and comedies too .', 'He trusts his senses , but not his touch .', 'I do not like furniture , I prefer wallpaper .', 'I like pines , except shrubs .', 'He does not like fear , he prefers wisdom .', 'I like veal more than salmon .', 'I like grass more than birches .', 'I like jewelry , except blues .', 'I do not like pines , I prefer trees .', 'I like workers , and restaurants too .', 'I like prosciutto more than carrots .', 'I do not like scientists , I prefer astronomers .', 'I do not like cutlery , I prefer wardrobes .', 'I like wallpaper , and wardrobes too .', 'I like pork , except prosciutto .', 'I like films more than textbooks .', 'I like oysters , but not veal .', 'He trusts guesses , but not his sight .', 'He trusts guesses , except his sight .', 'I like bicycles more than Suzukis .', 'I like bacon , except apples .', 'I do not like sparrows , I prefer dogs .', 'I like workers , and offices too .', 'I like essays , but not paintings .', 'I like apples more than ham .', 'I like bracelets more than glasses .', 'I like bicycles , except enduros .', 'I like schools , and professors too .', 'I like documentaries more than videogames .', 'He likes emotions , except wisdom .', 'I use glass , and nylon too .', 'I like handbags more than bracelets .', 'He trusts his senses , and his sight too .', 'I like cutlery , except tables .', 'I do not like salmon , I prefer beef .', 'I like whales , except hamsters .', 'I do not like scarfs , I prefer bracelets .', 'I met clerks , except biologists .', 'I like bulldogs , except rabbits .', 'I do not like chicken , I prefer caviar .', 'He does not trust his hearing , he prefers guesses .', 'I like Chianti more than water .', 'I like clerks more than biologists .', 'I like beagles , but not cats .', 'I like whales more than dogs .', 'I like factories , but not caretakers .', 'I like crabs , except chicken .', 'I like professors , but not restaurants .', 'I like paintings , and handbooks too .', 'I like handbooks , but not books .', 'I like shrubs , but not pines .', 'I like beer , and Merlot too .', 'I like parrots , but not pigs .', 'I like pork , and apples too .', 'I like parrots more than hamsters .', 'I like bracelets , and scarfs too .', 'I like caretakers more than biologists .', 'I like earrings more than glasses .', 'I like beer , and Chardonnay too .', 'I like tables , but not furniture .', 'I met geneticists , except caretakers .', 'I do not like carrots , I prefer ham .', 'I like rabbits more than whales .', 'I like Chardonnay , but not wine .', 'I like birds , and blackbirds too .', 'I like shirts , and jewelry too .', 'I like handbooks , but not cartoons .', 'I like wine , and Merlot too .', 'I like caviar , except veal .', 'I like offices , but not waiters .', 'I like essays , but not music .', 'I do not like boardgames , I prefer techno .', 'I do not like jewelry , I prefer rock .', 'I like schools more than caretakers .', 'I like Chianti more than sprite .', 'I like pets , but not jellyfish .', 'He trusts reports , and his sight too .', 'I like clerks more than restaurants .', 'I like shrubs , but not birches .', 'I like earrings , and jewelry too .', 'I like techno , except boardgames .', 'I like trousers , and clothes too .', 'I like bicycles more than Kawasakis .', 'I like birches more than shrubs .', 'I like trees , and pines too .', 'I like techno , but not boardgames .', 'I like huskies , except parrots .', 'I like clerks , but not factories .', 'I use vinyl , except glass .', 'I like furniture more than parquet .', 'I do not like trousers , I prefer jewelry .', 'I use polyester , except cotton .', 'I like movies , and comedies too .', 'He likes stupidity , and sadness too .', 'I like thrillers more than essays .', 'I do not like bushes , I prefer oaks .', 'I do not like rock , I prefer music .', 'He trusts his touch , and his senses too .', 'I like broccoli more than bacon .', 'I do not like waiters , I prefer factories .', 'I like socks , and pets too .', 'He does not like emotions , he prefers joy .', 'I do not like pets , I prefer bears .', 'I do not like beef , I prefer oysters .', 'I like pets , and giraffes too .', 'I like essays , except films .', 'He does not trust reports , he prefers his sight .', 'I like birds , except blackbirds .', 'I like tables more than cutlery .', 'I use PVC , except leather .', 'I like wine , and coca-cola too .', 'I like rabbits , and bears too .', 'I do not like offices , I prefer waiters .', 'I do not like jazz , I prefer music .', 'I do not like bobtails , I prefer cats .', 'I like shrubs , and birches too .', 'I like food more than rock .', 'I do not like handbags , I prefer bracelets .', 'I like handbags , except bracelets .', 'I do not like dogs , I prefer pets .', 'He likes love , and wisdom too .', 'I like cats , except huskies .', 'I like wine more than Zinfandel .', 'I like caviar , except seafood .', 'I like cats more than blackbirds .', 'I do not like fish , I prefer bacon .', 'I like documentaries , and textbooks too .', 'I do not like handbags , I prefer rings .', 'I like firs more than bushes .', 'I like cutlery , and chairs too .', 'I like pines more than animals .', 'I like Chardonnay , except sprite .', 'I do not like PVC , I prefer wood .', 'I like trees more than grass .', 'He likes wisdom more than sadness .', 'I like coca-cola , except Chardonnay .', 'I like dogs , and pets too .', 'I do not like rock , I prefer food .', 'I like textbooks , except paintings .', 'I like caviar , but not beef .', 'I like wine , except Merlot .', 'I do not like books , I prefer music .', 'I like tables , but not cutlery .', 'He does not trust reconstructions , he prefers his touch .', 'I like earrings , but not glasses .', 'I do not like Chianti , I prefer sprite .', 'I met astronomers , and janitors too .', 'I like caretakers more than offices .', 'I like shoes more than bracelets .', 'I like Chardonnay , and beer too .', 'I do not like veal , I prefer salmon .', 'I like comedies , but not videogames .', 'I like enduros , and bicycles too .', 'I like paintings , except wardrobes .', 'I like socks , and clothes too .', 'I like wallpaper , except chairs .', 'I do not like dogs , I prefer jellyfish .', 'I do not like giraffes , I prefer cats .', 'I like music , and handbooks too .', 'I like bicycles , except Suzukis .', 'I like ducks , but not cats .', 'I met caretakers , except geneticists .', 'I like broccoli , but not bacon .', 'I use plastic , and glass too .', 'I do not like beds , I prefer parquet .', 'I like caretakers more than factories .', 'I like dogs more than rabbits .', 'He trusts his senses , except reports .', 'I do not like jewelry , I prefer rings .', 'I like rings , but not jewelry .', 'I like wine more than Chardonnay .', 'I like skirts , except clothes .', 'I like trains more than enduros .', 'He trusts rumors more than his touch .', 'I like books , except novels .', 'He likes emotions , but not logic .', 'I like novels more than paintings .', 'I like veal , and salmon too .', 'I use glass , and PVC too .', 'I like whales , and cats too .', 'He likes love , except emotions .', 'I like ham , except fish .', 'I like shrubs , and oaks too .', 'He trusts rumors more than his sight .', 'I like prosciutto more than apples .', 'I do not like music , I prefer novels .', 'I do not like bears , I prefer rabbits .', 'I like Chianti , except sprite .', 'I like paintings more than beds .', 'I like ships , except enduros .', 'He likes emotions , except stupidity .', 'I do not like glasses , I prefer shirts .', 'I like schools , except waiters .', 'I like wine , except water .', 'I like shoes , but not necklaces .', 'I do not like wallpaper , I prefer wardrobes .', 'He trusts his sight , and rumors too .', 'I do not like physicists , I prefer clerks .', 'I like music , except jazz .', 'I like thrillers , but not essays .', 'I do not like essays , I prefer cartoons .', 'I met caretakers , except physicists .', 'I like scarfs , but not rings .', 'He likes emotions , except calculations .', 'I like Merlot , but not beer .', 'I do not like wine , I prefer beer .', 'He does not trust his sight , he prefers reports .', 'I like earrings , but not shoes .', 'I do not like cats , I prefer whales .', 'I like handbooks , and films too .', 'I like jewelry , except rock .', 'I like documentaries , except textbooks .', 'He likes calculations , except fear .', 'I like sprite , but not Chardonnay .', 'I do not like music , I prefer blues .', 'I like clerks , and restaurants too .', 'I like movies , and documentaries too .', 'I like glasses , except necklaces .', 'I do not like textbooks , I prefer comedies .', 'I like veal more than oysters .', 'I like rabbits , but not pets .', 'I do not like nylon , I prefer glass .', 'I like bacon , and pork too .', 'I like earrings , and handbags too .', 'I met waiters , and biologists too .', 'I like bacon , and apples too .', 'I like dogs , but not parrots .', 'I like whales more than rabbits .', 'I like hamsters , except sparrows .', 'I like novels , but not films .', 'I like hamsters , but not bulldogs .', 'I like trousers , except clothes .', 'I do not like factories , I prefer waiters .', 'I like novels , except cartoons .', 'I like offices more than caretakers .', 'I do not like jewelry , I prefer shoes .', 'I like motorcycles more than trains .', 'I do not like caviar , I prefer beef .', 'I use vinyl , but not glass .', 'I do not like shirts , I prefer clothes .', 'He likes sadness , but not calculations .', 'I like turkey , and caviar too .', 'I like chairs , except cutlery .', 'I like huskies , except cats .', 'He trusts his touch more than reports .', 'I like trousers , but not shoes .', 'I like motorcycles , but not Kawasakis .', 'I like bacon , except pork .', 'I like rock more than music .', 'I like ducks , except birds .', 'I like Merlot , but not wine .', 'I like videogames , and westerns too .', 'I do not like factories , I prefer caretakers .', 'He trusts reconstructions , except his sight .', 'I like seafood , except beef .', 'He trusts rumors , and his sight too .', 'He does not trust his touch , he prefers reports .', 'I like boardgames , and jazz too .', 'I like pigs more than blackbirds .', 'I like jewelry , except rings .', 'I use nylon , except wood .', 'I like hamsters , except bears .', 'I like birds , and sparrows too .', 'I met scientists , but not waiters .', 'I do not like rabbits , I prefer giraffes .', 'I like textbooks , but not books .', 'He trusts his senses more than guesses .', 'I like clothes , but not trousers .', 'I do not like rock , I prefer jewelry .', 'I like enduros , but not ships .', 'I like techno , and jewelry too .', 'I like birds , except parrots .', 'He does not like fear , he prefers logic .', 'I like lard , but not apples .', 'I met janitors , but not physicists .', 'He does not trust rumors , he prefers his hearing .', 'I like Kawasakis , but not motorcycles .', 'I like fish more than ham .', 'I like cartoons , except textbooks .', 'I do not like glasses , I prefer necklaces .', 'I like essays more than paintings .', 'I do not like waiters , I prefer physicists .', 'I like dogs , but not beagles .', 'I do not like physicists , I prefer janitors .', 'I like oysters more than chicken .', 'I like beef , but not oysters .', 'I like bracelets , but not jewelry .', 'I like novels , and films too .', 'I like astronomers more than scientists .', 'He likes love , except stupidity .', 'I do not like furniture , I prefer beds .', 'I like scientists more than physicists .', 'I like giraffes , except hamsters .', 'I like caviar , and chicken too .', 'I do not like pigs , I prefer sparrows .', 'I like prosciutto , except pork .', 'I do not like thrillers , I prefer videogames .', 'I do not like apples , I prefer prosciutto .', 'He likes joy , and stupidity too .', 'He trusts his senses more than his sight .', 'I like Chianti , except coca-cola .', 'I do not like motorcycles , I prefer Suzukis .', 'I like rabbits , but not bulldogs .', 'I use glass , but not polyester .', 'I like wine more than water .', 'I do not like caretakers , I prefer restaurants .', 'I do not like Kawasakis , I prefer trains .', 'I use nylon , and glass too .', 'I do not like earrings , I prefer jewelry .', 'I do not like turkey , I prefer caviar .', 'I do not like grass , I prefer birches .', 'I use glass , and polyester too .', 'I like coca-cola , except Zinfandel .', 'I do not like cotton , I prefer vinyl .', 'I like sports , except jazz .', 'I like techno , except sports .', 'I do not like beagles , I prefer dogs .', 'I do not like rings , I prefer scarfs .', 'I like birches , and trees too .', 'I do not like clothes , I prefer pets .', 'I like Merlot , and water too .', 'I like wine , and beer too .', 'I like workers more than factories .', 'I like cartoons , but not novels .', 'I like bushes , but not birches .', 'I like bears , and rabbits too .', 'I like comedies , and videogames too .', 'I do not like jellyfish , I prefer dogs .', 'I do not like textbooks , I prefer paintings .', 'I like rock , except food .', 'I do not like handbooks , I prefer cartoons .', 'I like sprite , and Chianti too .', 'I do not like planes , I prefer Suzukis .', 'I met clerks , except physicists .', 'I like lard , but not broccoli .', 'I use polyester , except plastic .', 'I like glasses , and necklaces too .', 'I like furniture , and chairs too .', 'I like cats , but not beagles .', 'I like Merlot , except beer .', 'I do not like handbooks , I prefer paintings .', 'I like earrings , except shoes .', 'I like wine , but not Chardonnay .', 'He likes emotions , and fear too .', 'He does not trust his hearing , he prefers reconstructions .', 'I like bobtails , except rabbits .', 'I like rabbits more than beagles .', 'I like Chardonnay , except beer .', 'I like caviar more than veal .', 'I like blackbirds , except cats .', 'I met caretakers , and biologists too .', 'I like jellyfish , but not cats .', 'I like workers more than waiters .', 'He trusts his sight , but not reports .', 'I like cats , except bears .', 'I like handbags , except necklaces .', 'I like Chardonnay , and wine too .', 'I like music , except sports .', 'I like Harley-Davidson more than motorcycles .', 'I met clerks , and physicists too .', 'I like furniture , except tables .', 'He trusts his senses , but not reconstructions .', 'I do not like nylon , I prefer cotton .', 'I like bobtails , and dogs too .', 'I like Suzukis , and trains too .', 'I like beer , and Zinfandel too .', 'I like pines more than trees .', 'He does not trust his taste , he prefers rumors .', 'I like boardgames , but not blues .', 'I do not like tables , I prefer parquet .', 'I do not like cotton , I prefer nylon .', 'I like bulldogs , and hamsters too .', 'I like blackbirds , and hamsters too .', 'I like boardgames more than blues .', 'I do not like bracelets , I prefer scarfs .', 'I do not like hamsters , I prefer whales .', 'He trusts guesses , but not his touch .', 'I do not like beagles , I prefer rabbits .', 'I like trees more than oaks .', 'I like chairs , except parquet .', 'I like jazz , but not sports .', 'I like glasses , except earrings .', 'I do not like rock , I prefer boardgames .', 'I like cats more than bears .', 'I like shirts , except shoes .', 'I like whales , but not dogs .', 'I like socks , but not glasses .', 'I do not like caviar , I prefer seafood .', 'I like cutlery , except wardrobes .', 'I met scientists , except astronomers .', 'He likes logic more than sadness .', 'I like Suzukis , but not motorcycles .', 'I do not like cotton , I prefer polyester .', 'I like cats , except giraffes .', 'I like glasses more than bracelets .', 'I like motorcycles , and bicycles too .', 'I do not like scarfs , I prefer necklaces .', 'I do not like chairs , I prefer furniture .', 'I like jazz , except food .', 'I like caretakers , and schools too .', 'I do not like glasses , I prefer skirts .', 'I like prosciutto , and apples too .', 'I like documentaries more than boardgames .', 'He trusts guesses more than his taste .', 'I like music , and jewelry too .', 'He does not like love , he prefers logic .', 'He does not trust his senses , he prefers his touch .', 'I like waiters more than restaurants .', 'I like salmon , but not veal .', 'I do not like professors , I prefer workers .', 'I like books more than paintings .', 'He trusts reconstructions , but not his touch .', 'He likes wisdom more than fear .', 'I do not like Chardonnay , I prefer coca-cola .', 'I like prosciutto , but not apples .', 'I like parrots , except hamsters .', 'I like paintings , and novels too .', 'I like jazz , except boardgames .', 'He likes sadness , except wisdom .', 'I do not like trees , I prefer shrubs .', 'I like furniture , and parquet too .', 'He likes joy more than wisdom .', 'I like jewelry , and shirts too .', 'I like oaks , and grass too .', 'I like Chardonnay , but not water .', 'He does not like joy , he prefers wisdom .', 'I do not like paintings , I prefer beds .', 'He likes calculations , but not joy .', 'I do not like clerks , I prefer offices .', 'I use cotton , but not vinyl .', 'I like movies more than essays .', 'I like techno more than sports .', 'I like comedies , and essays too .', 'He does not like love , he prefers emotions .', 'I do not like Harley-Davidson , I prefer bicycles .', 'I like movies , but not boardgames .', 'I like coca-cola , and Merlot too .', 'I like comedies , and textbooks too .', 'I like firs more than animals .', 'I use nylon , and wood too .', 'I like dogs , except beagles .', 'I do not like jazz , I prefer sports .', 'I like fish , and prosciutto too .', 'I do not like nylon , I prefer wood .', 'I like planes , and Harley-Davidson too .', 'He trusts his taste , but not reconstructions .', 'He trusts reports , but not his touch .', 'I do not like blues , I prefer jewelry .', 'I do not like music , I prefer boardgames .', 'I like rings , and jewelry too .', 'I do not like handbooks , I prefer films .', 'I met physicists , except scientists .', 'I do not like cartoons , I prefer handbooks .', 'I like oaks , except shrubs .', 'I like socks , but not shoes .', 'I like waiters , and offices too .', 'I like grass more than pines .', 'I like shoes , but not earrings .', 'I do not like hamsters , I prefer bears .', 'I like essays more than cartoons .', 'I like books , except essays .', 'I do not like bracelets , I prefer glasses .', 'I use polyester , except wood .', 'I like prosciutto more than broccoli .', 'I like rock , except boardgames .', 'I like earrings , except jewelry .', 'I do not like clerks , I prefer physicists .', 'I do not like hamsters , I prefer bulldogs .', 'I like caviar , but not turkey .', 'I use vinyl , but not leather .', 'I like carrots , but not bacon .', 'I like giraffes , and dogs too .', 'He does not trust his touch , he prefers guesses .', 'I like westerns , but not textbooks .', 'He trusts his taste , except his senses .', 'I like ham , except carrots .', 'I like lard , except apples .', 'I like socks , except jewelry .', 'I do not like sparrows , I prefer pigs .', 'I do not like bulldogs , I prefer dogs .', 'I like furniture , except wardrobes .', 'He likes fear , except stupidity .', 'I like rabbits , and giraffes too .', 'He does not like emotions , he prefers calculations .', 'I do not like pets , I prefer whales .', 'I like dogs more than blackbirds .', 'He trusts rumors , and his taste too .', 'I like restaurants , but not waiters .', 'I like jewelry more than rings .', 'I like books , except handbooks .', 'I like sparrows more than cats .', 'I do not like physicists , I prefer scientists .', 'I like hamsters , and bulldogs too .', 'I do not like giraffes , I prefer hamsters .', 'I like jewelry more than blues .', 'I like bicycles , but not Kawasakis .', 'I like dogs , but not sparrows .', 'I do not like beds , I prefer wallpaper .', 'I do not like coca-cola , I prefer Zinfandel .', 'I like Zinfandel more than beer .', 'I like physicists more than janitors .', 'I like pets more than jellyfish .', 'I met biologists , and waiters too .', 'He likes joy , but not calculations .', 'I met scientists , and waiters too .', 'I like workers , and clerks too .', 'I like jewelry , and bracelets too .', 'I like huskies , but not rabbits .', 'I do not like workers , I prefer factories .', 'I use plastic , and polyester too .', 'I like pork more than broccoli .', 'I like factories , and waiters too .', 'I like oysters , except veal .', 'I like textbooks , but not documentaries .', 'I do not like blackbirds , I prefer birds .', 'I do not like turkey , I prefer salmon .', 'I do not like caretakers , I prefer offices .', 'I like wine , and Zinfandel too .', 'I use vinyl more than plastic .', 'I do not like huskies , I prefer dogs .', 'I like parrots , and cats too .', 'I like pork more than ham .', 'I do not like geneticists , I prefer waiters .', 'I like birds more than dogs .', 'I like techno more than boardgames .', 'He trusts reports more than his touch .', 'I like caretakers more than physicists .', 'I do not like books , I prefer novels .', 'I use plastic , and PVC too .', 'I like necklaces more than glasses .', 'I like blues more than music .', 'I like furniture , except parquet .', 'I like paintings , except handbooks .', 'I like dogs , and hamsters too .', 'I like Harley-Davidson , except motorcycles .', 'I like rabbits , except beagles .', 'I like whales , but not rabbits .', 'I like professors more than offices .', 'I do not like socks , I prefer earrings .', 'He trusts his senses , and reconstructions too .', 'I like pets more than giraffes .', 'I use wood more than vinyl .', 'I like sports , except rock .', 'I do not like birds , I prefer blackbirds .', 'I use plastic , except wood .', 'I like shirts , and clothes too .', 'I like birches , except trees .', 'I like trains , except Kawasakis .', 'I like cutlery , but not beds .', 'I do not like bulldogs , I prefer parrots .', 'He does not trust guesses , he prefers his hearing .', 'I do not like pigs , I prefer blackbirds .', 'I like parrots , but not bulldogs .', 'I like bushes , except oaks .', 'I like trees , and oaks too .', 'I do not like birds , I prefer dogs .', 'I use cotton , and polyester too .', 'I like Chardonnay , and water too .', 'I like Merlot more than beer .', 'I like books , and films too .', 'I like ham , except apples .', 'I like essays more than westerns .', 'I like motorcycles , but not enduros .', 'I like oysters , and turkey too .', 'I do not like wardrobes , I prefer paintings .', 'I like cats , but not huskies .', 'I like trees , but not shrubs .', 'He trusts his senses , except guesses .', 'I like dogs , and bears too .', 'I like pets more than skirts .', 'I like veal , and crabs too .', 'I like bears , except cats .', 'I like thrillers , except textbooks .', 'I like hamsters more than parrots .', 'I like thrillers more than textbooks .', 'I like jewelry more than jazz .', 'I like carrots more than bacon .', 'I like furniture , but not wallpaper .', 'I do not like blackbirds , I prefer pigs .', 'I do not like hamsters , I prefer jellyfish .', 'I do not like polyester , I prefer plastic .', 'I like bears , and hamsters too .', 'I like bracelets , and shoes too .', 'I like workers , except waiters .', 'I like parrots , and pigs too .', 'I like trains , and Suzukis too .', 'I like shoes , and bracelets too .', 'I like beef , but not crabs .', 'I like sports , but not techno .', 'I do not like Suzukis , I prefer airplanes .', 'I do not like books , I prefer essays .', 'I like lard , except carrots .', 'I like shoes , except skirts .', 'I like beds , except paintings .', 'I like beagles more than parrots .', 'I use vinyl , and leather too .', 'I do not like novels , I prefer cartoons .', 'I like physicists more than caretakers .', 'I like beagles , except rabbits .', 'I like Merlot , but not coca-cola .', 'I like veal , except oysters .', 'I like giraffes , except dogs .', 'I like food more than techno .', 'I do not like beds , I prefer furniture .', 'I like oaks more than trees .', 'I like animals more than birches .', 'I like trees , and shrubs too .', 'I do not like workers , I prefer schools .', 'I like apples , and ham too .', 'He trusts his hearing , except guesses .', 'I like apples , except lard .', 'I like birches , except shrubs .', 'I like books more than essays .', 'I like earrings , but not skirts .', 'I met astronomers , but not scientists .', 'I like furniture , and cutlery too .', 'I like dogs more than huskies .', 'I like pork more than lard .', 'I do not like documentaries , I prefer textbooks .', 'I do not like bacon , I prefer apples .', 'I like bacon , but not fish .', 'I like tables , and furniture too .', 'I like essays , except westerns .', 'I like bears , and dogs too .', 'I like factories , except caretakers .', 'I do not like vinyl , I prefer plastic .', 'I like wine , except coca-cola .', 'I like seafood , and caviar too .', 'I like furniture , but not beds .', 'I like ships , and Harley-Davidson too .', 'I use glass , except vinyl .', 'I like chairs , and wallpaper too .', 'I like Kawasakis , and trains too .', 'I like documentaries more than essays .', 'I like chicken , but not oysters .', 'I like caretakers , but not schools .', 'He trusts his touch , except rumors .', 'I met scientists , except physicists .', 'I like socks more than jewelry .', 'He does not trust his senses , he prefers rumors .', 'I like restaurants , but not caretakers .', 'He likes emotions , and sadness too .', 'I like sparrows , but not cats .', 'He likes fear , and emotions too .', 'I like whales , except rabbits .', 'I like parquet , and tables too .', 'I do not like pork , I prefer broccoli .', 'I like comedies more than essays .', 'He trusts his sight , except reconstructions .']
2021-12-05 20:49:37,784 - transformers - INFO - X_dev: ['I like dogs , an interesting type of giraffe .', 'I use PVC , an interesting type of plastic .', 'I like documentaries , an interesting type of textbook .', 'I like motorcycles , an interesting type of bicycle .', 'I like birds , an interesting type of hamster .', 'I use cotton , an interesting type of nylon .', 'I like wardrobes , an interesting type of parquet .', 'He trusts his touch , an interesting type of report .', 'I like jazz , an interesting type of necklace .', 'I like pork , an interesting type of carrot .', 'I like Harley-Davidson , an interesting type of ship .', 'I like wine , an interesting type of Merlot .', 'I use wood , an interesting type of nylon .', 'He trusts his senses , an interesting type of sight .', 'I like videogames , an interesting type of comedy .', 'I met waiters , an interesting type of geneticist .', 'I like beer , an interesting type of Chardonnay .', 'I like rabbits , an interesting type of bear .', 'I like shirts , an interesting type of pet .', 'I like motorcycles , an interesting type of Suzuki .', 'I met caretakers , an interesting type of astronomer .', 'I like hamsters , an interesting type of bobtail .', 'He likes stupidity , an interesting type of love .', 'I like books , an interesting type of textbook .', 'I like dogs , an interesting type of sparrow .', 'I like cats , an interesting type of sparrow .', 'I use nylon , an interesting type of plastic .', 'I like thrillers , an interesting type of videogame .', 'He likes calculations , an interesting type of love .', 'I like chicken , an interesting type of caviar .', 'I like rabbits , an interesting type of bulldog .', 'I like trees , an interesting type of shrub .', 'I like techno , an interesting type of necklace .', 'I like veal , an interesting type of oysters .', 'I like rabbits , an interesting type of husky .', 'I like waiters , an interesting type of school .', 'I like offices , an interesting type of professor .', 'I like music , an interesting type of jazz .', 'I like turkey , an interesting type of caviar .', 'I like Suzukis , an interesting type of ship .', 'I met astronomers , an interesting type of clerk .', 'I like handbags , an interesting type of bracelet .', 'I met scientists , an interesting type of janitor .', 'I use nylon , an interesting type of leather .', 'I like trains , an interesting type of Harley-Davidson .', 'He trusts his touch , an interesting type of sense .', 'I like dogs , an interesting type of whale .', 'I like waiters , an interesting type of restaurant .', 'I like caviar , an interesting type of veal .', 'I like lard , an interesting type of pork .', 'I like ships , an interesting type of Kawasaki .', 'He trusts his sight , an interesting type of sense .', 'I like ducks , an interesting type of bird .', 'I like firs , an interesting type of tree .', 'I like necklaces , an interesting type of glasses .', 'I like Chardonnay , an interesting type of beer .', 'I like music , an interesting type of food .', 'I like rock , an interesting type of sport .', 'I like offices , an interesting type of clerk .', 'He likes logic , an interesting type of fear .', 'I like parquet , an interesting type of bed .', 'I like documentaries , an interesting type of essay .', 'I met biologists , an interesting type of waiter .', 'I like whales , an interesting type of cat .', 'I like films , an interesting type of novel .', 'I like wine , an interesting type of Chianti .', 'I like firs , an interesting type of animal .', 'I like boardgames , an interesting type of thriller .', 'I like shoes , an interesting type of necklace .', 'I like essays , an interesting type of thriller .', 'I like necklaces , an interesting type of jewelry .', 'He likes joy , an interesting type of logic .', 'I like workers , an interesting type of school .', 'I like furniture , an interesting type of bed .', 'I like Chianti , an interesting type of beer .', 'I like jewelry , an interesting type of skirt .', 'I like parrots , an interesting type of beagle .', 'I like workers , an interesting type of restaurant .', 'I like Suzukis , an interesting type of bicycle .', 'I met biologists , an interesting type of scientist .', 'I met geneticists , an interesting type of scientist .', 'He trusts guesses , an interesting type of taste .', 'I like rabbits , an interesting type of pet .', 'I like scarfs , an interesting type of bracelet .', 'He likes sadness , an interesting type of emotion .', 'I like grass , an interesting type of oak .', 'I like birches , an interesting type of bush .', 'I like bears , an interesting type of dog .', 'I like jewelry , an interesting type of techno .', 'I like skirts , an interesting type of earring .', 'I use vinyl , an interesting type of cotton .', 'I like Kawasakis , an interesting type of airplane .', 'I like handbooks , an interesting type of film .', 'I like textbooks , an interesting type of comedy .', 'I like pork , an interesting type of broccoli .', 'I like cats , an interesting type of beagle .', 'I like cats , an interesting type of giraffe .', 'I like ducks , an interesting type of pig .', 'I met scientists , an interesting type of astronomer .', 'I like salmon , an interesting type of veal .', 'I like essays , an interesting type of comedy .', 'I like wine , an interesting type of beer .', 'I like jewelry , an interesting type of rock .', 'I met waiters , an interesting type of biologist .', 'I like cats , an interesting type of bulldog .', 'I like wardrobes , an interesting type of cutlery .', 'I like dogs , an interesting type of beagle .', 'I like boardgames , an interesting type of western .', 'He trusts guesses , an interesting type of sight .', 'I like bacon , an interesting type of fish .', 'I use vinyl , an interesting type of plastic .', 'I like books , an interesting type of painting .', 'I like sparrows , an interesting type of cat .', 'I like enduros , an interesting type of train .', 'I like bulldogs , an interesting type of hamster .', 'I like wallpaper , an interesting type of table .', 'I met janitors , an interesting type of physicist .', 'I like seafood , an interesting type of oyster .', 'I like Chianti , an interesting type of water .', 'He trusts his sight , an interesting type of reconstruction .', 'He trusts his sight , an interesting type of report .', 'I like ducks , an interesting type of cat .', 'I like food , an interesting type of blues .', 'I like schools , an interesting type of waiter .', 'I like jazz , an interesting type of sport .', 'I like music , an interesting type of techno .', 'He trusts his hearing , an interesting type of guess .', 'I like beef , an interesting type of crabs .', 'I like bracelets , an interesting type of handbag .', 'I like rabbits , an interesting type of jellyfish .', 'I met clerks , an interesting type of geneticist .', 'I like blues , an interesting type of necklace .', 'He trusts his senses , an interesting type of hearing .', 'I like comedies , an interesting type of textbook .', 'I like textbooks , an interesting type of book .', 'I like seafood , an interesting type of chicken .', 'I like socks , an interesting type of earring .', 'I like necklaces , an interesting type of shoe .', 'I like jewelry , an interesting type of glasses .', 'I like caviar , an interesting type of beef .', 'I like jazz , an interesting type of food .', 'I like movies , an interesting type of thriller .', 'I like westerns , an interesting type of boardgame .', 'He likes logic , an interesting type of love .', 'I like shirts , an interesting type of earring .', 'I like trees , an interesting type of fir .', 'I like huskies , an interesting type of rabbit .', 'I like Harley-Davidson , an interesting type of airplane .', 'I like planes , an interesting type of Harley-Davidson .', 'I like seafood , an interesting type of turkey .', 'I like pets , an interesting type of shirt .', 'I like textbooks , an interesting type of film .', 'I like bicycles , an interesting type of Kawasaki .', 'I like pets , an interesting type of giraffe .', 'I like pines , an interesting type of tree .', 'I like rock , an interesting type of music .', 'I like westerns , an interesting type of textbook .', 'I like workers , an interesting type of caretaker .', 'I met caretakers , an interesting type of physicist .', 'I like huskies , an interesting type of hamster .', 'I like seafood , an interesting type of caviar .', 'I like professors , an interesting type of school .', 'He likes sadness , an interesting type of stupidity .', 'I like trains , an interesting type of enduro .', 'I like paintings , an interesting type of novel .', 'I use plastic , an interesting type of glass .', 'I like ships , an interesting type of Suzuki .', 'I like fish , an interesting type of bacon .', 'I met janitors , an interesting type of astronomer .', 'I like bushes , an interesting type of birch .', 'I like glasses , an interesting type of earring .', 'I like Merlot , an interesting type of coca-cola .', 'I like birds , an interesting type of pig .', 'I like jewelry , an interesting type of blues .', 'I like offices , an interesting type of caretaker .', 'I like Kawasakis , an interesting type of train .', 'He likes logic , an interesting type of joy .', 'I like beds , an interesting type of wallpaper .', 'I like bacon , an interesting type of broccoli .', 'I like music , an interesting type of novel .', 'I like broccoli , an interesting type of prosciutto .', 'I like firs , an interesting type of grass .', 'I like rings , an interesting type of scarf .', 'I like Merlot , an interesting type of water .', 'I like pets , an interesting type of trouser .', 'I like cats , an interesting type of husky .', 'He likes calculations , an interesting type of joy .', 'I use nylon , an interesting type of glass .', 'I like bulldogs , an interesting type of dog .', 'I like clothes , an interesting type of skirt .', 'I like grass , an interesting type of pine .', 'I like cats , an interesting type of parrot .', 'I like clerks , an interesting type of worker .', 'I use leather , an interesting type of nylon .', 'I like tables , an interesting type of wallpaper .', 'I like coca-cola , an interesting type of Chardonnay .', 'I like chicken , an interesting type of oysters .', 'I like oaks , an interesting type of shrub .', 'I like cats , an interesting type of pet .', 'He likes love , an interesting type of emotion .', 'I like jewelry , an interesting type of scarf .', 'I like planes , an interesting type of Suzuki .', 'I like lard , an interesting type of broccoli .', 'I like essays , an interesting type of book .', 'I like trains , an interesting type of Kawasaki .', 'I like shrubs , an interesting type of birch .', 'I like glasses , an interesting type of bracelet .', 'I like Suzukis , an interesting type of airplane .', 'I like animals , an interesting type of fir .', 'I met geneticists , an interesting type of janitor .', 'I like motorcycles , an interesting type of Kawasaki .', 'I like huskies , an interesting type of parrot .', 'I like music , an interesting type of blues .', 'He likes sadness , an interesting type of calculation .', 'I like pork , an interesting type of bacon .', 'He likes emotions , an interesting type of logic .', 'I like schools , an interesting type of clerk .', 'I like dogs , an interesting type of cat .', 'I like essays , an interesting type of documentary .', 'I like socks , an interesting type of glass .', 'I like bobtails , an interesting type of parrot .', 'I like clothes , an interesting type of jewelry .', 'I like westerns , an interesting type of essay .', 'I like seafood , an interesting type of beef .', 'He trusts his sight , an interesting type of rumor .', 'I like bracelets , an interesting type of jewelry .', 'I like Chianti , an interesting type of coca-cola .', 'He trusts his senses , an interesting type of rumor .', 'I like books , an interesting type of music .', 'I like Kawasakis , an interesting type of bicycle .', 'I use glass , an interesting type of polyester .', 'I like lard , an interesting type of carrots .', 'I like crabs , an interesting type of seafood .', 'I like boardgames , an interesting type of blues .', 'I like ham , an interesting type of broccoli .', 'He likes fear , an interesting type of stupidity .', 'I use plastic , an interesting type of vinyl .', 'I like tables , an interesting type of painting .', 'I like prosciutto , an interesting type of apples .', 'I like boardgames , an interesting type of rock .', 'I like beds , an interesting type of furniture .', 'I like thrillers , an interesting type of movie .', 'He likes joy , an interesting type of wisdom .', 'I like Harley-Davidson , an interesting type of bicycle .', 'I like pigs , an interesting type of parrot .', 'I like birches , an interesting type of tree .', 'I like pines , an interesting type of animal .', 'I like cartoons , an interesting type of novel .', 'I use nylon , an interesting type of cotton .', 'I like oysters , an interesting type of seafood .', 'I like videogames , an interesting type of documentary .', 'I like professors , an interesting type of worker .', 'I like rock , an interesting type of food .', 'I like shirts , an interesting type of jewelry .', 'I like glasses , an interesting type of necklace .', 'I like motorcycles , an interesting type of train .', 'I like beds , an interesting type of parquet .', 'I like clothes , an interesting type of pet .', 'I like huskies , an interesting type of dog .', 'I met janitors , an interesting type of biologist .', 'I like enduros , an interesting type of bicycle .', 'I use vinyl , an interesting type of leather .', 'He likes stupidity , an interesting type of fear .', 'I like techno , an interesting type of boardgame .', 'He trusts reconstructions , an interesting type of taste .', 'I like comedies , an interesting type of videogame .', 'I use cotton , an interesting type of polyester .', 'I like broccoli , an interesting type of bacon .', 'I met scientists , an interesting type of clerk .', 'I like sparrows , an interesting type of hamster .', 'I like rabbits , an interesting type of bobtail .', 'I like chicken , an interesting type of crabs .', 'I like paintings , an interesting type of wardrobe .', 'I like sports , an interesting type of jazz .', 'I like earrings , an interesting type of shirt .', 'I like bracelets , an interesting type of glasses .', 'I like oysters , an interesting type of beef .', 'I like techno , an interesting type of music .', 'I like paintings , an interesting type of bed .', 'I like boardgames , an interesting type of documentary .', 'I like textbooks , an interesting type of thriller .', 'I like beef , an interesting type of oysters .', 'I like beds , an interesting type of cutlery .', 'I like pets , an interesting type of jellyfish .', 'He likes love , an interesting type of calculation .', 'I use plastic , an interesting type of polyester .', 'I like bears , an interesting type of hamster .', 'I like books , an interesting type of film .', 'I like wallpaper , an interesting type of wardrobe .', 'I like parrots , an interesting type of dog .', 'I like shoes , an interesting type of ring .', 'He likes stupidity , an interesting type of sadness .', 'I like shoes , an interesting type of earring .', 'I like wardrobes , an interesting type of furniture .', 'I like workers , an interesting type of office .', 'I like furniture , an interesting type of table .', 'I like movies , an interesting type of essay .', 'I like parrots , an interesting type of hamster .', 'I like movies , an interesting type of western .', 'I like essays , an interesting type of western .', 'I like sparrows , an interesting type of pig .', 'He likes wisdom , an interesting type of joy .', 'I like Chianti , an interesting type of sprite .', 'I like socks , an interesting type of clothes .', 'I like prosciutto , an interesting type of carrots .', 'I like movies , an interesting type of boardgame .', 'I like ham , an interesting type of apples .', 'I like caretakers , an interesting type of worker .', 'I like clothes , an interesting type of trousers .', 'I like shrubs , an interesting type of fir .', 'He trusts his taste , an interesting type of reconstruction .', 'I like dogs , an interesting type of bulldog .', 'I like beagles , an interesting type of cat .', 'I like dogs , an interesting type of husky .', 'I like rings , an interesting type of shoe .', 'I like hamsters , an interesting type of sparrow .', 'I like wine , an interesting type of Chardonnay .', 'I met waiters , an interesting type of physicist .', 'I use polyester , an interesting type of plastic .', 'I met caretakers , an interesting type of geneticist .', 'I like bears , an interesting type of cat .', 'I like textbooks , an interesting type of music .', 'I met clerks , an interesting type of physicist .', 'I like boardgames , an interesting type of techno .', 'I like birches , an interesting type of shrub .', 'I like techno , an interesting type of food .', 'I like chairs , an interesting type of parquet .', 'I like factories , an interesting type of caretaker .', 'I like trousers , an interesting type of glass .', 'I like novels , an interesting type of music .', 'I like skirts , an interesting type of pet .', 'I like apples , an interesting type of ham .', 'I like ham , an interesting type of fish .', 'I like parrots , an interesting type of husky .', 'I like scarfs , an interesting type of earring .', 'I like pets , an interesting type of sock .', 'I like socks , an interesting type of jewelry .', 'I like parrots , an interesting type of pig .', 'He likes love , an interesting type of logic .', 'I like furniture , an interesting type of chair .', 'I like clothes , an interesting type of socks .', 'I like food , an interesting type of jazz .', 'I like crabs , an interesting type of chicken .', 'I like caretakers , an interesting type of office .', 'I like skirts , an interesting type of clothes .', 'I like shirts , an interesting type of glass .', 'I like blues , an interesting type of music .', 'I like Chardonnay , an interesting type of sprite .', 'I like furniture , an interesting type of wardrobe .', 'I met physicists , an interesting type of caretaker .', 'I use wood , an interesting type of polyester .', 'He trusts reports , an interesting type of sight .', 'I use vinyl , an interesting type of glass .', 'I like Suzukis , an interesting type of train .', 'He trusts his hearing , an interesting type of reconstruction .', 'I like professors , an interesting type of office .', 'He likes fear , an interesting type of calculation .', 'I like bulldogs , an interesting type of parrot .', 'I like sports , an interesting type of blues .', 'I like salmon , an interesting type of seafood .', 'I met physicists , an interesting type of janitor .', 'I like beagles , an interesting type of parrot .', 'I like bushes , an interesting type of pine .', 'I like bacon , an interesting type of apples .', 'I like trees , an interesting type of animal .', 'I met biologists , an interesting type of janitor .', 'I like trees , an interesting type of oak .', 'I like blackbirds , an interesting type of pig .', 'I like hamsters , an interesting type of parrot .', 'I use plastic , an interesting type of wood .', 'I like prosciutto , an interesting type of fish .', 'I like bobtails , an interesting type of hamster .', 'I like jellyfish , an interesting type of hamster .', 'I like cats , an interesting type of jellyfish .', 'I like cartoons , an interesting type of essay .', 'I like wallpaper , an interesting type of bed .', 'I like sports , an interesting type of rock .', 'He likes joy , an interesting type of calculation .', 'I like clerks , an interesting type of office .', 'I like caretakers , an interesting type of factory .', 'I met biologists , an interesting type of clerk .', 'I like factories , an interesting type of professor .', 'I met clerks , an interesting type of astronomer .', 'I like music , an interesting type of boardgame .', 'I like clerks , an interesting type of school .', 'I like novels , an interesting type of film .', 'I like whales , an interesting type of hamster .', 'I like glasses , an interesting type of shirt .', 'He trusts his hearing , an interesting type of report .', 'I like whales , an interesting type of dog .', 'I like huskies , an interesting type of cat .', 'I met astronomers , an interesting type of waiter .', 'I like salmon , an interesting type of turkey .', 'I like rabbits , an interesting type of beagle .', 'He likes sadness , an interesting type of logic .', 'I like books , an interesting type of handbook .', 'I like jazz , an interesting type of boardgame .', 'He likes emotions , an interesting type of sadness .', 'I like Kawasakis , an interesting type of motorcycle .', 'I use leather , an interesting type of PVC .', 'I like trains , an interesting type of Suzuki .', 'I like seafood , an interesting type of salmon .', 'I like earrings , an interesting type of handbag .', 'I use cotton , an interesting type of PVC .', 'I like westerns , an interesting type of videogame .', 'I met janitors , an interesting type of geneticist .', 'He trusts his senses , an interesting type of reconstruction .', 'He likes logic , an interesting type of sadness .', 'I like bobtails , an interesting type of cat .', 'I like rabbits , an interesting type of whale .', 'I use leather , an interesting type of polyester .', 'I use cotton , an interesting type of vinyl .', 'I like beer , an interesting type of Zinfandel .', 'He likes love , an interesting type of wisdom .', 'I like earrings , an interesting type of glasses .', 'I like shoes , an interesting type of bracelet .', 'I like pines , an interesting type of shrub .', 'I use polyester , an interesting type of leather .', 'I like pets , an interesting type of cat .', 'I like workers , an interesting type of professor .', 'I like paintings , an interesting type of essay .', 'I like earrings , an interesting type of jewelry .', 'I like videogames , an interesting type of thriller .', 'I met geneticists , an interesting type of caretaker .', 'He likes calculations , an interesting type of sadness .', 'I like clerks , an interesting type of restaurant .', 'I like apples , an interesting type of prosciutto .', 'I like giraffes , an interesting type of dog .', 'I like ducks , an interesting type of dog .', 'I like coca-cola , an interesting type of Merlot .', 'I like shirts , an interesting type of clothes .', 'I like cutlery , an interesting type of bed .', 'I like caviar , an interesting type of turkey .', 'I met geneticists , an interesting type of clerk .', 'I like giraffes , an interesting type of rabbit .', 'I like bracelets , an interesting type of shoe .', 'I like documentaries , an interesting type of videogame .', 'He trusts guesses , an interesting type of hearing .', 'I use PVC , an interesting type of wood .', 'I met scientists , an interesting type of physicist .', 'I like handbooks , an interesting type of book .', 'I like glasses , an interesting type of ring .', 'I like skirts , an interesting type of jewelry .', 'I like giraffes , an interesting type of hamster .', 'I like handbooks , an interesting type of music .', 'He likes stupidity , an interesting type of joy .', 'He likes fear , an interesting type of emotion .', 'He trusts reports , an interesting type of hearing .', 'I like books , an interesting type of cartoon .', 'I like Merlot , an interesting type of beer .', 'I like essays , an interesting type of music .', 'He trusts rumors , an interesting type of hearing .', 'I use vinyl , an interesting type of wood .', 'He likes joy , an interesting type of emotion .', 'I like motorcycles , an interesting type of enduro .', 'I like hamsters , an interesting type of jellyfish .', 'I like waiters , an interesting type of office .', 'I like earrings , an interesting type of sock .', 'I met waiters , an interesting type of astronomer .', 'I like food , an interesting type of rock .', 'I like beef , an interesting type of caviar .', 'I like earrings , an interesting type of scarf .', 'He likes emotions , an interesting type of calculation .', 'I like factories , an interesting type of waiter .', 'I like handbags , an interesting type of necklace .', 'I like thrillers , an interesting type of essay .', 'I like glasses , an interesting type of sock .', 'I like books , an interesting type of essay .', 'I like jewelry , an interesting type of trouser .', 'I like earrings , an interesting type of skirt .', 'I like books , an interesting type of novel .', 'I like workers , an interesting type of factory .', 'I like water , an interesting type of Chianti .', 'I like pets , an interesting type of rabbit .', 'I like carrots , an interesting type of ham .', 'I like jazz , an interesting type of music .', 'I like carrots , an interesting type of bacon .', 'I like films , an interesting type of handbook .', 'I use PVC , an interesting type of glass .', 'I like bulldogs , an interesting type of rabbit .', 'He trusts reconstructions , an interesting type of hearing .', 'I like cats , an interesting type of whale .', 'I like films , an interesting type of essay .', 'I like earrings , an interesting type of trouser .', 'I like trousers , an interesting type of clothes .', 'I like cats , an interesting type of duck .', 'I like veal , an interesting type of crabs .', 'I like glasses , an interesting type of skirt .', 'I like paintings , an interesting type of textbook .', 'I like oysters , an interesting type of veal .', 'I like blackbirds , an interesting type of dog .', 'I met biologists , an interesting type of caretaker .', 'I like wine , an interesting type of coca-cola .', 'He likes emotions , an interesting type of stupidity .', 'I use polyester , an interesting type of wood .', 'I like crabs , an interesting type of veal .', 'I like essays , an interesting type of film .', 'I like fish , an interesting type of ham .', 'I like movies , an interesting type of documentary .', 'I like dogs , an interesting type of blackbird .', 'I like ham , an interesting type of carrots .', 'I like blues , an interesting type of sport .', 'I like chairs , an interesting type of painting .', 'I like coca-cola , an interesting type of Zinfandel .', 'I use plastic , an interesting type of nylon .', 'I like videogames , an interesting type of western .', 'I like seafood , an interesting type of veal .', 'I like hamsters , an interesting type of husky .', 'I like hamsters , an interesting type of bear .', 'I use glass , an interesting type of vinyl .', 'I like glasses , an interesting type of trouser .', 'I like restaurants , an interesting type of clerk .', 'I like lard , an interesting type of apples .', 'I like textbooks , an interesting type of western .', 'I like comedies , an interesting type of essay .', 'I like carrots , an interesting type of lard .', 'I like water , an interesting type of Zinfandel .', 'I like wardrobes , an interesting type of wallpaper .', 'I like bicycles , an interesting type of enduro .', 'I like beagles , an interesting type of dog .', 'I met geneticists , an interesting type of waiter .', 'I like pets , an interesting type of bear .', 'I like comedies , an interesting type of movie .', 'I like cats , an interesting type of blackbird .', 'He likes sadness , an interesting type of wisdom .', 'I like turkey , an interesting type of salmon .', 'I like comedies , an interesting type of boardgame .', 'I like textbooks , an interesting type of documentary .', 'I like birds , an interesting type of blackbird .', 'He trusts his touch , an interesting type of reconstruction .', 'I like novels , an interesting type of book .', 'I like ham , an interesting type of pork .', 'I met scientists , an interesting type of geneticist .', 'He likes fear , an interesting type of logic .', 'I like enduros , an interesting type of airplane .', 'He trusts rumors , an interesting type of touch .', 'He likes calculations , an interesting type of fear .', 'I use plastic , an interesting type of leather .', 'I like jewelry , an interesting type of bracelet .', 'I like scarfs , an interesting type of ring .', 'I like trees , an interesting type of grass .', 'He trusts reconstructions , an interesting type of sight .', 'I like jellyfish , an interesting type of rabbit .', 'I like boardgames , an interesting type of jazz .', 'I like pork , an interesting type of apple .', 'He trusts his touch , an interesting type of rumor .', 'I like blues , an interesting type of food .', 'I like beef , an interesting type of salmon .', 'I like furniture , an interesting type of parquet .', 'I like waiters , an interesting type of worker .', 'I like whales , an interesting type of rabbit .', 'I like pets , an interesting type of hamster .', 'I use polyester , an interesting type of cotton .', 'I use polyester , an interesting type of glass .', 'I like textbooks , an interesting type of painting .', 'I like hamsters , an interesting type of giraffe .', 'I like skirts , an interesting type of glass .', 'I like Chardonnay , an interesting type of wine .', 'I like music , an interesting type of essay .', 'I like wine , an interesting type of water .', 'He trusts his senses , an interesting type of taste .', 'I like professors , an interesting type of restaurant .', 'I like planes , an interesting type of Kawasaki .', 'I like blackbirds , an interesting type of hamster .', 'I like Merlot , an interesting type of sprite .', 'He trusts his senses , an interesting type of report .', 'I like sprite , an interesting type of Chardonnay .', 'He likes love , an interesting type of stupidity .', 'I like jewelry , an interesting type of shoe .', 'I like professors , an interesting type of factory .', 'I like schools , an interesting type of caretaker .', 'I like enduros , an interesting type of motorcycle .', 'I like sprite , an interesting type of Zinfandel .', 'I like bicycles , an interesting type of Harley-Davidson .', 'I like water , an interesting type of Chardonnay .', 'I use leather , an interesting type of vinyl .', 'I like pines , an interesting type of grass .', 'I like Harley-Davidson , an interesting type of motorcycle .', 'I like oysters , an interesting type of chicken .', 'He trusts reconstructions , an interesting type of touch .', 'I like veal , an interesting type of caviar .', 'I like broccoli , an interesting type of ham .', 'I like bracelets , an interesting type of scarf .', 'I like furniture , an interesting type of painting .', 'I like salmon , an interesting type of beef .', 'I like beer , an interesting type of Merlot .', 'I like dogs , an interesting type of bear .', 'I like jewelry , an interesting type of sock .', 'I like crabs , an interesting type of turkey .', 'I like Chardonnay , an interesting type of coca-cola .', 'I like hamsters , an interesting type of pet .', 'I like veal , an interesting type of salmon .', 'I like movies , an interesting type of videogame .', 'He trusts rumors , an interesting type of taste .', 'I like handbooks , an interesting type of painting .', 'I like earrings , an interesting type of shoe .', 'I like movies , an interesting type of textbook .', 'I met astronomers , an interesting type of scientist .', 'I like pigs , an interesting type of duck .', 'I like hamsters , an interesting type of blackbird .', 'I like chairs , an interesting type of cutlery .', 'I like ducks , an interesting type of hamster .', 'I like movies , an interesting type of comedie .', 'I like cartoons , an interesting type of handbook .', 'He trusts his taste , an interesting type of guess .', 'I like firs , an interesting type of bush .', 'I like tables , an interesting type of furniture .', 'I like bobtails , an interesting type of rabbit .', 'I like cats , an interesting type of bobtail .', 'I like lard , an interesting type of fish .', 'I like rings , an interesting type of glasses .', 'I like clerks , an interesting type of factory .', 'I like pork , an interesting type of lard .', 'I like dogs , an interesting type of hamster .', 'I like bicycles , an interesting type of Suzuki .', 'I use PVC , an interesting type of cotton .', 'I like paintings , an interesting type of chair .', 'I like bacon , an interesting type of pork .', 'I like music , an interesting type of necklace .', 'I like crabs , an interesting type of beef .', 'I like jewelry , an interesting type of ring .', 'I like apples , an interesting type of lard .', 'He likes fear , an interesting type of wisdom .', 'I like hamsters , an interesting type of bulldog .', 'I like blues , an interesting type of boardgame .', 'I like tables , an interesting type of parquet .', 'I like birds , an interesting type of dog .', 'I like sprite , an interesting type of Chianti .', 'I like oaks , an interesting type of grass .', 'I like handbags , an interesting type of ring .', 'I like caviar , an interesting type of seafood .', 'I like restaurants , an interesting type of caretaker .', 'I like chairs , an interesting type of wallpaper .', 'I like cutlery , an interesting type of table .', 'I like clothes , an interesting type of shirt .', 'I like schools , an interesting type of professor .', 'I like sparrows , an interesting type of dog .', 'I like essays , an interesting type of cartoon .', 'I like dogs , an interesting type of duck .', 'I like food , an interesting type of techno .', 'I like turkey , an interesting type of oysters .', 'I like Merlot , an interesting type of wine .', 'I like jewelry , an interesting type of handbag .', 'I like music , an interesting type of handbook .', 'I like birds , an interesting type of cat .', 'I like paintings , an interesting type of table .', 'I like motorcycles , an interesting type of airplane .', 'I like jellyfish , an interesting type of dog .', 'I like films , an interesting type of textbook .', 'I like cutlery , an interesting type of chair .', 'I like sports , an interesting type of techno .', 'I like pets , an interesting type of whale .', 'I like wine , an interesting type of sprite .', 'I like hamsters , an interesting type of whale .', 'He trusts his hearing , an interesting type of sense .', 'I like coca-cola , an interesting type of Chianti .', 'He trusts his taste , an interesting type of report .', 'I like caretakers , an interesting type of school .', 'I like bulldogs , an interesting type of cat .', 'I like salmon , an interesting type of chicken .', 'I like novels , an interesting type of cartoon .', 'I use nylon , an interesting type of wood .', 'I like animals , an interesting type of birch .', 'I like westerns , an interesting type of movie .', 'I like socks , an interesting type of pet .', 'I like Zinfandel , an interesting type of sprite .', 'I like beer , an interesting type of Chianti .', 'I like ships , an interesting type of enduro .', 'I like pork , an interesting type of prosciutto .', 'I like restaurants , an interesting type of professor .', 'I like Zinfandel , an interesting type of beer .', 'I like blackbirds , an interesting type of cat .', 'I like thrillers , an interesting type of boardgame .', 'I like offices , an interesting type of waiter .', 'I like parquet , an interesting type of chair .', 'I met scientists , an interesting type of biologist .', 'I like birds , an interesting type of duck .', 'I like hamsters , an interesting type of beagle .', 'I met scientists , an interesting type of caretaker .', 'I met astronomers , an interesting type of janitor .', 'I like beagles , an interesting type of rabbit .', 'I like rock , an interesting type of necklace .', 'He trusts his senses , an interesting type of touch .', 'I like dogs , an interesting type of rabbit .', 'I met physicists , an interesting type of scientist .', 'I like bushes , an interesting type of oak .', 'I like handbags , an interesting type of earring .', 'I like music , an interesting type of sport .', 'I like pork , an interesting type of fish .', 'I like bobtails , an interesting type of dog .', 'I like giraffes , an interesting type of cat .', 'I use plastic , an interesting type of PVC .', 'I like waiters , an interesting type of factory .', 'I like Chianti , an interesting type of wine .', 'I like jewelry , an interesting type of earring .', 'I like Zinfandel , an interesting type of wine .', 'I like furniture , an interesting type of wallpaper .', 'I like bacon , an interesting type of carrots .', 'I like pigs , an interesting type of blackbird .', 'I like dogs , an interesting type of bobtail .', 'I like dogs , an interesting type of jellyfish .', 'I met clerks , an interesting type of biologist .', 'I like enduros , an interesting type of ship .', 'I like water , an interesting type of Merlot .', 'I like motorcycles , an interesting type of ship .', 'I like seafood , an interesting type of crab .', 'I like shrubs , an interesting type of pine .', 'I like pork , an interesting type of ham .', 'I like handbooks , an interesting type of cartoon .', 'I like Zinfandel , an interesting type of water .', 'I like wine , an interesting type of Zinfandel .', 'I like trees , an interesting type of pine .', 'I like clothes , an interesting type of earring .', 'I like fish , an interesting type of lard .', 'I like parrots , an interesting type of cat .', 'I like caviar , an interesting type of chicken .', 'I like birds , an interesting type of parrot .', 'I like pets , an interesting type of dog .', 'I like parquet , an interesting type of table .', 'I like birches , an interesting type of animal .', 'I like parquet , an interesting type of wardrobe .', 'I like cutlery , an interesting type of wardrobe .', 'I like pigs , an interesting type of sparrow .', 'He likes joy , an interesting type of stupidity .', 'I like oaks , an interesting type of bush .', 'He likes wisdom , an interesting type of love .', 'He likes wisdom , an interesting type of fear .', 'I like rabbits , an interesting type of giraffe .', 'I like restaurants , an interesting type of waiter .', 'I like wardrobes , an interesting type of painting .', 'I like wallpaper , an interesting type of chair .', 'He likes emotions , an interesting type of fear .', 'I like caretakers , an interesting type of restaurant .', 'He trusts rumors , an interesting type of sight .', 'He trusts his taste , an interesting type of sense .', 'I like trousers , an interesting type of jewelry .', 'I use glass , an interesting type of PVC .', 'I like dogs , an interesting type of parrot .', 'I like pines , an interesting type of bush .', 'He trusts his taste , an interesting type of rumor .', 'He trusts reports , an interesting type of touch .', 'I like trees , an interesting type of birch .', 'I like broccoli , an interesting type of lard .', 'I like trousers , an interesting type of pet .', 'I use PVC , an interesting type of leather .', 'I like sparrows , an interesting type of bird .', 'I like trousers , an interesting type of earring .', 'I use plastic , an interesting type of cotton .', 'He trusts his senses , an interesting type of guess .', 'I like clothes , an interesting type of glass .', 'I like animals , an interesting type of pine .', 'I like Kawasakis , an interesting type of ship .', 'I like Harley-Davidson , an interesting type of train .', 'I use wood , an interesting type of vinyl .', 'I like music , an interesting type of rock .', 'I like turkey , an interesting type of crabs .', 'He trusts reports , an interesting type of taste .', 'I like Zinfandel , an interesting type of coca-cola .', 'I like rings , an interesting type of handbag .', 'He likes emotions , an interesting type of joy .', 'I like planes , an interesting type of enduro .', 'I met physicists , an interesting type of clerk .', 'I like boardgames , an interesting type of comedy .', 'I met physicists , an interesting type of waiter .', 'I like factories , an interesting type of clerk .', 'I like paintings , an interesting type of handbook .', 'I like documentaries , an interesting type of movie .', 'I like jellyfish , an interesting type of cat .', 'I like novels , an interesting type of painting .', 'I like Suzukis , an interesting type of motorcycle .', 'I like animals , an interesting type of oak .', 'I like jewelry , an interesting type of necklace .', 'He likes wisdom , an interesting type of sadness .', 'I like dogs , an interesting type of pet .', 'He trusts his touch , an interesting type of guess .', 'I like jewelry , an interesting type of shirt .', 'I like rings , an interesting type of jewelry .', 'I use glass , an interesting type of nylon .', 'I like tables , an interesting type of cutlery .', 'I like firs , an interesting type of shrub .', 'I like bears , an interesting type of rabbit .', 'He trusts guesses , an interesting type of touch .', 'He likes emotions , an interesting type of wisdom .', 'I like textbooks , an interesting type of cartoon .', 'I like rock , an interesting type of boardgame .', 'I like beds , an interesting type of painting .', 'I like workers , an interesting type of clerk .', 'I like prosciutto , an interesting type of broccoli .', 'I like oysters , an interesting type of turkey .', 'I like oaks , an interesting type of tree .', 'I like blackbirds , an interesting type of bird .', 'I like essays , an interesting type of painting .', 'I like parrots , an interesting type of bulldog .', 'I met scientists , an interesting type of waiter .', 'I like chicken , an interesting type of salmon .', 'I like grass , an interesting type of fir .', 'I like birches , an interesting type of grass .', 'I like thrillers , an interesting type of textbook .', 'I like necklaces , an interesting type of scarf .', 'I use wood , an interesting type of PVC .', 'He trusts his sight , an interesting type of guess .', 'I like motorcycles , an interesting type of Harley-Davidson .', 'I like carrots , an interesting type of prosciutto .', 'I like parrots , an interesting type of bobtail .', 'I like apples , an interesting type of bacon .', 'I like furniture , an interesting type of cutlery .', 'I like cats , an interesting type of bear .', 'I met caretakers , an interesting type of biologist .', 'I like techno , an interesting type of sport .', 'I like fish , an interesting type of prosciutto .', 'I like cartoons , an interesting type of textbook .', 'I like trees , an interesting type of bush .', 'I like scarfs , an interesting type of necklace .', 'I like bushes , an interesting type of fir .', 'I like sprite , an interesting type of Merlot .', 'I like beagles , an interesting type of hamster .', 'I like oaks , an interesting type of animal .', 'I like chairs , an interesting type of furniture .', 'I like parrots , an interesting type of bird .', 'I like pets , an interesting type of skirt .', 'I like ships , an interesting type of Harley-Davidson .', 'I like hamsters , an interesting type of duck .', 'I like necklaces , an interesting type of handbag .', 'I like shrubs , an interesting type of oak .', 'I like prosciutto , an interesting type of pork .', 'He trusts his hearing , an interesting type of rumor .', 'I like music , an interesting type of textbook .', 'I like grass , an interesting type of birch .', 'I like birds , an interesting type of sparrow .', 'I like workers , an interesting type of waiter .', 'I met astronomers , an interesting type of caretaker .', 'He likes emotions , an interesting type of love .', 'I like documentaries , an interesting type of boardgame .', 'I like Chardonnay , an interesting type of water .', 'I like jewelry , an interesting type of jazz .']
2021-12-05 20:54:09,339 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:54:09,341 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:54:13,023 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:54:13,024 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:54:13,024 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:54:13,024 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:54:13,024 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:54:13,745 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:54:13,746 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:54:14,213 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:54:14,216 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:54:15,081 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:54:16,572 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:54:16,572 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:54:28,870 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:54:28,871 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:54:31,871 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:54:31,872 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:54:31,872 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:54:31,872 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:54:31,872 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:54:32,304 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:54:32,307 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:54:32,795 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:54:32,797 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:54:33,275 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:54:34,563 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:54:34,564 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 20:55:15,853 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:55:15,855 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:55:18,629 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 20:55:18,631 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 20:55:18,631 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 20:55:18,631 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 20:55:18,632 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 20:55:19,289 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:55:19,290 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:55:19,756 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 20:55:19,758 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 20:55:20,343 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 20:55:21,643 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 20:55:21,643 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 21:03:25,694 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:03:25,695 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:03:29,373 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 21:03:29,373 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 21:03:29,374 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 21:03:29,374 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 21:03:29,374 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 21:03:29,902 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:03:29,905 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:03:30,421 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:03:30,422 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:03:30,891 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 21:03:32,174 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 21:03:32,174 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 21:03:45,246 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:03:45,249 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:03:47,928 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 21:03:47,929 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 21:03:47,929 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 21:03:47,929 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 21:03:47,929 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 21:03:48,355 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:03:48,358 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:03:49,148 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:03:49,150 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:03:49,622 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 21:03:50,915 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 21:03:50,916 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 21:06:52,128 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:06:52,129 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:06:55,000 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 21:06:55,001 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 21:06:55,001 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 21:06:55,001 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 21:06:55,001 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 21:06:55,522 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:06:55,522 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:06:56,033 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:06:56,035 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:06:56,507 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 21:06:57,787 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 21:06:57,787 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 21:14:49,397 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:14:49,399 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:14:52,897 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 21:14:52,897 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 21:14:52,898 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 21:14:52,898 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 21:14:52,898 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 21:14:53,615 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:14:53,616 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:14:54,333 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:14:54,333 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:14:54,793 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 21:14:56,130 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 21:14:56,130 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 21:16:19,405 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:16:19,406 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:16:22,151 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 21:16:22,152 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 21:16:22,153 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 21:16:22,153 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 21:16:22,154 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 21:16:22,907 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:16:22,908 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:16:23,377 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:16:23,380 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:16:23,861 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 21:16:25,141 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 21:16:25,141 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 21:18:01,431 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:18:01,432 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:18:04,388 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 21:18:04,389 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 21:18:04,390 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 21:18:04,390 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 21:18:04,390 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 21:18:05,103 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:18:05,104 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:18:05,619 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:18:05,620 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:18:06,091 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 21:18:07,370 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 21:18:07,371 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 21:20:58,695 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:20:58,698 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:21:01,869 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 21:21:01,870 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 21:21:01,871 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 21:21:01,871 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 21:21:01,871 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 21:21:02,300 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:21:02,301 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:21:02,770 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:21:02,773 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:21:03,241 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 21:21:04,517 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 21:21:04,517 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 21:21:30,621 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:21:30,623 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:21:33,901 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 21:21:33,902 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 21:21:33,902 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 21:21:33,903 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 21:21:33,903 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 21:21:34,457 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:21:34,460 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:21:35,025 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:21:35,026 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:21:35,747 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 21:21:37,040 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 21:21:37,040 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 21:23:10,975 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:23:10,976 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:23:13,997 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 21:23:13,998 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 21:23:13,998 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 21:23:13,998 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 21:23:13,999 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 21:23:14,460 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:23:14,463 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:23:15,072 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:23:15,075 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:23:15,548 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 21:23:16,880 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 21:23:16,881 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 21:27:09,567 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:27:09,570 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:27:12,947 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 21:27:12,948 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 21:27:12,948 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 21:27:12,949 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 21:27:12,949 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 21:27:13,666 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:27:13,668 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:27:14,149 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:27:14,152 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:27:14,630 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 21:27:15,953 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 21:27:15,953 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 21:28:03,027 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:28:03,028 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:28:06,093 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 21:28:06,094 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 21:28:06,094 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 21:28:06,094 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 21:28:06,095 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 21:28:06,518 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:28:06,520 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:28:07,321 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:28:07,322 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:28:07,770 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 21:28:09,214 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 21:28:09,215 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2021-12-05 21:33:20,499 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:33:20,502 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:33:23,383 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/an/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
2021-12-05 21:33:23,384 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/an/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
2021-12-05 21:33:23,384 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None
2021-12-05 21:33:23,384 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None
2021-12-05 21:33:23,384 - transformers.tokenization_utils_base - INFO - loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/an/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79
2021-12-05 21:33:23,810 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:33:23,813 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:33:25,537 - transformers.configuration_utils - INFO - loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/an/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
2021-12-05 21:33:25,539 - transformers.configuration_utils - INFO - Model config BertConfig {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.11.2",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

2021-12-05 21:33:26,016 - transformers.modeling_tf_utils - INFO - loading weights file https://huggingface.co/bert-base-uncased/resolve/main/tf_model.h5 from cache at /home/an/.cache/huggingface/transformers/775efbdc2152093295bc5824dee96da82a5f3c1f218dfface1b8cef3094bdf8f.c719a806caef7d36ec0185f14b3b5fa727d919f924abe35622b4b7147bfbb8c7.h5
2021-12-05 21:33:27,308 - transformers.modeling_tf_utils - WARNING - All model checkpoint layers were used when initializing TFBertForSequenceClassification.

2021-12-05 21:33:27,308 - transformers.modeling_tf_utils - WARNING - Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
